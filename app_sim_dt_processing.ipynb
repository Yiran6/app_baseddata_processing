{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"G:/My Drive/2021/Bias/sumo_simulation/appsim\"\n",
    "os.chdir(path)\n",
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other method \n",
    "#considering taz as a point and construct a network\n",
    "#possible resource\n",
    "#https://github.com/sharifulgeo/ESRI/tree/master/Connect_Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get taz data\n",
    "taz_tree = ET.parse('Taz_bigger_Seattle_all_fordtagg.add.xml')\n",
    "taz_root = taz_tree.getroot()\n",
    "\n",
    "#for i in root.iter('timestep'):\n",
    "#    print(i.attrib)\n",
    "##output:{'time': '0.00'} {'time': '300.00'}\n",
    "\n",
    "#use the fcd output to check the data\n",
    "tree = ET.parse('fcd_output_5.xml')\n",
    "root = tree.getroot()\n",
    "#for i in root.iter('timestep'):\n",
    "#    print(i.attrib)\n",
    "##output:{'time': '0.00'} {'time': '300.00'}\n",
    "\n",
    "#get net data\n",
    "net_tree = ET.parse('test_2_traffic_sig_revise_5.net.xml')\n",
    "net_root = net_tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing TAZs processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "#get edge id in tazs\n",
    "edge_taz_dict = {}\n",
    "edges_in2tazs = {}\n",
    "for tazs in taz_root.iter('taz'):\n",
    "    taz_id_cur = tazs.attrib['id']\n",
    "    for edge in tazs.findall('tazSource'):\n",
    "        edge_id_cur = edge.attrib['id']\n",
    "        if edge_id_cur not in edge_taz_dict:\n",
    "            edge_taz_dict[edge_id_cur] = taz_id_cur\n",
    "        else:\n",
    "            #print('warning, edges appear in more than one taz')\n",
    "            edges_in2tazs[edge_id_cur] = []\n",
    "            edges_in2tazs[edge_id_cur].append(edge_taz_dict[edge_id_cur])\n",
    "            edges_in2tazs[edge_id_cur].append(taz_id_cur)\n",
    "            \n",
    "print(edges_in2tazs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get fcd data\n",
    "#check edges in the data\n",
    "edge_lst = []\n",
    "lane_lst = []\n",
    "\n",
    "for t in root.findall('timestep'):\n",
    "    #get lane id from vehicle\n",
    "    for veh in t.findall('vehicle'):\n",
    "        #print(veh.attrib['id'])\n",
    "        lane_id_cur = veh.attrib['lane']\n",
    "        #if '_' in lane_id_cur:\n",
    "        #    lane_id_cur = ExtractEdgeFromLane(lane_id_cur)\n",
    "        if lane_id_cur not in lane_lst:\n",
    "            lane_lst.append(lane_id_cur)\n",
    "    for per in t.findall('person'):\n",
    "        edge_id_cur = per.attrib['edge']\n",
    "        if edge_id_cur not in edge_lst:\n",
    "            edge_lst.append(edge_id_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert lane to edge from net file\n",
    "lane_dict = {}\n",
    "edge_net_lst = [] #get all edges from the network\n",
    "for edge in net_root.findall('edge'):\n",
    "    edge_id = edge.attrib['id']\n",
    "    if edge_id not in edge_net_lst:\n",
    "        edge_net_lst.append(edge_id)   \n",
    "    for lane in edge.findall('lane'):\n",
    "        lane_id = lane.attrib['id']\n",
    "       # print(lane_id)\n",
    "        if lane_id in lane_lst and lane_id not in lane_dict:\n",
    "            lane_dict[lane_id] = edge_id\n",
    "#print(lane_dict)\n",
    "\n",
    "for edge in list(lane_dict.values()):\n",
    "    if edge not in edge_lst:\n",
    "        edge_lst.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_missing_tazs = []\n",
    "edges_with_tazs = list(edge_taz_dict.keys())\n",
    "for edges in edge_lst:\n",
    "    if edges not in edges_with_tazs and edges not in edges_missing_tazs:\n",
    "        edges_missing_tazs.append(edges)\n",
    "        \n",
    "missings_taz_veh = []\n",
    "missings_taz_ped_pub = []\n",
    "for edges in edges_missing_tazs:\n",
    "    if \":\" in edges: \n",
    "        missings_taz_ped_pub.append(edges)\n",
    "    else:\n",
    "        missings_taz_veh.append(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge with tazs identified: 7213\n",
      "edge w.o tazs identified: 6329\n"
     ]
    }
   ],
   "source": [
    "print('edge with tazs identified:', len(edges_with_tazs))\n",
    "print('edge w.o tazs identified:', len(edges_missing_tazs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign taz to missing edges\n",
    "missing_edge_connection = {}\n",
    "\n",
    "def assign_val(missing_edge_connection, target_edge, connect_edge):\n",
    "    if target_edge not in missing_edge_connection:\n",
    "        missing_edge_connection[target_edge] = []\n",
    "        missing_edge_connection[target_edge].append(connect_edge)\n",
    "    else:\n",
    "        if connect_edge not in missing_edge_connection[target_edge]:\n",
    "            missing_edge_connection[target_edge].append(connect_edge)\n",
    "    return(missing_edge_connection)\n",
    "            \n",
    "for c in net_root.findall('connection'):\n",
    "    edge1 = c.attrib['from']\n",
    "    edge2 = c.attrib['to']\n",
    "    #print(edge1, edge2)\n",
    "    \n",
    "    if edge1 in edges_missing_tazs:\n",
    "        #print(edge1)\n",
    "        missing_edge_connection = assign_val(missing_edge_connection,\n",
    "                                             edge1, edge2)\n",
    "    elif edge2 in edges_missing_tazs:\n",
    "        #print(edge2)\n",
    "        missing_edge_connection = assign_val(missing_edge_connection,\n",
    "                                            edge2, edge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6329\n",
      "6329\n"
     ]
    }
   ],
   "source": [
    "#print(len(list(missing_edge_connection.keys())))\n",
    "#print(len(edges_missing_tazs))\n",
    "#previous return = 6329 (both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 576\n"
     ]
    }
   ],
   "source": [
    "def convert2taz(connect_edges):\n",
    "    connect_taz = []\n",
    "    for edge in connect_edges:\n",
    "        if edge in edge_taz_dict:\n",
    "            connect_taz.append(edge_taz_dict[edge])\n",
    "    include_taz = np.unique(connect_taz)\n",
    "    taz_ct = []\n",
    "    for taz in include_taz:\n",
    "        taz_ct.append(connect_taz.count(taz))\n",
    "    try:\n",
    "        return(include_taz[taz_ct.index(max(taz_ct))])\n",
    "    except:\n",
    "        return(-1)\n",
    "\n",
    "#for edges in missing_edge_connection:\n",
    "print('test', convert2taz(missing_edge_connection['165086027#0']))\n",
    "\n",
    "missing_edge_taz = {}\n",
    "for edge in missing_edge_connection:\n",
    "    missing_edge_taz[edge] = convert2taz(missing_edge_connection[edge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get edge with no taz mapped\n",
    "edges_ = []\n",
    "index_ = 0\n",
    "for i in list(missing_edge_taz.values()):\n",
    "    if i == -1:\n",
    "        edges_.append(list(missing_edge_taz.keys())[index_])\n",
    "    index_ += 1\n",
    "    \n",
    "for edge in missing_edge_taz:\n",
    "    taz_val = missing_edge_taz[edge]\n",
    "    if taz_val != -1:\n",
    "        if edge not in edge_taz_dict:\n",
    "            edge_taz_dict[edge] = taz_val\n",
    "        else:\n",
    "            print('edge in taz already', edge)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "':cluster_gneJ449_gneJ451_1_1'[:-1]\n",
    "':cluster_gneJ449_gneJ451_1_1'[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check '_' in lanes and edges\n",
    "for i in edge_net_lst:\n",
    "    if i[-2] == '_':\n",
    "        pass\n",
    "    if i[-3] == '_':\n",
    "        pass\n",
    "    if i[-4] == '_':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a_w3'[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':cluster_gneJ449_gneJ451_1'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "':cluster_gneJ449_gneJ451_1_1'[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_str(lane_str):\n",
    "    if len(lane_str) != 0:\n",
    "        return(lane_str.split(' '))\n",
    "    else:\n",
    "        return('1')\n",
    "    \n",
    "def get_edge(int_inc_lane, edge_net_lst):\n",
    "    edge_cur = []\n",
    "    for l in int_inc_lane:\n",
    "        if l != '1':\n",
    "            if l[-2] == '_':\n",
    "                if l[:-2] in edge_net_lst:\n",
    "                    edge_cur.append(l[:-2])\n",
    "            if l[-3] == '_':\n",
    "                if l[:-3] in edge_net_lst:\n",
    "                    if l[:-3] not in edge_cur:\n",
    "                        edge_cur.append(l[:-3])\n",
    "    return(edge_cur)\n",
    "\n",
    "def get_taz(edge, edge_taz_dict):\n",
    "    try:\n",
    "        return(edge_taz_dict[edge])\n",
    "    except:\n",
    "        return(0)\n",
    "    \n",
    "def assign_edge_val(edge_cur, junctionid, edge_taz_dict):\n",
    "    edge_val = []\n",
    "    for edge in edge_cur:\n",
    "        val = get_taz(edge, edge_taz_dict)\n",
    "        if val == 0:\n",
    "            pass\n",
    "        else:\n",
    "            edge_val.append(val)\n",
    "    edge_val.append(junctionid)\n",
    "    return(edge_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "':cluster_gneJ449_gneJ451_1' in missing_edge_junc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1487\n"
     ]
    }
   ],
   "source": [
    "#get junction\n",
    "missing_edge_junc = {}\n",
    "#index_ = 0\n",
    "for junc in net_root.findall('junction'):\n",
    "    #print(index_)\n",
    "    int_lane = junc.attrib['intLanes']\n",
    "    inc_lane = junc.attrib['incLanes']\n",
    "    junctionid = junc.attrib['id']\n",
    "\n",
    "    int_inc_lane = []\n",
    "    int_inc_lane.extend(sep_str(int_lane))\n",
    "    int_inc_lane.extend(sep_str(inc_lane))\n",
    "    #print(int_inc_lane)\n",
    "    if len(int_inc_lane) != 0:\n",
    "        edge_cur = get_edge(int_inc_lane, edge_net_lst)\n",
    "    for edge in edge_cur:\n",
    "        if edge in edges_:\n",
    "            if edge not in missing_edge_junc:\n",
    "                missing_edge_junc[edge] = assign_edge_val(edge_cur, \n",
    "                                                          junctionid, \n",
    "                                                          edge_taz_dict)            \n",
    "\n",
    "print(len(missing_edge_junc))\n",
    "selected_junc = list(missing_edge_junc.values())\n",
    "\n",
    "index_ = 0\n",
    "for edge in missing_edge_junc:\n",
    "    tazs = missing_edge_junc[edge][:-1]\n",
    "    #print(tazs)\n",
    "    taz_ct = []\n",
    "    unique_taz = np.unique(tazs)\n",
    "    #print(unique_taz)\n",
    "    for taz in unique_taz:\n",
    "        taz_ct.append(tazs.count(taz))\n",
    "    #print(taz_ct)\n",
    "    try:\n",
    "        taz_ = unique_taz[taz_ct.index(max(taz_ct))]\n",
    "    except:\n",
    "        taz_ = -1\n",
    "    #print(taz_)\n",
    "    if edge not in edge_taz_dict and taz_!=-1:\n",
    "        edge_taz_dict[edge] = taz_\n",
    "    elif taz_ == -1:\n",
    "        print(edge)\n",
    "#through the check, we assign 629 to the missing edges\n",
    "#edge_taz_dict[':53217375_5'] = '629'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'542'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_taz_dict[':cluster_gneJ449_gneJ451_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fcd data processing (ground truth with taz assigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'506'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_taz_dict[lane_dict['460423550#0_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get total taz in sumo network\n",
    "taz_lst = []\n",
    "for taz in taz_root.findall('taz'):\n",
    "    taz_lst.append(taz.attrib['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_dt(fcd_outputpath, data_path, lane_dict, edge_taz_dict):\n",
    "    #use the fcd output to check the data\n",
    "\n",
    "fcd_outputpath = 'fcd_output_5.xml'\n",
    "write_line = ''\n",
    "with open ('fcd_data_5.csv', 'w') as f:\n",
    "    for t in root.findall('timestep'):\n",
    "        time_cur = t.attrib['time']\n",
    "        #print(time_cur)\n",
    "        #get lane id from vehicle\n",
    "        for veh in t.findall('vehicle'):\n",
    "            vehid = veh.attrib['id']\n",
    "            #print(vehid)\n",
    "            lane_id_cur = veh.attrib['lane']\n",
    "            taz_id = edge_taz_dict[lane_dict[lane_id_cur]]\n",
    "            write_line = vehid+','+taz_id+','+time_cur+'\\n'\n",
    "            f.write(write_line)\n",
    "        try:    \n",
    "            for per in t.findall('person'):\n",
    "                \n",
    "                perid = per.attrib['id']\n",
    "                #print(perid)\n",
    "                edge_id_cur = per.attrib['edge']\n",
    "                taz_id = edge_taz_dict[edge_id_cur]\n",
    "                write_line = perid+','+taz_id+','+time_cur+'\\n'\n",
    "                f.write(write_line)\n",
    "        except: \n",
    "            pass\n",
    "f.close()\n",
    "print('data output done')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_dt(fcd_outputpath, data_path, lane_dict, edge_taz_dict):\n",
    "    #use the fcd output to check the data\n",
    "#using 30 sec as an example\n",
    "fcd_outputpath = 'fcd_output_5_30sec.xml'\n",
    "write_line = ''\n",
    "\n",
    "tree = ET.parse(fcd_outputpath)\n",
    "root = tree.getroot()\n",
    "with open ('fcd_data_5_30sec.csv', 'w') as f:\n",
    "    for t in root.findall('timestep'):\n",
    "        time_cur = t.attrib['time']\n",
    "        #print(time_cur)\n",
    "        #get lane id from vehicle\n",
    "        for veh in t.findall('vehicle'):\n",
    "            vehid = veh.attrib['id']\n",
    "            #print(vehid)\n",
    "            lane_id_cur = veh.attrib['lane']\n",
    "            taz_id = edge_taz_dict[lane_dict[lane_id_cur]]\n",
    "            write_line = vehid+','+taz_id+','+time_cur+'\\n'\n",
    "            f.write(write_line)\n",
    "        try:    \n",
    "            for per in t.findall('person'):\n",
    "                perid = per.attrib['id']\n",
    "                #print(perid)\n",
    "                edge_id_cur = per.attrib['edge']\n",
    "                taz_id = edge_taz_dict[edge_id_cur]\n",
    "                write_line = perid+','+taz_id+','+time_cur+'\\n'\n",
    "                f.write(write_line)\n",
    "        except: \n",
    "            pass\n",
    "f.close()\n",
    "print('data output done')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcd_dt_path = 'fcd_data_5.csv'\n",
    "#convert dt to matrix\n",
    "def convert2mx(csv_path, savepath, save_index=False):\n",
    "    fcd_out = pd.read_csv(fcd_dt_path, header=None)\n",
    "    fcd_out.columns = ['id', 'taz', 'time']\n",
    "    fcd_out.taz = fcd_out.taz.astype('int')\n",
    "    fcd_out.time = fcd_out.time.astype('int')\n",
    "    print('num id', len(np.unique(fcd_out.id)))\n",
    "\n",
    "    #fcd_out.sort_values(by=['time', 'taz'])\n",
    "    fcd_out['tl_id'] = fcd_out['taz'].astype(str)+'_'+((fcd_out['time']/300).astype(int)).astype(str)\n",
    "\n",
    "    fcd_out = fcd_out[~fcd_out['time'].isin([86400, 86700])]\n",
    "    time_ = np.unique((fcd_out['time']/300).astype(int))\n",
    "    newuser_ = {}\n",
    "    index_ = 0\n",
    "    for i in np.unique(fcd_out.id):\n",
    "        newuser_[i] = index_\n",
    "        index_ += 1\n",
    "\n",
    "    loc_time = {}\n",
    "    index_ = 0\n",
    "    taz_ = np.unique(fcd_out['taz'])\n",
    "    time_ = np.unique((fcd_out['time']/300).astype(int))\n",
    "    for taz in taz_:\n",
    "        for t in time_:\n",
    "            loc_time[str(taz)+'_'+str(t)] = index_\n",
    "            index_ += 1\n",
    "\n",
    "    origin_dt = np.zeros((len(newuser_), len(loc_time)))\n",
    "    ids_ = fcd_out['id'].values\n",
    "    tl_id_ = fcd_out['tl_id'].values\n",
    "    for i in range(len(ids_)):\n",
    "        origin_dt[newuser_[ids_[i]]][loc_time[tl_id_[i]]] = 1\n",
    "    if save_index == True:\n",
    "        pd.DataFrame(origin_dt).to_csv(savepath)\n",
    "    else:\n",
    "        return(origin_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39286"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edge_net_lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
