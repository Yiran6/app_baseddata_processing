{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorly\n",
    "\n",
    "#imported packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker\n",
    "import math\n",
    "from scipy import stats\n",
    "import csv\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib\n",
    "from sklearn.metrics import mean_squared_error as rmse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defined functions\n",
    "#data column methods\n",
    "\n",
    "#convert data to array\n",
    "def getseqid(targetval):\n",
    "    #convert taz idx\n",
    "    targetidx = {}\n",
    "    idxtarget = {}\n",
    "    idx = 0\n",
    "    for i in targetval:\n",
    "        targetidx[i] = idx        \n",
    "        idxtarget[idx] = i\n",
    "        idx += 1\n",
    "    return(targetidx, idxtarget)\n",
    "\n",
    "def data2arr(datapath, binaryidx=True, to2d=True):\n",
    "    taz2idx = lambda x: tazidx[x]\n",
    "    str2time = lambda x: int(int(x.split(':')[0])*12 + int(x.split(':')[1])/5)\n",
    "    timelen = 24*12 #with 5-min interval\n",
    "    newid2idx = lambda x: newididx[x]\n",
    "    \n",
    "    datapath = raw_dt_path[0]\n",
    "    dt = pd.read_csv(datapath)\n",
    "    \n",
    "    #convert time and location\n",
    "    tazidx, idxtaz = getseqid(np.unique(dt['taz']))\n",
    "    dt['tazidx'] = dt['taz'].apply(taz2idx)\n",
    "    dt['timeidx'] = dt['time'].apply(str2time)\n",
    "\n",
    "    newididx, idxnewid = getseqid(np.unique(dt['newid']))\n",
    "    dt['newididx'] = dt['newid'].apply(newid2idx)\n",
    "    \n",
    "    if to2d == True:\n",
    "        dt['ltidx'] = dt['tazidx']*timelen+dt['timeidx']\n",
    "        nrow = len(newididx)\n",
    "        ncol = timelen * len(tazidx)\n",
    "\n",
    "        arr = np.zeros((nrow, ncol))\n",
    "        dt = dt[['newididx','ltidx', 'sum']].to_numpy()\n",
    "\n",
    "        #assign binary index\n",
    "        for i, j, count in dt:\n",
    "            if binaryidx == True:\n",
    "                arr[i, j] = 1\n",
    "            else:\n",
    "                arr[i, j] = count\n",
    "        return(arr)\n",
    "    else:\n",
    "        nrow = len(newididx)\n",
    "        ntaz = len(tazidx)\n",
    "        ntime = timelen\n",
    "        \n",
    "        arr = np.zeros((nrow, ntaz, ntime))\n",
    "        dt = dt[['newididx', 'tazidx', 'timeidx', 'sum']].to_numpy()\n",
    "        \n",
    "        for i, j, k, count in dt:\n",
    "            if binaryidx == True:\n",
    "                arr[i, j, k] = 1\n",
    "            else:\n",
    "                arr[i, j, k] = sum\n",
    "        return(arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the fcd data\n",
    "path = \"G:/My Drive/2021/Bias/sumo_simulation/\"\n",
    "#os.listdir()\n",
    "\n",
    "raw_dt_path = []\n",
    "for i in os.listdir(path):\n",
    "    if len(i) == 12 and '2017' in i:\n",
    "        raw_dt_path.append(path+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = data2arr(raw_dt_path[0], to2d=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "rank_individuals = 10\n",
    "rank_locations = 10\n",
    "rank_times = 12\n",
    "\n",
    "core, factors = tucker(arr, rank=[rank_individuals, rank_locations, rank_times])\n",
    "endtime = time.time()\n",
    "print(f'running time {endtime-starttime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data = tl.tucker_to_tensor((core, factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(arr, reconstructed_data, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tucker() got an unexpected keyword argument 'ranks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m rank_times \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m       \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Perform Tucker decomposition\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m core, factors \u001b[38;5;241m=\u001b[39m \u001b[43mtucker\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mrank_individuals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank_times\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: tucker() got an unexpected keyword argument 'ranks'"
     ]
    }
   ],
   "source": [
    "# Specify the desired rank for each mode (individuals, locations, times)\n",
    "rank_individuals = 5  # Adjust as needed\n",
    "rank_locations = 5   # Adjust as needed\n",
    "rank_times = 5       # Adjust as needed\n",
    "\n",
    "# Perform Tucker decomposition\n",
    "core, factors = tucker(arr, ranks=[rank_individuals, rank_locations, rank_times])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
