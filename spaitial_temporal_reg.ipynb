{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import csv\n",
    "#import pandasql as ps\n",
    "import matplotlib.pyplot as plt\n",
    "import shapefile as shp\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import pysal as ps\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import statistics\n",
    "\n",
    "#temporal pattern clustering\n",
    "from tslearn.clustering import TimeSeriesKMeans, silhouette_score\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from sklearn import metrics\n",
    "\n",
    "from dtaidistance import dtw\n",
    "from dtaidistance import dtw_visualisation as dtwvis\n",
    "\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "#regression model\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from pysal.model import spreg\n",
    "from pysal.lib import weights\n",
    "from pysal.explore import esda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ = 'G:/My Drive/2020/Bias/data-processing'\n",
    "os.chdir(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get geoid with demo\n",
    "#data processing\n",
    "#demo and urban info for entire psrc\n",
    "demo_reg = pd.read_csv('demo_reg_df.csv')\n",
    "\n",
    "#obs info in Seattle\n",
    "obs_Seattle = pd.read_csv('obs_Seattle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seattle_geo = np.unique(obs_Seattle['GEOID10'])\n",
    "demo_reg = demo_reg[demo_reg['GEOID10'].isin(Seattle_geo)]\n",
    "\n",
    "geoids = []\n",
    "for geoid in Seattle_geo:\n",
    "    geoids.append(str(geoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select spatial features\n",
    "#Notice that downtown Seattle only has urban area\n",
    "st_reg = demo_reg[['GEOID10', 'INTPTLAT10','INTPTLON10','total','Urban']]\n",
    "\n",
    "#read the cb geo data\n",
    "path_ = 'spatial_check/'\n",
    "os.chdir(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(demo_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seattle_st_cb = gpd.read_file('Seattle_ct_spatial_features.shp')\n",
    "Seattle_busstop_cb = gpd.read_file('transit_stop.shp')\n",
    "Seattle_sidewalk_cb = gpd.read_file('Seattle_ct_spatial_features_sidewalks.shp')\n",
    "Seattle_bus_cb = gpd.read_file('Seattle_ct_spatial_features_transit_rt.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seattle_zone(dt_file, geoids):\n",
    "    return(dt_file[dt_file['GEOID10'].isin(geoids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seattle_st_cb = get_seattle_zone(Seattle_st_cb, geoids)\n",
    "Seattle_busstop_cb = get_seattle_zone(Seattle_busstop_cb, geoids)\n",
    "Seattle_sidewalk_cb = get_seattle_zone(Seattle_sidewalk_cb, geoids)\n",
    "Seattle_bus_cb = get_seattle_zone(Seattle_bus_cb, geoids)\n",
    "\n",
    "Seattle_st_cb = Seattle_st_cb[['GEOID10', 'ARTCLASS', 'STREETTYPE', 'ARTDESCRIP']]\n",
    "Seattle_busstop_cb = Seattle_busstop_cb[['OBJECTID', 'STOP_ID', 'STOP_TYPE', 'GEOID10']]\n",
    "Seattle_sidewalk_cb = Seattle_sidewalk_cb[['CONDITION','GEOID10']]\n",
    "Seattle_bus_cb = Seattle_bus_cb[['ROUTE_NUM', 'GEOID10']]\n",
    "\n",
    "geoids = sorted(geoids)\n",
    "st_class = sorted(st_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Designated'], dtype=object)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Seattle_st_cb['ARTDESCRIP'][Seattle_st_cb['ARTCLASS']==0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data handling\n",
    "def get_data(dt, by_col, geoids):\n",
    "    a = dt.groupby(by=by_col).size().to_frame()\n",
    "    a.reset_index(inplace=True)\n",
    "    \n",
    "    b = a.groupby(by=by_col[0]).sum()\n",
    "    b.reset_index(inplace=True)\n",
    "    \n",
    "    col_class = np.unique(a[by_col[1]])\n",
    "\n",
    "    num_st_class = np.zeros((len(geoids), len(col_class)))\n",
    "\n",
    "    geoid_row = {}\n",
    "    para_col = {}\n",
    "\n",
    "    index_ = 0\n",
    "    for i in geoids:\n",
    "        geoid_row[i] = index_\n",
    "        index_ += 1\n",
    "    index_ = 0\n",
    "    for j in col_class:\n",
    "        para_col[j] = index_\n",
    "        index_ += 1\n",
    "\n",
    "    for i in range(len(a.index)):\n",
    "        row_ = geoid_row[a[by_col[0]].loc[i]]\n",
    "        col_ = para_col[a[by_col[1]].loc[i]]\n",
    "        val_ = a[0].loc[i]\n",
    "        #print(row_, col_, val_, i)\n",
    "        num_st_class[row_][col_] = val_\n",
    "        \n",
    "    col_name = list(para_col.keys())\n",
    "    col_name.append(by_col[1]+'_sum')\n",
    "        \n",
    "    return(np.c_[(num_st_class), b[0].values], col_name)\n",
    "\n",
    "#street data\n",
    "st_dt, st_name = get_data(Seattle_st_cb, ['GEOID10','ARTCLASS'], geoids)\n",
    "#bus stop\n",
    "bus_dt, bus_name = get_data(Seattle_busstop_cb, ['GEOID10', 'STOP_TYPE'], geoids)\n",
    "#sidewalk\n",
    "walk_dt, walk_name = get_data(Seattle_sidewalk_cb, ['GEOID10', 'CONDITION'], geoids)\n",
    "#bus route\n",
    "a = Seattle_bus_cb.groupby(by=['GEOID10','ROUTE_NUM']).size().to_frame()\n",
    "a.reset_index(inplace=True)\n",
    "a['ROUTE_NUM'] = a['ROUTE_NUM'].astype(str)\n",
    "\n",
    "num_route = []\n",
    "for geoid in geoids:\n",
    "    num_route.append(len(np.unique(a['ROUTE_NUM'][a['GEOID10'] == geoid].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs_Seattle\n",
    "def add_col(ori_dt, add_dt, col_name):\n",
    "    a = ori_dt.copy()\n",
    "    for i in range(len(col_name)):\n",
    "        a[col_name[i]] = add_dt[:, i]\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dt = add_col(st_reg, st_dt, st_name)\n",
    "test_dt = add_col(test_dt, bus_dt, bus_name)\n",
    "test_dt = add_col(test_dt, walk_dt, walk_name)\n",
    "test_dt['route_num'] = num_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling data index\n",
    "hr = [0] * 7\n",
    "hr.extend([1]*4)\n",
    "hr.extend([2]*5)\n",
    "hr.extend([3]*4)\n",
    "hr.extend([0]*4)\n",
    "\n",
    "set_hr_index = lambda x: hr[x]\n",
    "obs_Seattle['hr_index'] = obs_Seattle['hr'].apply(set_hr_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_hr = obs_Seattle[['GEOID10', 'hr_index', 'obs']].groupby(by=['GEOID10', 'hr_index']).sum()\n",
    "obs_hr.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'G:/My Drive/2021/Bias/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_hr.to_csv(path + 'obs_hr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_hr.set_index('GEOID10', inplace=True)\n",
    "test_dt.set_index('GEOID10', inplace=True)\n",
    "\n",
    "merge_df = pd.merge(obs_hr, test_dt, left_index=True, right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.to_csv(path+'spatial_temp_reg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
