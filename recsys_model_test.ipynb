{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29700\\anaconda3\\envs\\modeltest\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-22 11:16:02,508\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-04-22 11:16:02,809\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from recbole.quick_start import run_recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sequential recommendation parameter guidance](https://recbole.io/docs/get_started/started/sequential.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20170404.csv',\n",
       " '20170405.csv',\n",
       " '20170406.csv',\n",
       " '20170411.csv',\n",
       " '20170412.csv',\n",
       " '20170413.csv',\n",
       " '20170418.csv',\n",
       " '20170419.csv',\n",
       " '20170420.csv',\n",
       " '20170426.csv',\n",
       " '20170427.csv',\n",
       " '20170425.csv']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"G:/My Drive/2021/Bias/sumo_simulation/\"\n",
    "os.chdir(path)\n",
    "\n",
    "#get obs data matrix\n",
    "data_path_lst = []\n",
    "for i in os.listdir():\n",
    "    if len(i) == 12 and '.csv' in i:\n",
    "        data_path_lst.append(i)\n",
    "data_path_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference source: https://www.kaggle.com/code/astrung/recbole-lstm-sequential-for-recomendation-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convet data to recbole data format\n",
    "test_dt = pd.read_csv(data_path_lst[0])\n",
    "\n",
    "#convert time info to timestamp\n",
    "timestep_convert = lambda x: time.mktime(datetime.datetime.strptime(('2017_4_'+x[:-4]),\n",
    "                                                                    \"%Y_%m_%d_%H_%M\").timetuple())\n",
    "test_dt['date_time'] = test_dt['key'].apply(timestep_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newid</th>\n",
       "      <th>sum</th>\n",
       "      <th>key</th>\n",
       "      <th>taz</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4_3_55_608</td>\n",
       "      <td>608</td>\n",
       "      <td>4</td>\n",
       "      <td>3:55</td>\n",
       "      <td>1.491303e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>4_4_5_615</td>\n",
       "      <td>615</td>\n",
       "      <td>4</td>\n",
       "      <td>4:05</td>\n",
       "      <td>1.491304e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4_3_40_578</td>\n",
       "      <td>578</td>\n",
       "      <td>4</td>\n",
       "      <td>3:40</td>\n",
       "      <td>1.491302e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   newid  sum         key  taz  date  time     date_time\n",
       "0     26    1  4_3_55_608  608     4  3:55  1.491303e+09\n",
       "1     26    2   4_4_5_615  615     4  4:05  1.491304e+09\n",
       "2     26    1  4_3_40_578  578     4  3:40  1.491302e+09"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dt[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_dt[['newid','taz','date_time']].rename(columns={'newid': 'user_id:token', \n",
    "                                                     'taz': 'item_id:token', \n",
    "                                                     'date_time': 'timestamp:float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>timestamp:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>608</td>\n",
       "      <td>1.491303e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>615</td>\n",
       "      <td>1.491304e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>578</td>\n",
       "      <td>1.491302e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>627</td>\n",
       "      <td>1.491302e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>502</td>\n",
       "      <td>1.491331e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227191</th>\n",
       "      <td>458481</td>\n",
       "      <td>567</td>\n",
       "      <td>1.491372e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227192</th>\n",
       "      <td>458481</td>\n",
       "      <td>566</td>\n",
       "      <td>1.491372e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227193</th>\n",
       "      <td>458481</td>\n",
       "      <td>431</td>\n",
       "      <td>1.491372e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227194</th>\n",
       "      <td>458481</td>\n",
       "      <td>550</td>\n",
       "      <td>1.491373e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227195</th>\n",
       "      <td>458481</td>\n",
       "      <td>497</td>\n",
       "      <td>1.491373e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id:token  item_id:token  timestamp:float\n",
       "0                  26            608     1.491303e+09\n",
       "1                  26            615     1.491304e+09\n",
       "2                  26            578     1.491302e+09\n",
       "3                  26            627     1.491302e+09\n",
       "4                  32            502     1.491331e+09\n",
       "...               ...            ...              ...\n",
       "227191         458481            567     1.491372e+09\n",
       "227192         458481            566     1.491372e+09\n",
       "227193         458481            431     1.491372e+09\n",
       "227194         458481            550     1.491373e+09\n",
       "227195         458481            497     1.491373e+09\n",
       "\n",
       "[227196 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.to_csv('recbox_data/recbox_data.inter', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.sequential_recommender import GRU4Rec\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MatSumo-main.zip',\n",
       " 'MatSumo-main',\n",
       " 'obsmx04042017.csv',\n",
       " 'obsmx04052017.csv',\n",
       " 'obsmx04062017.csv',\n",
       " 'obsmx04112017.csv',\n",
       " 'obsmx04122017.csv',\n",
       " 'obsmx04132017.csv',\n",
       " 'obsmx04182017.csv',\n",
       " 'obsmx04192017.csv',\n",
       " 'obsmx04202017.csv',\n",
       " 'obsmx04252017.csv',\n",
       " 'obsmx04262017.csv',\n",
       " 'obsmx04272017.csv',\n",
       " 'newid_file.txt',\n",
       " 'newid_tsid_aggregation.txt',\n",
       " 'MatSim_userguide.pdf',\n",
       " 'obs_matrix_sum.csv',\n",
       " 'Seattle_network.osm.pbf',\n",
       " 'matsim-example-project',\n",
       " 'matsim-episim-example-project',\n",
       " 'matsim-code-examples',\n",
       " 'model_results.csv',\n",
       " 'svd.txt',\n",
       " 'model_results_nmf_larger10.csv',\n",
       " 'model_results_nmf_larger5.csv',\n",
       " 'indi_meeting.pptx',\n",
       " '~$sumo_sim.pptx',\n",
       " 'obs_matrixbyday.csv',\n",
       " 'WH_obs_2000601.csv',\n",
       " 'nmf_est_result_0405obs.csv',\n",
       " 'obs_byday_model_results.csv',\n",
       " 'modelpredresults78010103.csv',\n",
       " 'modelpredresults78010100.csv',\n",
       " 'laltontaz04042017.csv',\n",
       " 'lalton04042017.csv',\n",
       " 'latlon04042017.csv',\n",
       " 'latlontaz04042017.csv',\n",
       " 'latlon04052017.csv',\n",
       " 'latlontaz04052017.csv',\n",
       " 'latlon04062017.csv',\n",
       " 'latlontaz04062017.csv',\n",
       " 'latlon04112017.csv',\n",
       " 'latlontaz04112017.csv',\n",
       " 'latlon04122017.csv',\n",
       " 'latlontaz04122017.csv',\n",
       " 'latlon04132017.csv',\n",
       " 'latlontaz04132017.csv',\n",
       " 'latlon04182017.csv',\n",
       " 'latlontaz04182017.csv',\n",
       " 'latlontaz04272017.csv',\n",
       " 'latlon04272017.csv',\n",
       " 'latlontaz04262017.csv',\n",
       " 'latlon04262017.csv',\n",
       " 'latlontaz04252017.csv',\n",
       " 'latlon04252017.csv',\n",
       " 'latlontaz04202017.csv',\n",
       " 'latlon04202017.csv',\n",
       " 'latlontaz04192017.csv',\n",
       " 'latlon04192017.csv',\n",
       " 'output.csv',\n",
       " 'line_example.shp',\n",
       " 'line_example.dbf',\n",
       " 'line_example.cpg',\n",
       " 'Assessing Urban Travel Patterns-An Analysis of Traffic Analysis Zone-Based Mobility Patterns.pdf',\n",
       " 'obsmxtaz04042017.csv',\n",
       " 'obsmxtaz04052017.csv',\n",
       " 'obsmxtaz04062017.csv',\n",
       " 'obsmxtaz04112017.csv',\n",
       " 'obsmxtaz04272017.csv',\n",
       " 'obsmxtaz04262017.csv',\n",
       " 'obsmxtaz04252017.csv',\n",
       " 'obsmxtaz04202017.csv',\n",
       " 'obsmxtaz04192017.csv',\n",
       " 'obsmxtaz04182017.csv',\n",
       " 'obsmxtaz04132017.csv',\n",
       " 'obsmxtaz04122017.csv',\n",
       " 'cache',\n",
       " 'route_fileTAZ04042017.csv',\n",
       " '~$indi_meeting.pptx',\n",
       " 'route_fileTAZ04052017.csv',\n",
       " 'route_fileTAZ04062017.csv',\n",
       " 'route_fileTAZ04112017.csv',\n",
       " 'large-scale traffic flow using markov model.pdf',\n",
       " 'learning random MCMC.pdf',\n",
       " 'zone_trajcetory_based.pdf',\n",
       " 'Congestion_Pattern_Prediction_for_a_Busy_Traffic_Zone_Based_on_the_Hidden_Markov_Model.pdf',\n",
       " 'Research on the Collision Avoidance Algorithm for Fixed-Wing UAVs Based on Maneuver Coordination and Planned Trajectories Prediction.pdf',\n",
       " 'Bike zone prediction.pdf',\n",
       " 'recsys_sparse_matrix_svd.pdf',\n",
       " 'Modeling relationships at multiple scales to improve accuracy of large recommender systems.pdf',\n",
       " 'hybrid ae in recsys.pdf',\n",
       " 'trust management.pdf',\n",
       " 'Using_Viewing_Time_to_Infer_User_Preference_in_Recommender_Systems.pdf',\n",
       " 'Matrix_Factorization_Techniques_for_Recommender_Systems.pdf',\n",
       " 'Fast_and_Accurate_Non-negative_Latent_Factor_Analysis_on_High-dimensional_and_Sparse_Matrices_in_Recommender_Systems.pdf',\n",
       " 'spatial temporal recsys.pdf',\n",
       " 'zone_traj_check_ct_5min_04042017.txt',\n",
       " 'zone_traj_check_ct_5min_04042017.csv',\n",
       " 'appsim',\n",
       " '20170404.csv',\n",
       " 'sparse data trajectory.pdf',\n",
       " 'taz_not_in_test_area_app_based_dt.qgz',\n",
       " '20170405.csv',\n",
       " '20170406.csv',\n",
       " '20170411.csv',\n",
       " '20170412.csv',\n",
       " '20170413.csv',\n",
       " '20170418.csv',\n",
       " '20170419.csv',\n",
       " '20170420.csv',\n",
       " '20170426.csv',\n",
       " '20170427.csv',\n",
       " '20170425.csv',\n",
       " 'warp.png',\n",
       " 'SUMO_2024_v2_YZ.docx',\n",
       " 'sim_result_01.csv',\n",
       " 'sim_result_taz.csv',\n",
       " 'sim_result_ts.csv',\n",
       " 'recbox_data']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../SUMO_simulation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "    'data_path': '../SUMO_simulation/',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'load_col': {'inter': ['user_id', 'item_id', 'timestamp']},\n",
    "    'TEM_LIST_LENGTH_FIELD':2,\n",
    "    'neg_sampling':None,\n",
    "    'train_neg_sample_args': None,\n",
    "    'epochs': 50\n",
    "}\n",
    "\n",
    "config =  Config(model='GRU4Rec', dataset='recbox_data', config_dict=parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed(config['seed'], config['reproducibility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22 Apr 16:57    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../SUMO_simulation/recbox_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "TEM_LIST_LENGTH_FIELD = 2\n",
      "neg_sampling = None\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../SUMO_simulation/recbox_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "TEM_LIST_LENGTH_FIELD = 2\n",
      "neg_sampling = None\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22 Apr 16:57    INFO  recbox_data\n",
      "The number of users: 13710\n",
      "Average actions of users: 16.57276241884893\n",
      "The number of items: 168\n",
      "Average actions of items: 1360.4550898203593\n",
      "The number of inters: 227196\n",
      "The sparsity of the dataset: 90.13597999374805%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "recbox_data\n",
      "The number of users: 13710\n",
      "Average actions of users: 16.57276241884893\n",
      "The number of items: 168\n",
      "Average actions of items: 1360.4550898203593\n",
      "The number of inters: 227196\n",
      "The sparsity of the dataset: 90.13597999374805%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "logger.info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22 Apr 16:58    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "22 Apr 16:58    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22 Apr 16:58    INFO  GRU4Rec(\n",
      "  (item_embedding): Embedding(168, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 92736\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(168, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 92736\n",
      "22 Apr 17:02    INFO  epoch 0 training [time: 248.45s, train loss: 379.8291]\n",
      "epoch 0 training [time: 248.45s, train loss: 379.8291]\n",
      "22 Apr 17:02    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 17:06    INFO  epoch 1 training [time: 253.95s, train loss: 236.9083]\n",
      "epoch 1 training [time: 253.95s, train loss: 236.9083]\n",
      "22 Apr 17:06    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 17:11    INFO  epoch 2 training [time: 252.30s, train loss: 215.9556]\n",
      "epoch 2 training [time: 252.30s, train loss: 215.9556]\n",
      "22 Apr 17:11    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 17:15    INFO  epoch 3 training [time: 253.33s, train loss: 209.6606]\n",
      "epoch 3 training [time: 253.33s, train loss: 209.6606]\n",
      "22 Apr 17:15    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 17:19    INFO  epoch 4 training [time: 254.04s, train loss: 205.7469]\n",
      "epoch 4 training [time: 254.04s, train loss: 205.7469]\n",
      "22 Apr 17:19    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 17:23    INFO  epoch 5 training [time: 246.66s, train loss: 203.4689]\n",
      "epoch 5 training [time: 246.66s, train loss: 203.4689]\n",
      "22 Apr 17:23    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 17:27    INFO  epoch 6 training [time: 248.70s, train loss: 202.0379]\n",
      "epoch 6 training [time: 248.70s, train loss: 202.0379]\n",
      "22 Apr 17:27    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 17:31    INFO  epoch 7 training [time: 246.19s, train loss: 200.7600]\n",
      "epoch 7 training [time: 246.19s, train loss: 200.7600]\n",
      "22 Apr 17:31    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 17:35    INFO  epoch 8 training [time: 245.05s, train loss: 199.6475]\n",
      "epoch 8 training [time: 245.05s, train loss: 199.6475]\n",
      "22 Apr 17:35    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 17:40    INFO  epoch 9 training [time: 249.73s, train loss: 198.7331]\n",
      "epoch 9 training [time: 249.73s, train loss: 198.7331]\n",
      "22 Apr 17:40    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:07    INFO  epoch 10 training [time: 8855.14s, train loss: 198.3637]\n",
      "epoch 10 training [time: 8855.14s, train loss: 198.3637]\n",
      "22 Apr 20:07    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:11    INFO  epoch 11 training [time: 248.84s, train loss: 197.4176]\n",
      "epoch 11 training [time: 248.84s, train loss: 197.4176]\n",
      "22 Apr 20:11    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:15    INFO  epoch 12 training [time: 242.75s, train loss: 196.1224]\n",
      "epoch 12 training [time: 242.75s, train loss: 196.1224]\n",
      "22 Apr 20:15    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:20    INFO  epoch 13 training [time: 299.71s, train loss: 195.8127]\n",
      "epoch 13 training [time: 299.71s, train loss: 195.8127]\n",
      "22 Apr 20:20    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:25    INFO  epoch 14 training [time: 270.71s, train loss: 195.8468]\n",
      "epoch 14 training [time: 270.71s, train loss: 195.8468]\n",
      "22 Apr 20:25    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:29    INFO  epoch 15 training [time: 252.26s, train loss: 194.7176]\n",
      "epoch 15 training [time: 252.26s, train loss: 194.7176]\n",
      "22 Apr 20:29    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:33    INFO  epoch 16 training [time: 261.14s, train loss: 194.1538]\n",
      "epoch 16 training [time: 261.14s, train loss: 194.1538]\n",
      "22 Apr 20:33    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:38    INFO  epoch 17 training [time: 254.72s, train loss: 193.8165]\n",
      "epoch 17 training [time: 254.72s, train loss: 193.8165]\n",
      "22 Apr 20:38    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:42    INFO  epoch 18 training [time: 256.14s, train loss: 193.2405]\n",
      "epoch 18 training [time: 256.14s, train loss: 193.2405]\n",
      "22 Apr 20:42    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:46    INFO  epoch 19 training [time: 252.66s, train loss: 193.1223]\n",
      "epoch 19 training [time: 252.66s, train loss: 193.1223]\n",
      "22 Apr 20:46    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:50    INFO  epoch 20 training [time: 256.35s, train loss: 192.7971]\n",
      "epoch 20 training [time: 256.35s, train loss: 192.7971]\n",
      "22 Apr 20:50    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:55    INFO  epoch 21 training [time: 249.02s, train loss: 192.2811]\n",
      "epoch 21 training [time: 249.02s, train loss: 192.2811]\n",
      "22 Apr 20:55    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 20:59    INFO  epoch 22 training [time: 253.68s, train loss: 191.9559]\n",
      "epoch 22 training [time: 253.68s, train loss: 191.9559]\n",
      "22 Apr 20:59    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:03    INFO  epoch 23 training [time: 249.26s, train loss: 191.3847]\n",
      "epoch 23 training [time: 249.26s, train loss: 191.3847]\n",
      "22 Apr 21:03    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:07    INFO  epoch 24 training [time: 256.94s, train loss: 191.1863]\n",
      "epoch 24 training [time: 256.94s, train loss: 191.1863]\n",
      "22 Apr 21:07    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:12    INFO  epoch 25 training [time: 257.50s, train loss: 190.6791]\n",
      "epoch 25 training [time: 257.50s, train loss: 190.6791]\n",
      "22 Apr 21:12    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:16    INFO  epoch 26 training [time: 262.63s, train loss: 190.3096]\n",
      "epoch 26 training [time: 262.63s, train loss: 190.3096]\n",
      "22 Apr 21:16    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:20    INFO  epoch 27 training [time: 259.96s, train loss: 189.8798]\n",
      "epoch 27 training [time: 259.96s, train loss: 189.8798]\n",
      "22 Apr 21:20    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:25    INFO  epoch 28 training [time: 270.33s, train loss: 190.1170]\n",
      "epoch 28 training [time: 270.33s, train loss: 190.1170]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22 Apr 21:25    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:29    INFO  epoch 29 training [time: 274.14s, train loss: 189.6485]\n",
      "epoch 29 training [time: 274.14s, train loss: 189.6485]\n",
      "22 Apr 21:29    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:34    INFO  epoch 30 training [time: 265.64s, train loss: 189.4596]\n",
      "epoch 30 training [time: 265.64s, train loss: 189.4596]\n",
      "22 Apr 21:34    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:39    INFO  epoch 31 training [time: 306.44s, train loss: 188.9732]\n",
      "epoch 31 training [time: 306.44s, train loss: 188.9732]\n",
      "22 Apr 21:39    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:45    INFO  epoch 32 training [time: 340.13s, train loss: 188.5656]\n",
      "epoch 32 training [time: 340.13s, train loss: 188.5656]\n",
      "22 Apr 21:45    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:51    INFO  epoch 33 training [time: 373.00s, train loss: 188.2017]\n",
      "epoch 33 training [time: 373.00s, train loss: 188.2017]\n",
      "22 Apr 21:51    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 21:56    INFO  epoch 34 training [time: 301.58s, train loss: 187.9900]\n",
      "epoch 34 training [time: 301.58s, train loss: 187.9900]\n",
      "22 Apr 21:56    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:00    INFO  epoch 35 training [time: 282.90s, train loss: 187.6847]\n",
      "epoch 35 training [time: 282.90s, train loss: 187.6847]\n",
      "22 Apr 22:00    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:05    INFO  epoch 36 training [time: 268.33s, train loss: 187.6114]\n",
      "epoch 36 training [time: 268.33s, train loss: 187.6114]\n",
      "22 Apr 22:05    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:10    INFO  epoch 37 training [time: 291.43s, train loss: 187.2750]\n",
      "epoch 37 training [time: 291.43s, train loss: 187.2750]\n",
      "22 Apr 22:10    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:14    INFO  epoch 38 training [time: 267.37s, train loss: 186.8367]\n",
      "epoch 38 training [time: 267.37s, train loss: 186.8367]\n",
      "22 Apr 22:14    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:19    INFO  epoch 39 training [time: 258.02s, train loss: 186.5022]\n",
      "epoch 39 training [time: 258.02s, train loss: 186.5022]\n",
      "22 Apr 22:19    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:23    INFO  epoch 40 training [time: 248.98s, train loss: 186.3363]\n",
      "epoch 40 training [time: 248.98s, train loss: 186.3363]\n",
      "22 Apr 22:23    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:27    INFO  epoch 41 training [time: 250.24s, train loss: 186.3911]\n",
      "epoch 41 training [time: 250.24s, train loss: 186.3911]\n",
      "22 Apr 22:27    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:32    INFO  epoch 42 training [time: 286.07s, train loss: 186.2599]\n",
      "epoch 42 training [time: 286.07s, train loss: 186.2599]\n",
      "22 Apr 22:32    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:37    INFO  epoch 43 training [time: 300.66s, train loss: 185.9775]\n",
      "epoch 43 training [time: 300.66s, train loss: 185.9775]\n",
      "22 Apr 22:37    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:42    INFO  epoch 44 training [time: 312.89s, train loss: 185.4322]\n",
      "epoch 44 training [time: 312.89s, train loss: 185.4322]\n",
      "22 Apr 22:42    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:47    INFO  epoch 45 training [time: 285.62s, train loss: 185.1195]\n",
      "epoch 45 training [time: 285.62s, train loss: 185.1195]\n",
      "22 Apr 22:47    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:52    INFO  epoch 46 training [time: 307.67s, train loss: 185.0858]\n",
      "epoch 46 training [time: 307.67s, train loss: 185.0858]\n",
      "22 Apr 22:52    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 22:57    INFO  epoch 47 training [time: 312.22s, train loss: 185.1103]\n",
      "epoch 47 training [time: 312.22s, train loss: 185.1103]\n",
      "22 Apr 22:57    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 23:02    INFO  epoch 48 training [time: 323.60s, train loss: 184.8662]\n",
      "epoch 48 training [time: 323.60s, train loss: 184.8662]\n",
      "22 Apr 23:02    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "22 Apr 23:08    INFO  epoch 49 training [time: 315.36s, train loss: 184.5405]\n",
      "epoch 49 training [time: 315.36s, train loss: 184.5405]\n",
      "22 Apr 23:08    INFO  Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n",
      "Saving current: saved\\GRU4Rec-Apr-22-2024_16-58-24.pth\n"
     ]
    }
   ],
   "source": [
    "# model loading and initialization\n",
    "model = GRU4Rec(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer = Trainer(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.utils.case_study import full_sort_topk\n",
    "external_user_ids = dataset.id2token(\n",
    "    dataset.uid_field, list(range(dataset.user_num)))[1:]#fist element in array is 'PAD'(default of Recbole) ->remove it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m internal_user_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(dataset\u001b[38;5;241m.\u001b[39muser_num))[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m      3\u001b[0m     _, topk_iid_list \u001b[38;5;241m=\u001b[39m full_sort_topk([internal_user_id], model, test_data, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, device\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m     last_topk_iid_list \u001b[38;5;241m=\u001b[39m \u001b[43mtopk_iid_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m     external_item_list \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mid2token(dataset\u001b[38;5;241m.\u001b[39miid_field, last_topk_iid_list\u001b[38;5;241m.\u001b[39mcpu())\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      6\u001b[0m     topk_items\u001b[38;5;241m.\u001b[39mappend(external_item_list)\n",
      "\u001b[1;31mIndexError\u001b[0m: index -1 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "topk_items = []\n",
    "for internal_user_id in list(range(dataset.user_num))[1:]:\n",
    "    _, topk_iid_list = full_sort_topk([internal_user_id], model, test_data, k=12, device=config['device'])\n",
    "    last_topk_iid_list = topk_iid_list[-1]\n",
    "    external_item_list = dataset.id2token(dataset.iid_field, last_topk_iid_list.cpu()).tolist()\n",
    "    topk_items.append(external_item_list)\n",
    "print(len(topk_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (3) does not match length of index (13709)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m external_item_str \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m topk_items]\n\u001b[0;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(external_user_ids, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m external_item_str\n\u001b[0;32m      4\u001b[0m result\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4134\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4135\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4146\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4147\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4148\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4149\u001b[0m     ):\n\u001b[0;32m   4150\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4870\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (3) does not match length of index (13709)"
     ]
    }
   ],
   "source": [
    "external_item_str = [' '.join(x) for x in topk_items]\n",
    "result = pd.DataFrame(external_user_ids, columns=['customer_id'])\n",
    "result['prediction'] = external_item_str\n",
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modeltest",
   "language": "python",
   "name": "modeltest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
