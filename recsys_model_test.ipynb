{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-31 21:40:58,045\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-03-31 21:40:58,478\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from recbole.quick_start import run_recbole\n",
    "import time\n",
    "import datetime\n",
    "#tensor factorization\n",
    "#source: https://tensorly.org/stable/user_guide/tensor_decomposition.html\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "\n",
    "from tensorly.decomposition import non_negative_tucker\n",
    "from tensorly.decomposition import non_negative_parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sequential recommendation parameter guidance](https://recbole.io/docs/get_started/started/sequential.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"G:/My Drive/2021/Bias/sumo_simulation/\"\n",
    "os.chdir(path)\n",
    "\n",
    "#get obs data matrix\n",
    "data_path_lst = []\n",
    "for i in os.listdir():\n",
    "    if len(i) == 12 and '.csv' in i:\n",
    "        data_path_lst.append(i)\n",
    "#data_path_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor factorization test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dt = pd.read_csv(data_path_lst[0])\n",
    "timestep_convert = lambda x: time.mktime(datetime.datetime.strptime(('2017_4_'+x[:-4]),\n",
    "                                                                    \"%Y_%m_%d_%H_%M\").timetuple())\n",
    "test_dt['date_time'] = test_dt['key'].apply(timestep_convert)\n",
    "\n",
    "def convert_idx(selectcol, newcol, data):\n",
    "    newdict = {}\n",
    "    idx = 0\n",
    "    for i in np.unique(data[selectcol]):\n",
    "        newdict[i] = idx\n",
    "        idx += 1\n",
    "    add_val = lambda x: newdict[x]\n",
    "    data[newcol] = data[selectcol].apply(add_val)\n",
    "    \n",
    "def calculate_rmse_mae(original, reconstructed):\n",
    "    # Flatten the tensors to compute the errors\n",
    "    original_flat = original.flatten()\n",
    "    reconstructed_flat = reconstructed.flatten()\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((original_flat - reconstructed_flat) ** 2))\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = np.mean(np.abs(original_flat - reconstructed_flat))\n",
    "    \n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to 3d matrix\n",
    "num_ids, num_taz, num_time = len(np.unique(test_dt.newid)), len(np.unique(test_dt.taz)), len(np.unique(test_dt.time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_idx('newid', 'newidx', test_dt)\n",
    "convert_idx('taz', 'tazidx', test_dt)\n",
    "convert_idx('date_time', 'timeidx', test_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mx = np.zeros((num_ids, num_taz, num_time))\n",
    "\n",
    "for i, j, k in test_dt[['newidx', 'tazidx', 'timeidx']].values:\n",
    "    test_mx[i][j][k] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_mx \u001b[38;5;241m=\u001b[39m \u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\recboletensor\\lib\\site-packages\\tensorly\\backend\\__init__.py:206\u001b[0m, in \u001b[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_backend_method\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;124;03m\"\"\"A dynamically dispatched method\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    Returns the queried method from the currently set backend\"\"\"\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_THREAD_LOCAL_DATA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\recboletensor\\lib\\site-packages\\tensorly\\backend\\numpy_backend.py:18\u001b[0m, in \u001b[0;36mNumpyBackend.tensor\u001b[1;34m(data, dtype, **kwargs)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_mx = tl.tensor(test_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = non_negative_parafac(test_mx, rank=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.9441467747462673\n",
      "RMSE, MAE: (0.017525987060110774, 0.0005588863170128765)\n"
     ]
    }
   ],
   "source": [
    "reconstructed_tensor = tl.kruskal_to_tensor(factors)\n",
    "\n",
    "# Comparing the original tensor with the reconstructed tensor\n",
    "reconstruction_error = tl.norm(test_mx - reconstructed_tensor) / tl.norm(test_mx)\n",
    "print(f\"Reconstruction error: {reconstruction_error}\")\n",
    "print(f\"RMSE, MAE: {calculate_rmse_mae(test_mx, reconstructed_tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "core, factors_tucker = tucker(test_mx, rank=[50, 24, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.9707548785143651\n",
      "RMSE, MAE: (0.01801990738564394, 0.0006950310438924797)\n"
     ]
    }
   ],
   "source": [
    "reconstructed_tensor = tl.tucker_tensor.tucker_to_tensor((core, factors_tucker))\n",
    "reconstruction_error = tl.norm(test_mx - reconstructed_tensor) / tl.norm(test_mx)\n",
    "print(f\"Reconstruction error: {reconstruction_error}\")\n",
    "print(f\"RMSE, MAE: {calculate_rmse_mae(test_mx, reconstructed_tensor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recbole-based\n",
    "### Sequential model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference source: https://www.kaggle.com/code/astrung/recbole-lstm-sequential-for-recomendation-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_dt[['newid','taz','date_time']].rename(columns={'newid': 'user_id:token', \n",
    "                                                     'taz': 'item_id:token', \n",
    "                                                     'date_time': 'timestamp:float'})\n",
    "temp.to_csv('recbox_data/recbox_data.inter', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.sequential_recommender import GRU4Rec\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "from recbole.model.sequential_recommender import FPMC, BERT4Rec, SASRec, FOSSIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.quick_start import load_data_and_model\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir('../SUMO_simulation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 May 12:32    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../SUMO_simulation/recbox_data\n",
      "checkpoint_dir = ./model_checkpoints\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "loss_type = BPR\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "neg_sampling = None\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../SUMO_simulation/recbox_data\n",
      "checkpoint_dir = ./model_checkpoints\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "loss_type = BPR\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "neg_sampling = None\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "28 May 12:32    INFO  recbox_data\n",
      "The number of users: 13710\n",
      "Average actions of users: 16.57276241884893\n",
      "The number of items: 168\n",
      "Average actions of items: 1360.4550898203593\n",
      "The number of inters: 227196\n",
      "The sparsity of the dataset: 90.13597999374805%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "recbox_data\n",
      "The number of users: 13710\n",
      "Average actions of users: 16.57276241884893\n",
      "The number of items: 168\n",
      "Average actions of items: 1360.4550898203593\n",
      "The number of inters: 227196\n",
      "The sparsity of the dataset: 90.13597999374805%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "28 May 12:33    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "28 May 12:33    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n"
     ]
    }
   ],
   "source": [
    "parameter_dict_FPMC = {\n",
    "    'data_path': '../SUMO_simulation/',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'load_col': {'inter': ['user_id', 'item_id', 'timestamp']},\n",
    "    #'train_neg_sample_args': None,\n",
    "    'checkpoint_dir': './model_checkpoints',\n",
    "    'neg_sampling':None,\n",
    "    'eval_args':{\n",
    "        'topk':30,\n",
    "        'order':'TO'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "config =  Config(model='FPMC', dataset='recbox_data', config_dict=parameter_dict_FPMC)\n",
    "\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)\n",
    "\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_FPMC.pth',\n",
       " 'model_SASrec.pth',\n",
       " 'model_BERT4Rec.pth',\n",
       " 'model_FOSSIL.pth']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current model\n",
    "os.listdir('model_checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_checkpoints/model_FPMC.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('UI_emb.weight',\n",
       "              tensor([[ 0.0199, -0.0053, -0.0153,  ..., -0.0236, -0.0017, -0.0016],\n",
       "                      [-0.0640,  0.0404, -0.0244,  ...,  0.0406,  0.0172, -0.0889],\n",
       "                      [-0.0919, -0.1722, -0.1223,  ...,  0.1103,  0.0787,  0.0875],\n",
       "                      ...,\n",
       "                      [-0.0905,  0.0410,  0.1475,  ..., -0.1536,  0.1417, -0.0563],\n",
       "                      [ 0.0845,  0.1662,  0.0443,  ...,  0.0120, -0.1688, -0.0409],\n",
       "                      [-0.0050,  0.1509, -0.1128,  ...,  0.1383,  0.0628, -0.0980]],\n",
       "                     device='cuda:0')),\n",
       "             ('IU_emb.weight',\n",
       "              tensor([[ 0.0702,  0.0839,  0.0188,  ..., -0.0573, -0.0408, -0.1000],\n",
       "                      [-0.1461,  0.8167, -0.2362,  ...,  0.4133, -0.6238, -0.7000],\n",
       "                      [-0.3645,  0.4812, -0.9058,  ..., -0.1218,  0.2447,  0.2747],\n",
       "                      ...,\n",
       "                      [-0.5439,  0.0585, -0.0822,  ..., -0.4391, -0.3355,  0.2907],\n",
       "                      [ 0.4976, -0.3538,  0.3692,  ..., -0.0916,  0.3251,  0.7177],\n",
       "                      [-0.7738, -0.9263,  0.9235,  ..., -0.4206, -0.0281,  0.8648]],\n",
       "                     device='cuda:0')),\n",
       "             ('LI_emb.weight',\n",
       "              tensor([[-0.0402, -0.0368,  0.0701,  ...,  0.0929,  0.1805,  0.0764],\n",
       "                      [ 0.3095,  0.2934, -0.4513,  ...,  0.0987,  0.0135, -0.1705],\n",
       "                      [ 0.1113,  0.3536, -0.6329,  ...,  0.2008, -0.1059, -0.2866],\n",
       "                      ...,\n",
       "                      [ 0.4319,  0.1636,  0.1823,  ...,  0.2446,  0.1709,  0.3821],\n",
       "                      [ 0.4252, -0.1173,  0.2072,  ...,  0.5080,  0.0086,  0.1175],\n",
       "                      [ 0.1486,  0.3584,  0.0519,  ...,  0.2160, -0.0337,  0.2457]],\n",
       "                     device='cuda:0')),\n",
       "             ('IL_emb.weight',\n",
       "              tensor([[-0.0954,  0.1347, -0.1288,  ..., -0.0939, -0.0513, -0.0866],\n",
       "                      [ 0.1728,  0.2939, -0.1305,  ...,  0.0441, -0.1210, -0.3656],\n",
       "                      [ 0.0435,  0.1391, -0.3580,  ...,  0.2298,  0.1284, -0.2812],\n",
       "                      ...,\n",
       "                      [ 0.2236,  0.1273,  0.1814,  ...,  0.1919, -0.0779,  0.1800],\n",
       "                      [ 0.3638, -0.1629,  0.1483,  ...,  0.4850,  0.0330,  0.0663],\n",
       "                      [ 0.3660,  0.1791,  0.1306,  ...,  0.3443,  0.1101,  0.0721]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.ustc.edu.cn/pypi/web/simple\n",
      "Collecting kmeans_pytorch\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/b5/c9/eb5b82e7e9741e61acf1aff70530a08810aa0c7e2272c534ff7a150fc5bd/kmeans_pytorch-0.3-py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: kmeans_pytorch\n",
      "Successfully installed kmeans_pytorch-0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script kmeans_pytorch.exe is installed in 'C:\\Users\\29700\\anaconda3\\envs\\recboletensor\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "model = load_data_and_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08 May 06:33    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "08 May 06:33    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "08 May 06:33    INFO  epoch 0 training [time: 8.96s, train loss: 50.7117]\n",
      "epoch 0 training [time: 8.96s, train loss: 50.7117]\n",
      "08 May 06:33    INFO  epoch 0 evaluating [time: 0.51s, valid_score: 0.477800]\n",
      "epoch 0 evaluating [time: 0.51s, valid_score: 0.477800]\n",
      "08 May 06:33    INFO  valid result: \n",
      "recall@10 : 0.6105    mrr@10 : 0.4778    ndcg@10 : 0.5096    hit@10 : 0.6105    precision@10 : 0.061\n",
      "valid result: \n",
      "recall@10 : 0.6105    mrr@10 : 0.4778    ndcg@10 : 0.5096    hit@10 : 0.6105    precision@10 : 0.061\n",
      "08 May 06:33    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:33    INFO  epoch 1 training [time: 8.28s, train loss: 34.2243]\n",
      "epoch 1 training [time: 8.28s, train loss: 34.2243]\n",
      "08 May 06:33    INFO  epoch 1 evaluating [time: 0.19s, valid_score: 0.514600]\n",
      "epoch 1 evaluating [time: 0.19s, valid_score: 0.514600]\n",
      "08 May 06:33    INFO  valid result: \n",
      "recall@10 : 0.7133    mrr@10 : 0.5146    ndcg@10 : 0.5625    hit@10 : 0.7133    precision@10 : 0.0713\n",
      "valid result: \n",
      "recall@10 : 0.7133    mrr@10 : 0.5146    ndcg@10 : 0.5625    hit@10 : 0.7133    precision@10 : 0.0713\n",
      "08 May 06:33    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:33    INFO  epoch 2 training [time: 7.86s, train loss: 21.7507]\n",
      "epoch 2 training [time: 7.86s, train loss: 21.7507]\n",
      "08 May 06:33    INFO  epoch 2 evaluating [time: 0.20s, valid_score: 0.526300]\n",
      "epoch 2 evaluating [time: 0.20s, valid_score: 0.526300]\n",
      "08 May 06:33    INFO  valid result: \n",
      "recall@10 : 0.7527    mrr@10 : 0.5263    ndcg@10 : 0.5807    hit@10 : 0.7527    precision@10 : 0.0753\n",
      "valid result: \n",
      "recall@10 : 0.7527    mrr@10 : 0.5263    ndcg@10 : 0.5807    hit@10 : 0.7527    precision@10 : 0.0753\n",
      "08 May 06:33    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:33    INFO  epoch 3 training [time: 8.08s, train loss: 15.1098]\n",
      "epoch 3 training [time: 8.08s, train loss: 15.1098]\n",
      "08 May 06:33    INFO  epoch 3 evaluating [time: 0.19s, valid_score: 0.531500]\n",
      "epoch 3 evaluating [time: 0.19s, valid_score: 0.531500]\n",
      "08 May 06:33    INFO  valid result: \n",
      "recall@10 : 0.767    mrr@10 : 0.5315    ndcg@10 : 0.588    hit@10 : 0.767    precision@10 : 0.0767\n",
      "valid result: \n",
      "recall@10 : 0.767    mrr@10 : 0.5315    ndcg@10 : 0.588    hit@10 : 0.767    precision@10 : 0.0767\n",
      "08 May 06:33    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:33    INFO  epoch 4 training [time: 7.87s, train loss: 11.5805]\n",
      "epoch 4 training [time: 7.87s, train loss: 11.5805]\n",
      "08 May 06:33    INFO  epoch 4 evaluating [time: 0.20s, valid_score: 0.534200]\n",
      "epoch 4 evaluating [time: 0.20s, valid_score: 0.534200]\n",
      "08 May 06:33    INFO  valid result: \n",
      "recall@10 : 0.7729    mrr@10 : 0.5342    ndcg@10 : 0.5914    hit@10 : 0.7729    precision@10 : 0.0773\n",
      "valid result: \n",
      "recall@10 : 0.7729    mrr@10 : 0.5342    ndcg@10 : 0.5914    hit@10 : 0.7729    precision@10 : 0.0773\n",
      "08 May 06:33    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:34    INFO  epoch 5 training [time: 7.80s, train loss: 9.7484]\n",
      "epoch 5 training [time: 7.80s, train loss: 9.7484]\n",
      "08 May 06:34    INFO  epoch 5 evaluating [time: 0.22s, valid_score: 0.535900]\n",
      "epoch 5 evaluating [time: 0.22s, valid_score: 0.535900]\n",
      "08 May 06:34    INFO  valid result: \n",
      "recall@10 : 0.7761    mrr@10 : 0.5359    ndcg@10 : 0.5935    hit@10 : 0.7761    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7761    mrr@10 : 0.5359    ndcg@10 : 0.5935    hit@10 : 0.7761    precision@10 : 0.0776\n",
      "08 May 06:34    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:34    INFO  epoch 6 training [time: 8.09s, train loss: 8.5443]\n",
      "epoch 6 training [time: 8.09s, train loss: 8.5443]\n",
      "08 May 06:34    INFO  epoch 6 evaluating [time: 0.19s, valid_score: 0.537500]\n",
      "epoch 6 evaluating [time: 0.19s, valid_score: 0.537500]\n",
      "08 May 06:34    INFO  valid result: \n",
      "recall@10 : 0.7786    mrr@10 : 0.5375    ndcg@10 : 0.5953    hit@10 : 0.7786    precision@10 : 0.0779\n",
      "valid result: \n",
      "recall@10 : 0.7786    mrr@10 : 0.5375    ndcg@10 : 0.5953    hit@10 : 0.7786    precision@10 : 0.0779\n",
      "08 May 06:34    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:34    INFO  epoch 7 training [time: 7.83s, train loss: 7.6544]\n",
      "epoch 7 training [time: 7.83s, train loss: 7.6544]\n",
      "08 May 06:34    INFO  epoch 7 evaluating [time: 0.20s, valid_score: 0.538600]\n",
      "epoch 7 evaluating [time: 0.20s, valid_score: 0.538600]\n",
      "08 May 06:34    INFO  valid result: \n",
      "recall@10 : 0.7796    mrr@10 : 0.5386    ndcg@10 : 0.5964    hit@10 : 0.7796    precision@10 : 0.078\n",
      "valid result: \n",
      "recall@10 : 0.7796    mrr@10 : 0.5386    ndcg@10 : 0.5964    hit@10 : 0.7796    precision@10 : 0.078\n",
      "08 May 06:34    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:34    INFO  epoch 8 training [time: 7.98s, train loss: 7.0537]\n",
      "epoch 8 training [time: 7.98s, train loss: 7.0537]\n",
      "08 May 06:34    INFO  epoch 8 evaluating [time: 0.21s, valid_score: 0.539200]\n",
      "epoch 8 evaluating [time: 0.21s, valid_score: 0.539200]\n",
      "08 May 06:34    INFO  valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.5392    ndcg@10 : 0.5973    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.5392    ndcg@10 : 0.5973    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "08 May 06:34    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:34    INFO  epoch 9 training [time: 7.78s, train loss: 6.5313]\n",
      "epoch 9 training [time: 7.78s, train loss: 6.5313]\n",
      "08 May 06:34    INFO  epoch 9 evaluating [time: 0.18s, valid_score: 0.539000]\n",
      "epoch 9 evaluating [time: 0.18s, valid_score: 0.539000]\n",
      "08 May 06:34    INFO  valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.539    ndcg@10 : 0.5972    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.539    ndcg@10 : 0.5972    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "08 May 06:34    INFO  epoch 10 training [time: 8.09s, train loss: 6.1967]\n",
      "epoch 10 training [time: 8.09s, train loss: 6.1967]\n",
      "08 May 06:34    INFO  epoch 10 evaluating [time: 0.21s, valid_score: 0.540100]\n",
      "epoch 10 evaluating [time: 0.21s, valid_score: 0.540100]\n",
      "08 May 06:34    INFO  valid result: \n",
      "recall@10 : 0.7827    mrr@10 : 0.5401    ndcg@10 : 0.5982    hit@10 : 0.7827    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7827    mrr@10 : 0.5401    ndcg@10 : 0.5982    hit@10 : 0.7827    precision@10 : 0.0783\n",
      "08 May 06:34    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:34    INFO  epoch 11 training [time: 7.83s, train loss: 5.7942]\n",
      "epoch 11 training [time: 7.83s, train loss: 5.7942]\n",
      "08 May 06:34    INFO  epoch 11 evaluating [time: 0.22s, valid_score: 0.540600]\n",
      "epoch 11 evaluating [time: 0.22s, valid_score: 0.540600]\n",
      "08 May 06:34    INFO  valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.5406    ndcg@10 : 0.5987    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.5406    ndcg@10 : 0.5987    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "08 May 06:34    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:35    INFO  epoch 12 training [time: 7.84s, train loss: 5.5183]\n",
      "epoch 12 training [time: 7.84s, train loss: 5.5183]\n",
      "08 May 06:35    INFO  epoch 12 evaluating [time: 0.18s, valid_score: 0.540500]\n",
      "epoch 12 evaluating [time: 0.18s, valid_score: 0.540500]\n",
      "08 May 06:35    INFO  valid result: \n",
      "recall@10 : 0.7825    mrr@10 : 0.5405    ndcg@10 : 0.5985    hit@10 : 0.7825    precision@10 : 0.0782\n",
      "valid result: \n",
      "recall@10 : 0.7825    mrr@10 : 0.5405    ndcg@10 : 0.5985    hit@10 : 0.7825    precision@10 : 0.0782\n",
      "08 May 06:35    INFO  epoch 13 training [time: 7.96s, train loss: 5.1601]\n",
      "epoch 13 training [time: 7.96s, train loss: 5.1601]\n",
      "08 May 06:35    INFO  epoch 13 evaluating [time: 0.20s, valid_score: 0.540900]\n",
      "epoch 13 evaluating [time: 0.20s, valid_score: 0.540900]\n",
      "08 May 06:35    INFO  valid result: \n",
      "recall@10 : 0.783    mrr@10 : 0.5409    ndcg@10 : 0.5989    hit@10 : 0.783    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.783    mrr@10 : 0.5409    ndcg@10 : 0.5989    hit@10 : 0.783    precision@10 : 0.0783\n",
      "08 May 06:35    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:35    INFO  epoch 14 training [time: 7.78s, train loss: 5.0508]\n",
      "epoch 14 training [time: 7.78s, train loss: 5.0508]\n",
      "08 May 06:35    INFO  epoch 14 evaluating [time: 0.18s, valid_score: 0.540900]\n",
      "epoch 14 evaluating [time: 0.18s, valid_score: 0.540900]\n",
      "08 May 06:35    INFO  valid result: \n",
      "recall@10 : 0.7842    mrr@10 : 0.5409    ndcg@10 : 0.5991    hit@10 : 0.7842    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7842    mrr@10 : 0.5409    ndcg@10 : 0.5991    hit@10 : 0.7842    precision@10 : 0.0784\n",
      "08 May 06:35    INFO  Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "Saving current: ./model_checkpoints\\FPMC-May-08-2024_06-33-12.pth\n",
      "08 May 06:35    INFO  epoch 15 training [time: 7.97s, train loss: 4.7427]\n",
      "epoch 15 training [time: 7.97s, train loss: 4.7427]\n",
      "08 May 06:35    INFO  epoch 15 evaluating [time: 0.19s, valid_score: 0.540000]\n",
      "epoch 15 evaluating [time: 0.19s, valid_score: 0.540000]\n",
      "08 May 06:35    INFO  valid result: \n",
      "recall@10 : 0.7838    mrr@10 : 0.54    ndcg@10 : 0.5985    hit@10 : 0.7838    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7838    mrr@10 : 0.54    ndcg@10 : 0.5985    hit@10 : 0.7838    precision@10 : 0.0784\n",
      "08 May 06:35    INFO  epoch 16 training [time: 7.89s, train loss: 4.6035]\n",
      "epoch 16 training [time: 7.89s, train loss: 4.6035]\n",
      "08 May 06:35    INFO  epoch 16 evaluating [time: 0.18s, valid_score: 0.540300]\n",
      "epoch 16 evaluating [time: 0.18s, valid_score: 0.540300]\n",
      "08 May 06:35    INFO  valid result: \n",
      "recall@10 : 0.784    mrr@10 : 0.5403    ndcg@10 : 0.5987    hit@10 : 0.784    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.784    mrr@10 : 0.5403    ndcg@10 : 0.5987    hit@10 : 0.784    precision@10 : 0.0784\n",
      "08 May 06:35    INFO  epoch 17 training [time: 7.98s, train loss: 4.5197]\n",
      "epoch 17 training [time: 7.98s, train loss: 4.5197]\n",
      "08 May 06:35    INFO  epoch 17 evaluating [time: 0.18s, valid_score: 0.540500]\n",
      "epoch 17 evaluating [time: 0.18s, valid_score: 0.540500]\n",
      "08 May 06:35    INFO  valid result: \n",
      "recall@10 : 0.7827    mrr@10 : 0.5405    ndcg@10 : 0.5985    hit@10 : 0.7827    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7827    mrr@10 : 0.5405    ndcg@10 : 0.5985    hit@10 : 0.7827    precision@10 : 0.0783\n",
      "08 May 06:35    INFO  epoch 18 training [time: 7.82s, train loss: 4.2471]\n",
      "epoch 18 training [time: 7.82s, train loss: 4.2471]\n",
      "08 May 06:35    INFO  epoch 18 evaluating [time: 0.20s, valid_score: 0.539800]\n",
      "epoch 18 evaluating [time: 0.20s, valid_score: 0.539800]\n",
      "08 May 06:35    INFO  valid result: \n",
      "recall@10 : 0.783    mrr@10 : 0.5398    ndcg@10 : 0.5981    hit@10 : 0.783    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.783    mrr@10 : 0.5398    ndcg@10 : 0.5981    hit@10 : 0.783    precision@10 : 0.0783\n",
      "08 May 06:35    INFO  epoch 19 training [time: 8.09s, train loss: 4.1038]\n",
      "epoch 19 training [time: 8.09s, train loss: 4.1038]\n",
      "08 May 06:35    INFO  epoch 19 evaluating [time: 0.19s, valid_score: 0.539800]\n",
      "epoch 19 evaluating [time: 0.19s, valid_score: 0.539800]\n",
      "08 May 06:35    INFO  valid result: \n",
      "recall@10 : 0.7822    mrr@10 : 0.5398    ndcg@10 : 0.5979    hit@10 : 0.7822    precision@10 : 0.0782\n",
      "valid result: \n",
      "recall@10 : 0.7822    mrr@10 : 0.5398    ndcg@10 : 0.5979    hit@10 : 0.7822    precision@10 : 0.0782\n",
      "08 May 06:36    INFO  epoch 20 training [time: 7.77s, train loss: 4.0134]\n",
      "epoch 20 training [time: 7.77s, train loss: 4.0134]\n",
      "08 May 06:36    INFO  epoch 20 evaluating [time: 0.21s, valid_score: 0.538700]\n",
      "epoch 20 evaluating [time: 0.21s, valid_score: 0.538700]\n",
      "08 May 06:36    INFO  valid result: \n",
      "recall@10 : 0.7818    mrr@10 : 0.5387    ndcg@10 : 0.5969    hit@10 : 0.7818    precision@10 : 0.0782\n",
      "valid result: \n",
      "recall@10 : 0.7818    mrr@10 : 0.5387    ndcg@10 : 0.5969    hit@10 : 0.7818    precision@10 : 0.0782\n",
      "08 May 06:36    INFO  epoch 21 training [time: 7.93s, train loss: 3.8969]\n",
      "epoch 21 training [time: 7.93s, train loss: 3.8969]\n",
      "08 May 06:36    INFO  epoch 21 evaluating [time: 0.20s, valid_score: 0.538900]\n",
      "epoch 21 evaluating [time: 0.20s, valid_score: 0.538900]\n",
      "08 May 06:36    INFO  valid result: \n",
      "recall@10 : 0.7802    mrr@10 : 0.5389    ndcg@10 : 0.5967    hit@10 : 0.7802    precision@10 : 0.078\n",
      "valid result: \n",
      "recall@10 : 0.7802    mrr@10 : 0.5389    ndcg@10 : 0.5967    hit@10 : 0.7802    precision@10 : 0.078\n",
      "08 May 06:36    INFO  epoch 22 training [time: 7.76s, train loss: 3.6775]\n",
      "epoch 22 training [time: 7.76s, train loss: 3.6775]\n",
      "08 May 06:36    INFO  epoch 22 evaluating [time: 0.22s, valid_score: 0.538800]\n",
      "epoch 22 evaluating [time: 0.22s, valid_score: 0.538800]\n",
      "08 May 06:36    INFO  valid result: \n",
      "recall@10 : 0.7805    mrr@10 : 0.5388    ndcg@10 : 0.5966    hit@10 : 0.7805    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7805    mrr@10 : 0.5388    ndcg@10 : 0.5966    hit@10 : 0.7805    precision@10 : 0.0781\n",
      "08 May 06:36    INFO  epoch 23 training [time: 8.00s, train loss: 3.6886]\n",
      "epoch 23 training [time: 8.00s, train loss: 3.6886]\n",
      "08 May 06:36    INFO  epoch 23 evaluating [time: 0.20s, valid_score: 0.538400]\n",
      "epoch 23 evaluating [time: 0.20s, valid_score: 0.538400]\n",
      "08 May 06:36    INFO  valid result: \n",
      "recall@10 : 0.7798    mrr@10 : 0.5384    ndcg@10 : 0.5962    hit@10 : 0.7798    precision@10 : 0.078\n",
      "valid result: \n",
      "recall@10 : 0.7798    mrr@10 : 0.5384    ndcg@10 : 0.5962    hit@10 : 0.7798    precision@10 : 0.078\n",
      "08 May 06:36    INFO  epoch 24 training [time: 7.85s, train loss: 3.5637]\n",
      "epoch 24 training [time: 7.85s, train loss: 3.5637]\n",
      "08 May 06:36    INFO  epoch 24 evaluating [time: 0.20s, valid_score: 0.537700]\n",
      "epoch 24 evaluating [time: 0.20s, valid_score: 0.537700]\n",
      "08 May 06:36    INFO  valid result: \n",
      "recall@10 : 0.7781    mrr@10 : 0.5377    ndcg@10 : 0.5953    hit@10 : 0.7781    precision@10 : 0.0778\n",
      "valid result: \n",
      "recall@10 : 0.7781    mrr@10 : 0.5377    ndcg@10 : 0.5953    hit@10 : 0.7781    precision@10 : 0.0778\n",
      "08 May 06:36    INFO  epoch 25 training [time: 7.96s, train loss: 3.4505]\n",
      "epoch 25 training [time: 7.96s, train loss: 3.4505]\n",
      "08 May 06:36    INFO  epoch 25 evaluating [time: 0.20s, valid_score: 0.537400]\n",
      "epoch 25 evaluating [time: 0.20s, valid_score: 0.537400]\n",
      "08 May 06:36    INFO  valid result: \n",
      "recall@10 : 0.7789    mrr@10 : 0.5374    ndcg@10 : 0.5952    hit@10 : 0.7789    precision@10 : 0.0779\n",
      "valid result: \n",
      "recall@10 : 0.7789    mrr@10 : 0.5374    ndcg@10 : 0.5952    hit@10 : 0.7789    precision@10 : 0.0779\n",
      "08 May 06:36    INFO  Finished training, best eval result in epoch 14\n",
      "Finished training, best eval result in epoch 14\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m best_valid_score_FPMC, best_valid_result_FPMC \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mfit(train_data, valid_data, saved\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_dir\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/model_FPMC.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), model_save_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#run_recbole(model='FPMC', dataset='recbox_data', config_dict=parameter_dict)\n",
    "# Step 4: Initialization\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "logger = init_logger(config)\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# Step 5: Training\n",
    "model_FPMC = FPMC(config, train_data.dataset).to(config['device'])\n",
    "trainer = Trainer(config, model_FPMC)\n",
    "\n",
    "# Train and evaluate the model\n",
    "best_valid_score_FPMC, best_valid_result_FPMC = trainer.fit(train_data, valid_data, saved=True)\n",
    "\n",
    "model_save_path = config['checkpoint_dir'] + '/model_FPMC.pth'\n",
    "\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_FPMC.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 May 09:15    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../SUMO_simulation/recbox_data\n",
      "checkpoint_dir = ./model_checkpoints\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "n_layers = 2\n",
      "n_heads = 2\n",
      "hidden_size = 64\n",
      "inner_size = 256\n",
      "hidden_dropout_prob = 0.5\n",
      "attn_dropout_prob = 0.5\n",
      "hidden_act = gelu\n",
      "layer_norm_eps = 1e-12\n",
      "initializer_range = 0.02\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "neg_sampling = None\n",
      "save_model = True\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../SUMO_simulation/recbox_data\n",
      "checkpoint_dir = ./model_checkpoints\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "n_layers = 2\n",
      "n_heads = 2\n",
      "hidden_size = 64\n",
      "inner_size = 256\n",
      "hidden_dropout_prob = 0.5\n",
      "attn_dropout_prob = 0.5\n",
      "hidden_act = gelu\n",
      "layer_norm_eps = 1e-12\n",
      "initializer_range = 0.02\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "neg_sampling = None\n",
      "save_model = True\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../SUMO_simulation/recbox_data\n",
      "checkpoint_dir = ./model_checkpoints\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "n_layers = 2\n",
      "n_heads = 2\n",
      "hidden_size = 64\n",
      "inner_size = 256\n",
      "hidden_dropout_prob = 0.5\n",
      "attn_dropout_prob = 0.5\n",
      "hidden_act = gelu\n",
      "layer_norm_eps = 1e-12\n",
      "initializer_range = 0.02\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "neg_sampling = None\n",
      "save_model = True\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter_dict_SASRec = {\n",
    "    'data_path': '../SUMO_simulation/',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'load_col': {'inter': ['user_id', 'item_id', 'timestamp']},\n",
    "    'train_neg_sample_args': None,\n",
    "    'neg_sampling':None,\n",
    "    'save_model': True,  # This will save the model after training\n",
    "    'checkpoint_dir': './model_checkpoints',\n",
    "    'epochs': 50,\n",
    "    'eval_args':{\n",
    "        'topk':30,\n",
    "        'order':'TO'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "config2 = Config(model='SASRec', dataset='recbox_data', config_dict=parameter_dict_SASRec)\n",
    "\n",
    "#run_recbole(model='SASRec', dataset='recbox_data', config_dict=parameter_dict_SASRec)\n",
    "init_seed(config2['seed'], config2['reproducibility'])\n",
    "\n",
    "#logger initialization\n",
    "init_logger(config2)\n",
    "logger = getLogger()\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 May 09:17    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "10 May 09:17    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(config2)\n",
    "train_data, valid_data, test_data = data_preparation(config2, dataset)\n",
    "\n",
    "\n",
    "# Step 5: Training\n",
    "model_SASRec = SASRec(config2, train_data.dataset).to(config2['device'])\n",
    "trainer = Trainer(config2, model_SASRec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 May 09:17    INFO  epoch 0 training [time: 14.25s, train loss: 314.9892]\n",
      "epoch 0 training [time: 14.25s, train loss: 314.9892]\n",
      "epoch 0 training [time: 14.25s, train loss: 314.9892]\n",
      "10 May 09:17    INFO  epoch 0 evaluating [time: 0.35s, valid_score: 0.501500]\n",
      "epoch 0 evaluating [time: 0.35s, valid_score: 0.501500]\n",
      "epoch 0 evaluating [time: 0.35s, valid_score: 0.501500]\n",
      "10 May 09:17    INFO  valid result: \n",
      "recall@10 : 0.759    mrr@10 : 0.5015    ndcg@10 : 0.5631    hit@10 : 0.759    precision@10 : 0.0759\n",
      "valid result: \n",
      "recall@10 : 0.759    mrr@10 : 0.5015    ndcg@10 : 0.5631    hit@10 : 0.759    precision@10 : 0.0759\n",
      "valid result: \n",
      "recall@10 : 0.759    mrr@10 : 0.5015    ndcg@10 : 0.5631    hit@10 : 0.759    precision@10 : 0.0759\n",
      "10 May 09:17    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:17    INFO  epoch 1 training [time: 13.24s, train loss: 216.4162]\n",
      "epoch 1 training [time: 13.24s, train loss: 216.4162]\n",
      "epoch 1 training [time: 13.24s, train loss: 216.4162]\n",
      "10 May 09:17    INFO  epoch 1 evaluating [time: 0.27s, valid_score: 0.525900]\n",
      "epoch 1 evaluating [time: 0.27s, valid_score: 0.525900]\n",
      "epoch 1 evaluating [time: 0.27s, valid_score: 0.525900]\n",
      "10 May 09:17    INFO  valid result: \n",
      "recall@10 : 0.7737    mrr@10 : 0.5259    ndcg@10 : 0.5853    hit@10 : 0.7737    precision@10 : 0.0774\n",
      "valid result: \n",
      "recall@10 : 0.7737    mrr@10 : 0.5259    ndcg@10 : 0.5853    hit@10 : 0.7737    precision@10 : 0.0774\n",
      "valid result: \n",
      "recall@10 : 0.7737    mrr@10 : 0.5259    ndcg@10 : 0.5853    hit@10 : 0.7737    precision@10 : 0.0774\n",
      "10 May 09:17    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:18    INFO  epoch 2 training [time: 13.24s, train loss: 200.6833]\n",
      "epoch 2 training [time: 13.24s, train loss: 200.6833]\n",
      "epoch 2 training [time: 13.24s, train loss: 200.6833]\n",
      "10 May 09:18    INFO  epoch 2 evaluating [time: 0.25s, valid_score: 0.534800]\n",
      "epoch 2 evaluating [time: 0.25s, valid_score: 0.534800]\n",
      "epoch 2 evaluating [time: 0.25s, valid_score: 0.534800]\n",
      "10 May 09:18    INFO  valid result: \n",
      "recall@10 : 0.78    mrr@10 : 0.5348    ndcg@10 : 0.5936    hit@10 : 0.78    precision@10 : 0.078\n",
      "valid result: \n",
      "recall@10 : 0.78    mrr@10 : 0.5348    ndcg@10 : 0.5936    hit@10 : 0.78    precision@10 : 0.078\n",
      "valid result: \n",
      "recall@10 : 0.78    mrr@10 : 0.5348    ndcg@10 : 0.5936    hit@10 : 0.78    precision@10 : 0.078\n",
      "10 May 09:18    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:18    INFO  epoch 3 training [time: 13.30s, train loss: 196.6177]\n",
      "epoch 3 training [time: 13.30s, train loss: 196.6177]\n",
      "epoch 3 training [time: 13.30s, train loss: 196.6177]\n",
      "10 May 09:18    INFO  epoch 3 evaluating [time: 0.25s, valid_score: 0.535400]\n",
      "epoch 3 evaluating [time: 0.25s, valid_score: 0.535400]\n",
      "epoch 3 evaluating [time: 0.25s, valid_score: 0.535400]\n",
      "10 May 09:18    INFO  valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.5354    ndcg@10 : 0.5944    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.5354    ndcg@10 : 0.5944    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.5354    ndcg@10 : 0.5944    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "10 May 09:18    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:18    INFO  epoch 4 training [time: 13.30s, train loss: 194.4824]\n",
      "epoch 4 training [time: 13.30s, train loss: 194.4824]\n",
      "epoch 4 training [time: 13.30s, train loss: 194.4824]\n",
      "10 May 09:18    INFO  epoch 4 evaluating [time: 0.27s, valid_score: 0.537200]\n",
      "epoch 4 evaluating [time: 0.27s, valid_score: 0.537200]\n",
      "epoch 4 evaluating [time: 0.27s, valid_score: 0.537200]\n",
      "10 May 09:18    INFO  valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.5372    ndcg@10 : 0.5962    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.5372    ndcg@10 : 0.5962    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.5372    ndcg@10 : 0.5962    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "10 May 09:18    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:18    INFO  epoch 5 training [time: 13.30s, train loss: 193.1707]\n",
      "epoch 5 training [time: 13.30s, train loss: 193.1707]\n",
      "epoch 5 training [time: 13.30s, train loss: 193.1707]\n",
      "10 May 09:18    INFO  epoch 5 evaluating [time: 0.25s, valid_score: 0.538700]\n",
      "epoch 5 evaluating [time: 0.25s, valid_score: 0.538700]\n",
      "epoch 5 evaluating [time: 0.25s, valid_score: 0.538700]\n",
      "10 May 09:18    INFO  valid result: \n",
      "recall@10 : 0.7852    mrr@10 : 0.5387    ndcg@10 : 0.5978    hit@10 : 0.7852    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7852    mrr@10 : 0.5387    ndcg@10 : 0.5978    hit@10 : 0.7852    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7852    mrr@10 : 0.5387    ndcg@10 : 0.5978    hit@10 : 0.7852    precision@10 : 0.0785\n",
      "10 May 09:18    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:18    INFO  epoch 6 training [time: 13.32s, train loss: 192.0505]\n",
      "epoch 6 training [time: 13.32s, train loss: 192.0505]\n",
      "epoch 6 training [time: 13.32s, train loss: 192.0505]\n",
      "10 May 09:18    INFO  epoch 6 evaluating [time: 0.25s, valid_score: 0.538300]\n",
      "epoch 6 evaluating [time: 0.25s, valid_score: 0.538300]\n",
      "epoch 6 evaluating [time: 0.25s, valid_score: 0.538300]\n",
      "10 May 09:18    INFO  valid result: \n",
      "recall@10 : 0.7851    mrr@10 : 0.5383    ndcg@10 : 0.5975    hit@10 : 0.7851    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7851    mrr@10 : 0.5383    ndcg@10 : 0.5975    hit@10 : 0.7851    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7851    mrr@10 : 0.5383    ndcg@10 : 0.5975    hit@10 : 0.7851    precision@10 : 0.0785\n",
      "10 May 09:19    INFO  epoch 7 training [time: 13.24s, train loss: 191.3201]\n",
      "epoch 7 training [time: 13.24s, train loss: 191.3201]\n",
      "epoch 7 training [time: 13.24s, train loss: 191.3201]\n",
      "10 May 09:19    INFO  epoch 7 evaluating [time: 0.25s, valid_score: 0.538800]\n",
      "epoch 7 evaluating [time: 0.25s, valid_score: 0.538800]\n",
      "epoch 7 evaluating [time: 0.25s, valid_score: 0.538800]\n",
      "10 May 09:19    INFO  valid result: \n",
      "recall@10 : 0.7841    mrr@10 : 0.5388    ndcg@10 : 0.5976    hit@10 : 0.7841    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7841    mrr@10 : 0.5388    ndcg@10 : 0.5976    hit@10 : 0.7841    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7841    mrr@10 : 0.5388    ndcg@10 : 0.5976    hit@10 : 0.7841    precision@10 : 0.0784\n",
      "10 May 09:19    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:19    INFO  epoch 8 training [time: 14.39s, train loss: 190.4171]\n",
      "epoch 8 training [time: 14.39s, train loss: 190.4171]\n",
      "epoch 8 training [time: 14.39s, train loss: 190.4171]\n",
      "10 May 09:19    INFO  epoch 8 evaluating [time: 0.27s, valid_score: 0.538800]\n",
      "epoch 8 evaluating [time: 0.27s, valid_score: 0.538800]\n",
      "epoch 8 evaluating [time: 0.27s, valid_score: 0.538800]\n",
      "10 May 09:19    INFO  valid result: \n",
      "recall@10 : 0.7836    mrr@10 : 0.5388    ndcg@10 : 0.5976    hit@10 : 0.7836    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7836    mrr@10 : 0.5388    ndcg@10 : 0.5976    hit@10 : 0.7836    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7836    mrr@10 : 0.5388    ndcg@10 : 0.5976    hit@10 : 0.7836    precision@10 : 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 May 09:19    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:19    INFO  epoch 9 training [time: 13.34s, train loss: 189.8442]\n",
      "epoch 9 training [time: 13.34s, train loss: 189.8442]\n",
      "epoch 9 training [time: 13.34s, train loss: 189.8442]\n",
      "10 May 09:19    INFO  epoch 9 evaluating [time: 0.26s, valid_score: 0.540400]\n",
      "epoch 9 evaluating [time: 0.26s, valid_score: 0.540400]\n",
      "epoch 9 evaluating [time: 0.26s, valid_score: 0.540400]\n",
      "10 May 09:19    INFO  valid result: \n",
      "recall@10 : 0.785    mrr@10 : 0.5404    ndcg@10 : 0.599    hit@10 : 0.785    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.785    mrr@10 : 0.5404    ndcg@10 : 0.599    hit@10 : 0.785    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.785    mrr@10 : 0.5404    ndcg@10 : 0.599    hit@10 : 0.785    precision@10 : 0.0785\n",
      "10 May 09:19    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:19    INFO  epoch 10 training [time: 13.41s, train loss: 189.5775]\n",
      "epoch 10 training [time: 13.41s, train loss: 189.5775]\n",
      "epoch 10 training [time: 13.41s, train loss: 189.5775]\n",
      "10 May 09:19    INFO  epoch 10 evaluating [time: 0.26s, valid_score: 0.540600]\n",
      "epoch 10 evaluating [time: 0.26s, valid_score: 0.540600]\n",
      "epoch 10 evaluating [time: 0.26s, valid_score: 0.540600]\n",
      "10 May 09:19    INFO  valid result: \n",
      "recall@10 : 0.785    mrr@10 : 0.5406    ndcg@10 : 0.5993    hit@10 : 0.785    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.785    mrr@10 : 0.5406    ndcg@10 : 0.5993    hit@10 : 0.785    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.785    mrr@10 : 0.5406    ndcg@10 : 0.5993    hit@10 : 0.785    precision@10 : 0.0785\n",
      "10 May 09:19    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:20    INFO  epoch 11 training [time: 13.36s, train loss: 188.7897]\n",
      "epoch 11 training [time: 13.36s, train loss: 188.7897]\n",
      "epoch 11 training [time: 13.36s, train loss: 188.7897]\n",
      "10 May 09:20    INFO  epoch 11 evaluating [time: 0.26s, valid_score: 0.541800]\n",
      "epoch 11 evaluating [time: 0.26s, valid_score: 0.541800]\n",
      "epoch 11 evaluating [time: 0.26s, valid_score: 0.541800]\n",
      "10 May 09:20    INFO  valid result: \n",
      "recall@10 : 0.786    mrr@10 : 0.5418    ndcg@10 : 0.6004    hit@10 : 0.786    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.786    mrr@10 : 0.5418    ndcg@10 : 0.6004    hit@10 : 0.786    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.786    mrr@10 : 0.5418    ndcg@10 : 0.6004    hit@10 : 0.786    precision@10 : 0.0786\n",
      "10 May 09:20    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:20    INFO  epoch 12 training [time: 13.31s, train loss: 188.4052]\n",
      "epoch 12 training [time: 13.31s, train loss: 188.4052]\n",
      "epoch 12 training [time: 13.31s, train loss: 188.4052]\n",
      "10 May 09:20    INFO  epoch 12 evaluating [time: 0.26s, valid_score: 0.542200]\n",
      "epoch 12 evaluating [time: 0.26s, valid_score: 0.542200]\n",
      "epoch 12 evaluating [time: 0.26s, valid_score: 0.542200]\n",
      "10 May 09:20    INFO  valid result: \n",
      "recall@10 : 0.7863    mrr@10 : 0.5422    ndcg@10 : 0.6007    hit@10 : 0.7863    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7863    mrr@10 : 0.5422    ndcg@10 : 0.6007    hit@10 : 0.7863    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7863    mrr@10 : 0.5422    ndcg@10 : 0.6007    hit@10 : 0.7863    precision@10 : 0.0786\n",
      "10 May 09:20    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:20    INFO  epoch 13 training [time: 13.56s, train loss: 188.0131]\n",
      "epoch 13 training [time: 13.56s, train loss: 188.0131]\n",
      "epoch 13 training [time: 13.56s, train loss: 188.0131]\n",
      "10 May 09:20    INFO  epoch 13 evaluating [time: 0.26s, valid_score: 0.542300]\n",
      "epoch 13 evaluating [time: 0.26s, valid_score: 0.542300]\n",
      "epoch 13 evaluating [time: 0.26s, valid_score: 0.542300]\n",
      "10 May 09:20    INFO  valid result: \n",
      "recall@10 : 0.7853    mrr@10 : 0.5423    ndcg@10 : 0.6006    hit@10 : 0.7853    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7853    mrr@10 : 0.5423    ndcg@10 : 0.6006    hit@10 : 0.7853    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7853    mrr@10 : 0.5423    ndcg@10 : 0.6006    hit@10 : 0.7853    precision@10 : 0.0785\n",
      "10 May 09:20    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:20    INFO  epoch 14 training [time: 13.18s, train loss: 187.7296]\n",
      "epoch 14 training [time: 13.18s, train loss: 187.7296]\n",
      "epoch 14 training [time: 13.18s, train loss: 187.7296]\n",
      "10 May 09:20    INFO  epoch 14 evaluating [time: 0.26s, valid_score: 0.542300]\n",
      "epoch 14 evaluating [time: 0.26s, valid_score: 0.542300]\n",
      "epoch 14 evaluating [time: 0.26s, valid_score: 0.542300]\n",
      "10 May 09:20    INFO  valid result: \n",
      "recall@10 : 0.7863    mrr@10 : 0.5423    ndcg@10 : 0.6008    hit@10 : 0.7863    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7863    mrr@10 : 0.5423    ndcg@10 : 0.6008    hit@10 : 0.7863    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7863    mrr@10 : 0.5423    ndcg@10 : 0.6008    hit@10 : 0.7863    precision@10 : 0.0786\n",
      "10 May 09:20    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:21    INFO  epoch 15 training [time: 13.21s, train loss: 187.3559]\n",
      "epoch 15 training [time: 13.21s, train loss: 187.3559]\n",
      "epoch 15 training [time: 13.21s, train loss: 187.3559]\n",
      "10 May 09:21    INFO  epoch 15 evaluating [time: 0.25s, valid_score: 0.542800]\n",
      "epoch 15 evaluating [time: 0.25s, valid_score: 0.542800]\n",
      "epoch 15 evaluating [time: 0.25s, valid_score: 0.542800]\n",
      "10 May 09:21    INFO  valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5428    ndcg@10 : 0.6014    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5428    ndcg@10 : 0.6014    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5428    ndcg@10 : 0.6014    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "10 May 09:21    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:21    INFO  epoch 16 training [time: 13.13s, train loss: 187.2636]\n",
      "epoch 16 training [time: 13.13s, train loss: 187.2636]\n",
      "epoch 16 training [time: 13.13s, train loss: 187.2636]\n",
      "10 May 09:21    INFO  epoch 16 evaluating [time: 0.26s, valid_score: 0.543300]\n",
      "epoch 16 evaluating [time: 0.26s, valid_score: 0.543300]\n",
      "epoch 16 evaluating [time: 0.26s, valid_score: 0.543300]\n",
      "10 May 09:21    INFO  valid result: \n",
      "recall@10 : 0.7864    mrr@10 : 0.5433    ndcg@10 : 0.6016    hit@10 : 0.7864    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7864    mrr@10 : 0.5433    ndcg@10 : 0.6016    hit@10 : 0.7864    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7864    mrr@10 : 0.5433    ndcg@10 : 0.6016    hit@10 : 0.7864    precision@10 : 0.0786\n",
      "10 May 09:21    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:21    INFO  epoch 17 training [time: 13.11s, train loss: 186.6769]\n",
      "epoch 17 training [time: 13.11s, train loss: 186.6769]\n",
      "epoch 17 training [time: 13.11s, train loss: 186.6769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 May 09:21    INFO  epoch 17 evaluating [time: 0.26s, valid_score: 0.543200]\n",
      "epoch 17 evaluating [time: 0.26s, valid_score: 0.543200]\n",
      "epoch 17 evaluating [time: 0.26s, valid_score: 0.543200]\n",
      "10 May 09:21    INFO  valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5432    ndcg@10 : 0.6017    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5432    ndcg@10 : 0.6017    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5432    ndcg@10 : 0.6017    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "10 May 09:21    INFO  epoch 18 training [time: 13.07s, train loss: 186.3867]\n",
      "epoch 18 training [time: 13.07s, train loss: 186.3867]\n",
      "epoch 18 training [time: 13.07s, train loss: 186.3867]\n",
      "10 May 09:21    INFO  epoch 18 evaluating [time: 0.25s, valid_score: 0.543100]\n",
      "epoch 18 evaluating [time: 0.25s, valid_score: 0.543100]\n",
      "epoch 18 evaluating [time: 0.25s, valid_score: 0.543100]\n",
      "10 May 09:21    INFO  valid result: \n",
      "recall@10 : 0.787    mrr@10 : 0.5431    ndcg@10 : 0.6016    hit@10 : 0.787    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.787    mrr@10 : 0.5431    ndcg@10 : 0.6016    hit@10 : 0.787    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.787    mrr@10 : 0.5431    ndcg@10 : 0.6016    hit@10 : 0.787    precision@10 : 0.0787\n",
      "10 May 09:21    INFO  epoch 19 training [time: 13.13s, train loss: 186.3255]\n",
      "epoch 19 training [time: 13.13s, train loss: 186.3255]\n",
      "epoch 19 training [time: 13.13s, train loss: 186.3255]\n",
      "10 May 09:21    INFO  epoch 19 evaluating [time: 0.24s, valid_score: 0.544200]\n",
      "epoch 19 evaluating [time: 0.24s, valid_score: 0.544200]\n",
      "epoch 19 evaluating [time: 0.24s, valid_score: 0.544200]\n",
      "10 May 09:21    INFO  valid result: \n",
      "recall@10 : 0.7876    mrr@10 : 0.5442    ndcg@10 : 0.6025    hit@10 : 0.7876    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7876    mrr@10 : 0.5442    ndcg@10 : 0.6025    hit@10 : 0.7876    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7876    mrr@10 : 0.5442    ndcg@10 : 0.6025    hit@10 : 0.7876    precision@10 : 0.0788\n",
      "10 May 09:21    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:22    INFO  epoch 20 training [time: 13.23s, train loss: 186.0005]\n",
      "epoch 20 training [time: 13.23s, train loss: 186.0005]\n",
      "epoch 20 training [time: 13.23s, train loss: 186.0005]\n",
      "10 May 09:22    INFO  epoch 20 evaluating [time: 0.26s, valid_score: 0.543100]\n",
      "epoch 20 evaluating [time: 0.26s, valid_score: 0.543100]\n",
      "epoch 20 evaluating [time: 0.26s, valid_score: 0.543100]\n",
      "10 May 09:22    INFO  valid result: \n",
      "recall@10 : 0.7864    mrr@10 : 0.5431    ndcg@10 : 0.6015    hit@10 : 0.7864    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7864    mrr@10 : 0.5431    ndcg@10 : 0.6015    hit@10 : 0.7864    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7864    mrr@10 : 0.5431    ndcg@10 : 0.6015    hit@10 : 0.7864    precision@10 : 0.0786\n",
      "10 May 09:22    INFO  epoch 21 training [time: 13.21s, train loss: 185.8489]\n",
      "epoch 21 training [time: 13.21s, train loss: 185.8489]\n",
      "epoch 21 training [time: 13.21s, train loss: 185.8489]\n",
      "10 May 09:22    INFO  epoch 21 evaluating [time: 0.25s, valid_score: 0.545000]\n",
      "epoch 21 evaluating [time: 0.25s, valid_score: 0.545000]\n",
      "epoch 21 evaluating [time: 0.25s, valid_score: 0.545000]\n",
      "10 May 09:22    INFO  valid result: \n",
      "recall@10 : 0.786    mrr@10 : 0.545    ndcg@10 : 0.6028    hit@10 : 0.786    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.786    mrr@10 : 0.545    ndcg@10 : 0.6028    hit@10 : 0.786    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.786    mrr@10 : 0.545    ndcg@10 : 0.6028    hit@10 : 0.786    precision@10 : 0.0786\n",
      "10 May 09:22    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:22    INFO  epoch 22 training [time: 13.16s, train loss: 185.4223]\n",
      "epoch 22 training [time: 13.16s, train loss: 185.4223]\n",
      "epoch 22 training [time: 13.16s, train loss: 185.4223]\n",
      "10 May 09:22    INFO  epoch 22 evaluating [time: 0.25s, valid_score: 0.544400]\n",
      "epoch 22 evaluating [time: 0.25s, valid_score: 0.544400]\n",
      "epoch 22 evaluating [time: 0.25s, valid_score: 0.544400]\n",
      "10 May 09:22    INFO  valid result: \n",
      "recall@10 : 0.7887    mrr@10 : 0.5444    ndcg@10 : 0.603    hit@10 : 0.7887    precision@10 : 0.0789\n",
      "valid result: \n",
      "recall@10 : 0.7887    mrr@10 : 0.5444    ndcg@10 : 0.603    hit@10 : 0.7887    precision@10 : 0.0789\n",
      "valid result: \n",
      "recall@10 : 0.7887    mrr@10 : 0.5444    ndcg@10 : 0.603    hit@10 : 0.7887    precision@10 : 0.0789\n",
      "10 May 09:22    INFO  epoch 23 training [time: 13.23s, train loss: 185.2255]\n",
      "epoch 23 training [time: 13.23s, train loss: 185.2255]\n",
      "epoch 23 training [time: 13.23s, train loss: 185.2255]\n",
      "10 May 09:22    INFO  epoch 23 evaluating [time: 0.27s, valid_score: 0.544400]\n",
      "epoch 23 evaluating [time: 0.27s, valid_score: 0.544400]\n",
      "epoch 23 evaluating [time: 0.27s, valid_score: 0.544400]\n",
      "10 May 09:22    INFO  valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5444    ndcg@10 : 0.6025    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5444    ndcg@10 : 0.6025    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5444    ndcg@10 : 0.6025    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "10 May 09:23    INFO  epoch 24 training [time: 13.14s, train loss: 185.2065]\n",
      "epoch 24 training [time: 13.14s, train loss: 185.2065]\n",
      "epoch 24 training [time: 13.14s, train loss: 185.2065]\n",
      "10 May 09:23    INFO  epoch 24 evaluating [time: 0.24s, valid_score: 0.545200]\n",
      "epoch 24 evaluating [time: 0.24s, valid_score: 0.545200]\n",
      "epoch 24 evaluating [time: 0.24s, valid_score: 0.545200]\n",
      "10 May 09:23    INFO  valid result: \n",
      "recall@10 : 0.789    mrr@10 : 0.5452    ndcg@10 : 0.6036    hit@10 : 0.789    precision@10 : 0.0789\n",
      "valid result: \n",
      "recall@10 : 0.789    mrr@10 : 0.5452    ndcg@10 : 0.6036    hit@10 : 0.789    precision@10 : 0.0789\n",
      "valid result: \n",
      "recall@10 : 0.789    mrr@10 : 0.5452    ndcg@10 : 0.6036    hit@10 : 0.789    precision@10 : 0.0789\n",
      "10 May 09:23    INFO  Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "Saving current: ./model_checkpoints\\SASRec-May-10-2024_09-17-18.pth\n",
      "10 May 09:23    INFO  epoch 25 training [time: 13.18s, train loss: 185.1317]\n",
      "epoch 25 training [time: 13.18s, train loss: 185.1317]\n",
      "epoch 25 training [time: 13.18s, train loss: 185.1317]\n",
      "10 May 09:23    INFO  epoch 25 evaluating [time: 0.25s, valid_score: 0.544600]\n",
      "epoch 25 evaluating [time: 0.25s, valid_score: 0.544600]\n",
      "epoch 25 evaluating [time: 0.25s, valid_score: 0.544600]\n",
      "10 May 09:23    INFO  valid result: \n",
      "recall@10 : 0.7878    mrr@10 : 0.5446    ndcg@10 : 0.6029    hit@10 : 0.7878    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7878    mrr@10 : 0.5446    ndcg@10 : 0.6029    hit@10 : 0.7878    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7878    mrr@10 : 0.5446    ndcg@10 : 0.6029    hit@10 : 0.7878    precision@10 : 0.0788\n",
      "10 May 09:23    INFO  epoch 26 training [time: 13.15s, train loss: 184.8130]\n",
      "epoch 26 training [time: 13.15s, train loss: 184.8130]\n",
      "epoch 26 training [time: 13.15s, train loss: 184.8130]\n",
      "10 May 09:23    INFO  epoch 26 evaluating [time: 0.26s, valid_score: 0.544200]\n",
      "epoch 26 evaluating [time: 0.26s, valid_score: 0.544200]\n",
      "epoch 26 evaluating [time: 0.26s, valid_score: 0.544200]\n",
      "10 May 09:23    INFO  valid result: \n",
      "recall@10 : 0.7864    mrr@10 : 0.5442    ndcg@10 : 0.6023    hit@10 : 0.7864    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7864    mrr@10 : 0.5442    ndcg@10 : 0.6023    hit@10 : 0.7864    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7864    mrr@10 : 0.5442    ndcg@10 : 0.6023    hit@10 : 0.7864    precision@10 : 0.0786\n",
      "10 May 09:23    INFO  epoch 27 training [time: 13.19s, train loss: 184.6930]\n",
      "epoch 27 training [time: 13.19s, train loss: 184.6930]\n",
      "epoch 27 training [time: 13.19s, train loss: 184.6930]\n",
      "10 May 09:23    INFO  epoch 27 evaluating [time: 0.27s, valid_score: 0.544400]\n",
      "epoch 27 evaluating [time: 0.27s, valid_score: 0.544400]\n",
      "epoch 27 evaluating [time: 0.27s, valid_score: 0.544400]\n",
      "10 May 09:23    INFO  valid result: \n",
      "recall@10 : 0.7876    mrr@10 : 0.5444    ndcg@10 : 0.6028    hit@10 : 0.7876    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7876    mrr@10 : 0.5444    ndcg@10 : 0.6028    hit@10 : 0.7876    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7876    mrr@10 : 0.5444    ndcg@10 : 0.6028    hit@10 : 0.7876    precision@10 : 0.0788\n",
      "10 May 09:23    INFO  epoch 28 training [time: 13.23s, train loss: 184.3333]\n",
      "epoch 28 training [time: 13.23s, train loss: 184.3333]\n",
      "epoch 28 training [time: 13.23s, train loss: 184.3333]\n",
      "10 May 09:23    INFO  epoch 28 evaluating [time: 0.25s, valid_score: 0.544500]\n",
      "epoch 28 evaluating [time: 0.25s, valid_score: 0.544500]\n",
      "epoch 28 evaluating [time: 0.25s, valid_score: 0.544500]\n",
      "10 May 09:23    INFO  valid result: \n",
      "recall@10 : 0.7863    mrr@10 : 0.5445    ndcg@10 : 0.6025    hit@10 : 0.7863    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7863    mrr@10 : 0.5445    ndcg@10 : 0.6025    hit@10 : 0.7863    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7863    mrr@10 : 0.5445    ndcg@10 : 0.6025    hit@10 : 0.7863    precision@10 : 0.0786\n",
      "10 May 09:24    INFO  epoch 29 training [time: 13.09s, train loss: 184.2278]\n",
      "epoch 29 training [time: 13.09s, train loss: 184.2278]\n",
      "epoch 29 training [time: 13.09s, train loss: 184.2278]\n",
      "10 May 09:24    INFO  epoch 29 evaluating [time: 0.26s, valid_score: 0.544000]\n",
      "epoch 29 evaluating [time: 0.26s, valid_score: 0.544000]\n",
      "epoch 29 evaluating [time: 0.26s, valid_score: 0.544000]\n",
      "10 May 09:24    INFO  valid result: \n",
      "recall@10 : 0.7867    mrr@10 : 0.544    ndcg@10 : 0.6022    hit@10 : 0.7867    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7867    mrr@10 : 0.544    ndcg@10 : 0.6022    hit@10 : 0.7867    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7867    mrr@10 : 0.544    ndcg@10 : 0.6022    hit@10 : 0.7867    precision@10 : 0.0787\n",
      "10 May 09:24    INFO  epoch 30 training [time: 13.41s, train loss: 184.2320]\n",
      "epoch 30 training [time: 13.41s, train loss: 184.2320]\n",
      "epoch 30 training [time: 13.41s, train loss: 184.2320]\n",
      "10 May 09:24    INFO  epoch 30 evaluating [time: 0.25s, valid_score: 0.544600]\n",
      "epoch 30 evaluating [time: 0.25s, valid_score: 0.544600]\n",
      "epoch 30 evaluating [time: 0.25s, valid_score: 0.544600]\n",
      "10 May 09:24    INFO  valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5446    ndcg@10 : 0.6027    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5446    ndcg@10 : 0.6027    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5446    ndcg@10 : 0.6027    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "10 May 09:24    INFO  epoch 31 training [time: 13.30s, train loss: 183.9259]\n",
      "epoch 31 training [time: 13.30s, train loss: 183.9259]\n",
      "epoch 31 training [time: 13.30s, train loss: 183.9259]\n",
      "10 May 09:24    INFO  epoch 31 evaluating [time: 0.27s, valid_score: 0.545000]\n",
      "epoch 31 evaluating [time: 0.27s, valid_score: 0.545000]\n",
      "epoch 31 evaluating [time: 0.27s, valid_score: 0.545000]\n",
      "10 May 09:24    INFO  valid result: \n",
      "recall@10 : 0.7884    mrr@10 : 0.545    ndcg@10 : 0.6033    hit@10 : 0.7884    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7884    mrr@10 : 0.545    ndcg@10 : 0.6033    hit@10 : 0.7884    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7884    mrr@10 : 0.545    ndcg@10 : 0.6033    hit@10 : 0.7884    precision@10 : 0.0788\n",
      "10 May 09:24    INFO  epoch 32 training [time: 13.40s, train loss: 183.8908]\n",
      "epoch 32 training [time: 13.40s, train loss: 183.8908]\n",
      "epoch 32 training [time: 13.40s, train loss: 183.8908]\n",
      "10 May 09:24    INFO  epoch 32 evaluating [time: 0.24s, valid_score: 0.544600]\n",
      "epoch 32 evaluating [time: 0.24s, valid_score: 0.544600]\n",
      "epoch 32 evaluating [time: 0.24s, valid_score: 0.544600]\n",
      "10 May 09:24    INFO  valid result: \n",
      "recall@10 : 0.788    mrr@10 : 0.5446    ndcg@10 : 0.6029    hit@10 : 0.788    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.788    mrr@10 : 0.5446    ndcg@10 : 0.6029    hit@10 : 0.788    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.788    mrr@10 : 0.5446    ndcg@10 : 0.6029    hit@10 : 0.788    precision@10 : 0.0788\n",
      "10 May 09:25    INFO  epoch 33 training [time: 13.31s, train loss: 183.8381]\n",
      "epoch 33 training [time: 13.31s, train loss: 183.8381]\n",
      "epoch 33 training [time: 13.31s, train loss: 183.8381]\n",
      "10 May 09:25    INFO  epoch 33 evaluating [time: 0.25s, valid_score: 0.544900]\n",
      "epoch 33 evaluating [time: 0.25s, valid_score: 0.544900]\n",
      "epoch 33 evaluating [time: 0.25s, valid_score: 0.544900]\n",
      "10 May 09:25    INFO  valid result: \n",
      "recall@10 : 0.788    mrr@10 : 0.5449    ndcg@10 : 0.6032    hit@10 : 0.788    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.788    mrr@10 : 0.5449    ndcg@10 : 0.6032    hit@10 : 0.788    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.788    mrr@10 : 0.5449    ndcg@10 : 0.6032    hit@10 : 0.788    precision@10 : 0.0788\n",
      "10 May 09:25    INFO  epoch 34 training [time: 13.18s, train loss: 183.5130]\n",
      "epoch 34 training [time: 13.18s, train loss: 183.5130]\n",
      "epoch 34 training [time: 13.18s, train loss: 183.5130]\n",
      "10 May 09:25    INFO  epoch 34 evaluating [time: 0.24s, valid_score: 0.544800]\n",
      "epoch 34 evaluating [time: 0.24s, valid_score: 0.544800]\n",
      "epoch 34 evaluating [time: 0.24s, valid_score: 0.544800]\n",
      "10 May 09:25    INFO  valid result: \n",
      "recall@10 : 0.7871    mrr@10 : 0.5448    ndcg@10 : 0.6028    hit@10 : 0.7871    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7871    mrr@10 : 0.5448    ndcg@10 : 0.6028    hit@10 : 0.7871    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7871    mrr@10 : 0.5448    ndcg@10 : 0.6028    hit@10 : 0.7871    precision@10 : 0.0787\n",
      "10 May 09:25    INFO  epoch 35 training [time: 13.30s, train loss: 183.4909]\n",
      "epoch 35 training [time: 13.30s, train loss: 183.4909]\n",
      "epoch 35 training [time: 13.30s, train loss: 183.4909]\n",
      "10 May 09:25    INFO  epoch 35 evaluating [time: 0.26s, valid_score: 0.544800]\n",
      "epoch 35 evaluating [time: 0.26s, valid_score: 0.544800]\n",
      "epoch 35 evaluating [time: 0.26s, valid_score: 0.544800]\n",
      "10 May 09:25    INFO  valid result: \n",
      "recall@10 : 0.7878    mrr@10 : 0.5448    ndcg@10 : 0.6031    hit@10 : 0.7878    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7878    mrr@10 : 0.5448    ndcg@10 : 0.6031    hit@10 : 0.7878    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7878    mrr@10 : 0.5448    ndcg@10 : 0.6031    hit@10 : 0.7878    precision@10 : 0.0788\n",
      "10 May 09:25    INFO  Finished training, best eval result in epoch 24\n",
      "Finished training, best eval result in epoch 24\n",
      "Finished training, best eval result in epoch 24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate the model\n",
    "best_valid_score_SASRec, best_valid_result_SASRec = trainer.fit(train_data, valid_data, saved=True)\n",
    "\n",
    "model_save_path = config2['checkpoint_dir'] + '/model_SASrec.pth'\n",
    "\n",
    "torch.save(model_SASRec.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 May 04:43    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "14 May 04:43    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "14 May 04:44    INFO  epoch 0 training [time: 19.42s, train loss: 374.5411]\n",
      "epoch 0 training [time: 19.42s, train loss: 374.5411]\n",
      "epoch 0 training [time: 19.42s, train loss: 374.5411]\n",
      "14 May 04:44    INFO  epoch 0 evaluating [time: 2.73s, valid_score: 0.360000]\n",
      "epoch 0 evaluating [time: 2.73s, valid_score: 0.360000]\n",
      "epoch 0 evaluating [time: 2.73s, valid_score: 0.360000]\n",
      "14 May 04:44    INFO  valid result: \n",
      "recall@10 : 0.5898    mrr@10 : 0.36    ndcg@10 : 0.4148    hit@10 : 0.5898    precision@10 : 0.059\n",
      "valid result: \n",
      "recall@10 : 0.5898    mrr@10 : 0.36    ndcg@10 : 0.4148    hit@10 : 0.5898    precision@10 : 0.059\n",
      "valid result: \n",
      "recall@10 : 0.5898    mrr@10 : 0.36    ndcg@10 : 0.4148    hit@10 : 0.5898    precision@10 : 0.059\n",
      "14 May 04:44    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:44    INFO  epoch 1 training [time: 18.70s, train loss: 248.7199]\n",
      "epoch 1 training [time: 18.70s, train loss: 248.7199]\n",
      "epoch 1 training [time: 18.70s, train loss: 248.7199]\n",
      "14 May 04:44    INFO  epoch 1 evaluating [time: 2.62s, valid_score: 0.472600]\n",
      "epoch 1 evaluating [time: 2.62s, valid_score: 0.472600]\n",
      "epoch 1 evaluating [time: 2.62s, valid_score: 0.472600]\n",
      "14 May 04:44    INFO  valid result: \n",
      "recall@10 : 0.6858    mrr@10 : 0.4726    ndcg@10 : 0.5237    hit@10 : 0.6858    precision@10 : 0.0686\n",
      "valid result: \n",
      "recall@10 : 0.6858    mrr@10 : 0.4726    ndcg@10 : 0.5237    hit@10 : 0.6858    precision@10 : 0.0686\n",
      "valid result: \n",
      "recall@10 : 0.6858    mrr@10 : 0.4726    ndcg@10 : 0.5237    hit@10 : 0.6858    precision@10 : 0.0686\n",
      "14 May 04:44    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:44    INFO  epoch 2 training [time: 19.27s, train loss: 204.5993]\n",
      "epoch 2 training [time: 19.27s, train loss: 204.5993]\n",
      "epoch 2 training [time: 19.27s, train loss: 204.5993]\n",
      "14 May 04:44    INFO  epoch 2 evaluating [time: 2.43s, valid_score: 0.496500]\n",
      "epoch 2 evaluating [time: 2.43s, valid_score: 0.496500]\n",
      "epoch 2 evaluating [time: 2.43s, valid_score: 0.496500]\n",
      "14 May 04:44    INFO  valid result: \n",
      "recall@10 : 0.7095    mrr@10 : 0.4965    ndcg@10 : 0.5475    hit@10 : 0.7095    precision@10 : 0.0709\n",
      "valid result: \n",
      "recall@10 : 0.7095    mrr@10 : 0.4965    ndcg@10 : 0.5475    hit@10 : 0.7095    precision@10 : 0.0709\n",
      "valid result: \n",
      "recall@10 : 0.7095    mrr@10 : 0.4965    ndcg@10 : 0.5475    hit@10 : 0.7095    precision@10 : 0.0709\n",
      "14 May 04:44    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:45    INFO  epoch 3 training [time: 18.69s, train loss: 189.2290]\n",
      "epoch 3 training [time: 18.69s, train loss: 189.2290]\n",
      "epoch 3 training [time: 18.69s, train loss: 189.2290]\n",
      "14 May 04:45    INFO  epoch 3 evaluating [time: 2.56s, valid_score: 0.512000]\n",
      "epoch 3 evaluating [time: 2.56s, valid_score: 0.512000]\n",
      "epoch 3 evaluating [time: 2.56s, valid_score: 0.512000]\n",
      "14 May 04:45    INFO  valid result: \n",
      "recall@10 : 0.7243    mrr@10 : 0.512    ndcg@10 : 0.5629    hit@10 : 0.7243    precision@10 : 0.0724\n",
      "valid result: \n",
      "recall@10 : 0.7243    mrr@10 : 0.512    ndcg@10 : 0.5629    hit@10 : 0.7243    precision@10 : 0.0724\n",
      "valid result: \n",
      "recall@10 : 0.7243    mrr@10 : 0.512    ndcg@10 : 0.5629    hit@10 : 0.7243    precision@10 : 0.0724\n",
      "14 May 04:45    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:45    INFO  epoch 4 training [time: 18.63s, train loss: 181.4423]\n",
      "epoch 4 training [time: 18.63s, train loss: 181.4423]\n",
      "epoch 4 training [time: 18.63s, train loss: 181.4423]\n",
      "14 May 04:45    INFO  epoch 4 evaluating [time: 2.47s, valid_score: 0.520000]\n",
      "epoch 4 evaluating [time: 2.47s, valid_score: 0.520000]\n",
      "epoch 4 evaluating [time: 2.47s, valid_score: 0.520000]\n",
      "14 May 04:45    INFO  valid result: \n",
      "recall@10 : 0.7377    mrr@10 : 0.52    ndcg@10 : 0.5721    hit@10 : 0.7377    precision@10 : 0.0738\n",
      "valid result: \n",
      "recall@10 : 0.7377    mrr@10 : 0.52    ndcg@10 : 0.5721    hit@10 : 0.7377    precision@10 : 0.0738\n",
      "valid result: \n",
      "recall@10 : 0.7377    mrr@10 : 0.52    ndcg@10 : 0.5721    hit@10 : 0.7377    precision@10 : 0.0738\n",
      "14 May 04:45    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:45    INFO  epoch 5 training [time: 18.78s, train loss: 172.4716]\n",
      "epoch 5 training [time: 18.78s, train loss: 172.4716]\n",
      "epoch 5 training [time: 18.78s, train loss: 172.4716]\n",
      "14 May 04:45    INFO  epoch 5 evaluating [time: 2.63s, valid_score: 0.524700]\n",
      "epoch 5 evaluating [time: 2.63s, valid_score: 0.524700]\n",
      "epoch 5 evaluating [time: 2.63s, valid_score: 0.524700]\n",
      "14 May 04:45    INFO  valid result: \n",
      "recall@10 : 0.7466    mrr@10 : 0.5247    ndcg@10 : 0.5778    hit@10 : 0.7466    precision@10 : 0.0747\n",
      "valid result: \n",
      "recall@10 : 0.7466    mrr@10 : 0.5247    ndcg@10 : 0.5778    hit@10 : 0.7466    precision@10 : 0.0747\n",
      "valid result: \n",
      "recall@10 : 0.7466    mrr@10 : 0.5247    ndcg@10 : 0.5778    hit@10 : 0.7466    precision@10 : 0.0747\n",
      "14 May 04:45    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:46    INFO  epoch 6 training [time: 18.55s, train loss: 169.5890]\n",
      "epoch 6 training [time: 18.55s, train loss: 169.5890]\n",
      "epoch 6 training [time: 18.55s, train loss: 169.5890]\n",
      "14 May 04:46    INFO  epoch 6 evaluating [time: 2.59s, valid_score: 0.531500]\n",
      "epoch 6 evaluating [time: 2.59s, valid_score: 0.531500]\n",
      "epoch 6 evaluating [time: 2.59s, valid_score: 0.531500]\n",
      "14 May 04:46    INFO  valid result: \n",
      "recall@10 : 0.755    mrr@10 : 0.5315    ndcg@10 : 0.585    hit@10 : 0.755    precision@10 : 0.0755\n",
      "valid result: \n",
      "recall@10 : 0.755    mrr@10 : 0.5315    ndcg@10 : 0.585    hit@10 : 0.755    precision@10 : 0.0755\n",
      "valid result: \n",
      "recall@10 : 0.755    mrr@10 : 0.5315    ndcg@10 : 0.585    hit@10 : 0.755    precision@10 : 0.0755\n",
      "14 May 04:46    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:46    INFO  epoch 7 training [time: 18.58s, train loss: 163.7645]\n",
      "epoch 7 training [time: 18.58s, train loss: 163.7645]\n",
      "epoch 7 training [time: 18.58s, train loss: 163.7645]\n",
      "14 May 04:46    INFO  epoch 7 evaluating [time: 2.63s, valid_score: 0.537100]\n",
      "epoch 7 evaluating [time: 2.63s, valid_score: 0.537100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 evaluating [time: 2.63s, valid_score: 0.537100]\n",
      "14 May 04:46    INFO  valid result: \n",
      "recall@10 : 0.7626    mrr@10 : 0.5371    ndcg@10 : 0.5911    hit@10 : 0.7626    precision@10 : 0.0763\n",
      "valid result: \n",
      "recall@10 : 0.7626    mrr@10 : 0.5371    ndcg@10 : 0.5911    hit@10 : 0.7626    precision@10 : 0.0763\n",
      "valid result: \n",
      "recall@10 : 0.7626    mrr@10 : 0.5371    ndcg@10 : 0.5911    hit@10 : 0.7626    precision@10 : 0.0763\n",
      "14 May 04:46    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:46    INFO  epoch 8 training [time: 18.69s, train loss: 160.4913]\n",
      "epoch 8 training [time: 18.69s, train loss: 160.4913]\n",
      "epoch 8 training [time: 18.69s, train loss: 160.4913]\n",
      "14 May 04:46    INFO  epoch 8 evaluating [time: 2.75s, valid_score: 0.539600]\n",
      "epoch 8 evaluating [time: 2.75s, valid_score: 0.539600]\n",
      "epoch 8 evaluating [time: 2.75s, valid_score: 0.539600]\n",
      "14 May 04:46    INFO  valid result: \n",
      "recall@10 : 0.7663    mrr@10 : 0.5396    ndcg@10 : 0.5939    hit@10 : 0.7663    precision@10 : 0.0766\n",
      "valid result: \n",
      "recall@10 : 0.7663    mrr@10 : 0.5396    ndcg@10 : 0.5939    hit@10 : 0.7663    precision@10 : 0.0766\n",
      "valid result: \n",
      "recall@10 : 0.7663    mrr@10 : 0.5396    ndcg@10 : 0.5939    hit@10 : 0.7663    precision@10 : 0.0766\n",
      "14 May 04:46    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:47    INFO  epoch 9 training [time: 18.42s, train loss: 163.1939]\n",
      "epoch 9 training [time: 18.42s, train loss: 163.1939]\n",
      "epoch 9 training [time: 18.42s, train loss: 163.1939]\n",
      "14 May 04:47    INFO  epoch 9 evaluating [time: 2.63s, valid_score: 0.541600]\n",
      "epoch 9 evaluating [time: 2.63s, valid_score: 0.541600]\n",
      "epoch 9 evaluating [time: 2.63s, valid_score: 0.541600]\n",
      "14 May 04:47    INFO  valid result: \n",
      "recall@10 : 0.7702    mrr@10 : 0.5416    ndcg@10 : 0.5963    hit@10 : 0.7702    precision@10 : 0.077\n",
      "valid result: \n",
      "recall@10 : 0.7702    mrr@10 : 0.5416    ndcg@10 : 0.5963    hit@10 : 0.7702    precision@10 : 0.077\n",
      "valid result: \n",
      "recall@10 : 0.7702    mrr@10 : 0.5416    ndcg@10 : 0.5963    hit@10 : 0.7702    precision@10 : 0.077\n",
      "14 May 04:47    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:47    INFO  epoch 10 training [time: 18.65s, train loss: 155.6935]\n",
      "epoch 10 training [time: 18.65s, train loss: 155.6935]\n",
      "epoch 10 training [time: 18.65s, train loss: 155.6935]\n",
      "14 May 04:47    INFO  epoch 10 evaluating [time: 2.60s, valid_score: 0.543300]\n",
      "epoch 10 evaluating [time: 2.60s, valid_score: 0.543300]\n",
      "epoch 10 evaluating [time: 2.60s, valid_score: 0.543300]\n",
      "14 May 04:47    INFO  valid result: \n",
      "recall@10 : 0.7728    mrr@10 : 0.5433    ndcg@10 : 0.5982    hit@10 : 0.7728    precision@10 : 0.0773\n",
      "valid result: \n",
      "recall@10 : 0.7728    mrr@10 : 0.5433    ndcg@10 : 0.5982    hit@10 : 0.7728    precision@10 : 0.0773\n",
      "valid result: \n",
      "recall@10 : 0.7728    mrr@10 : 0.5433    ndcg@10 : 0.5982    hit@10 : 0.7728    precision@10 : 0.0773\n",
      "14 May 04:47    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:47    INFO  epoch 11 training [time: 18.54s, train loss: 157.6057]\n",
      "epoch 11 training [time: 18.54s, train loss: 157.6057]\n",
      "epoch 11 training [time: 18.54s, train loss: 157.6057]\n",
      "14 May 04:48    INFO  epoch 11 evaluating [time: 2.56s, valid_score: 0.544300]\n",
      "epoch 11 evaluating [time: 2.56s, valid_score: 0.544300]\n",
      "epoch 11 evaluating [time: 2.56s, valid_score: 0.544300]\n",
      "14 May 04:48    INFO  valid result: \n",
      "recall@10 : 0.774    mrr@10 : 0.5443    ndcg@10 : 0.5992    hit@10 : 0.774    precision@10 : 0.0774\n",
      "valid result: \n",
      "recall@10 : 0.774    mrr@10 : 0.5443    ndcg@10 : 0.5992    hit@10 : 0.774    precision@10 : 0.0774\n",
      "valid result: \n",
      "recall@10 : 0.774    mrr@10 : 0.5443    ndcg@10 : 0.5992    hit@10 : 0.774    precision@10 : 0.0774\n",
      "14 May 04:48    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:48    INFO  epoch 12 training [time: 18.81s, train loss: 156.6760]\n",
      "epoch 12 training [time: 18.81s, train loss: 156.6760]\n",
      "epoch 12 training [time: 18.81s, train loss: 156.6760]\n",
      "14 May 04:48    INFO  epoch 12 evaluating [time: 2.59s, valid_score: 0.545500]\n",
      "epoch 12 evaluating [time: 2.59s, valid_score: 0.545500]\n",
      "epoch 12 evaluating [time: 2.59s, valid_score: 0.545500]\n",
      "14 May 04:48    INFO  valid result: \n",
      "recall@10 : 0.7756    mrr@10 : 0.5455    ndcg@10 : 0.6006    hit@10 : 0.7756    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7756    mrr@10 : 0.5455    ndcg@10 : 0.6006    hit@10 : 0.7756    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7756    mrr@10 : 0.5455    ndcg@10 : 0.6006    hit@10 : 0.7756    precision@10 : 0.0776\n",
      "14 May 04:48    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:48    INFO  epoch 13 training [time: 18.61s, train loss: 160.0902]\n",
      "epoch 13 training [time: 18.61s, train loss: 160.0902]\n",
      "epoch 13 training [time: 18.61s, train loss: 160.0902]\n",
      "14 May 04:48    INFO  epoch 13 evaluating [time: 2.58s, valid_score: 0.545400]\n",
      "epoch 13 evaluating [time: 2.58s, valid_score: 0.545400]\n",
      "epoch 13 evaluating [time: 2.58s, valid_score: 0.545400]\n",
      "14 May 04:48    INFO  valid result: \n",
      "recall@10 : 0.7773    mrr@10 : 0.5454    ndcg@10 : 0.6009    hit@10 : 0.7773    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7773    mrr@10 : 0.5454    ndcg@10 : 0.6009    hit@10 : 0.7773    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7773    mrr@10 : 0.5454    ndcg@10 : 0.6009    hit@10 : 0.7773    precision@10 : 0.0777\n",
      "14 May 04:49    INFO  epoch 14 training [time: 18.76s, train loss: 159.4032]\n",
      "epoch 14 training [time: 18.76s, train loss: 159.4032]\n",
      "epoch 14 training [time: 18.76s, train loss: 159.4032]\n",
      "14 May 04:49    INFO  epoch 14 evaluating [time: 2.55s, valid_score: 0.545700]\n",
      "epoch 14 evaluating [time: 2.55s, valid_score: 0.545700]\n",
      "epoch 14 evaluating [time: 2.55s, valid_score: 0.545700]\n",
      "14 May 04:49    INFO  valid result: \n",
      "recall@10 : 0.7774    mrr@10 : 0.5457    ndcg@10 : 0.6011    hit@10 : 0.7774    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7774    mrr@10 : 0.5457    ndcg@10 : 0.6011    hit@10 : 0.7774    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7774    mrr@10 : 0.5457    ndcg@10 : 0.6011    hit@10 : 0.7774    precision@10 : 0.0777\n",
      "14 May 04:49    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:49    INFO  epoch 15 training [time: 18.80s, train loss: 157.5749]\n",
      "epoch 15 training [time: 18.80s, train loss: 157.5749]\n",
      "epoch 15 training [time: 18.80s, train loss: 157.5749]\n",
      "14 May 04:49    INFO  epoch 15 evaluating [time: 2.60s, valid_score: 0.545900]\n",
      "epoch 15 evaluating [time: 2.60s, valid_score: 0.545900]\n",
      "epoch 15 evaluating [time: 2.60s, valid_score: 0.545900]\n",
      "14 May 04:49    INFO  valid result: \n",
      "recall@10 : 0.7774    mrr@10 : 0.5459    ndcg@10 : 0.6014    hit@10 : 0.7774    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7774    mrr@10 : 0.5459    ndcg@10 : 0.6014    hit@10 : 0.7774    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7774    mrr@10 : 0.5459    ndcg@10 : 0.6014    hit@10 : 0.7774    precision@10 : 0.0777\n",
      "14 May 04:49    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:49    INFO  epoch 16 training [time: 18.66s, train loss: 156.2799]\n",
      "epoch 16 training [time: 18.66s, train loss: 156.2799]\n",
      "epoch 16 training [time: 18.66s, train loss: 156.2799]\n",
      "14 May 04:49    INFO  epoch 16 evaluating [time: 2.33s, valid_score: 0.547300]\n",
      "epoch 16 evaluating [time: 2.33s, valid_score: 0.547300]\n",
      "epoch 16 evaluating [time: 2.33s, valid_score: 0.547300]\n",
      "14 May 04:49    INFO  valid result: \n",
      "recall@10 : 0.7811    mrr@10 : 0.5473    ndcg@10 : 0.6032    hit@10 : 0.7811    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7811    mrr@10 : 0.5473    ndcg@10 : 0.6032    hit@10 : 0.7811    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7811    mrr@10 : 0.5473    ndcg@10 : 0.6032    hit@10 : 0.7811    precision@10 : 0.0781\n",
      "14 May 04:49    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:50    INFO  epoch 17 training [time: 18.84s, train loss: 155.1031]\n",
      "epoch 17 training [time: 18.84s, train loss: 155.1031]\n",
      "epoch 17 training [time: 18.84s, train loss: 155.1031]\n",
      "14 May 04:50    INFO  epoch 17 evaluating [time: 2.57s, valid_score: 0.546400]\n",
      "epoch 17 evaluating [time: 2.57s, valid_score: 0.546400]\n",
      "epoch 17 evaluating [time: 2.57s, valid_score: 0.546400]\n",
      "14 May 04:50    INFO  valid result: \n",
      "recall@10 : 0.7793    mrr@10 : 0.5464    ndcg@10 : 0.6021    hit@10 : 0.7793    precision@10 : 0.0779\n",
      "valid result: \n",
      "recall@10 : 0.7793    mrr@10 : 0.5464    ndcg@10 : 0.6021    hit@10 : 0.7793    precision@10 : 0.0779\n",
      "valid result: \n",
      "recall@10 : 0.7793    mrr@10 : 0.5464    ndcg@10 : 0.6021    hit@10 : 0.7793    precision@10 : 0.0779\n",
      "14 May 04:50    INFO  epoch 18 training [time: 18.55s, train loss: 159.6350]\n",
      "epoch 18 training [time: 18.55s, train loss: 159.6350]\n",
      "epoch 18 training [time: 18.55s, train loss: 159.6350]\n",
      "14 May 04:50    INFO  epoch 18 evaluating [time: 2.70s, valid_score: 0.547700]\n",
      "epoch 18 evaluating [time: 2.70s, valid_score: 0.547700]\n",
      "epoch 18 evaluating [time: 2.70s, valid_score: 0.547700]\n",
      "14 May 04:50    INFO  valid result: \n",
      "recall@10 : 0.7809    mrr@10 : 0.5477    ndcg@10 : 0.6035    hit@10 : 0.7809    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7809    mrr@10 : 0.5477    ndcg@10 : 0.6035    hit@10 : 0.7809    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7809    mrr@10 : 0.5477    ndcg@10 : 0.6035    hit@10 : 0.7809    precision@10 : 0.0781\n",
      "14 May 04:50    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:50    INFO  epoch 19 training [time: 18.73s, train loss: 155.0808]\n",
      "epoch 19 training [time: 18.73s, train loss: 155.0808]\n",
      "epoch 19 training [time: 18.73s, train loss: 155.0808]\n",
      "14 May 04:50    INFO  epoch 19 evaluating [time: 2.57s, valid_score: 0.546800]\n",
      "epoch 19 evaluating [time: 2.57s, valid_score: 0.546800]\n",
      "epoch 19 evaluating [time: 2.57s, valid_score: 0.546800]\n",
      "14 May 04:50    INFO  valid result: \n",
      "recall@10 : 0.7802    mrr@10 : 0.5468    ndcg@10 : 0.6025    hit@10 : 0.7802    precision@10 : 0.078\n",
      "valid result: \n",
      "recall@10 : 0.7802    mrr@10 : 0.5468    ndcg@10 : 0.6025    hit@10 : 0.7802    precision@10 : 0.078\n",
      "valid result: \n",
      "recall@10 : 0.7802    mrr@10 : 0.5468    ndcg@10 : 0.6025    hit@10 : 0.7802    precision@10 : 0.078\n",
      "14 May 04:51    INFO  epoch 20 training [time: 18.76s, train loss: 152.4749]\n",
      "epoch 20 training [time: 18.76s, train loss: 152.4749]\n",
      "epoch 20 training [time: 18.76s, train loss: 152.4749]\n",
      "14 May 04:51    INFO  epoch 20 evaluating [time: 2.62s, valid_score: 0.548500]\n",
      "epoch 20 evaluating [time: 2.62s, valid_score: 0.548500]\n",
      "epoch 20 evaluating [time: 2.62s, valid_score: 0.548500]\n",
      "14 May 04:51    INFO  valid result: \n",
      "recall@10 : 0.7804    mrr@10 : 0.5485    ndcg@10 : 0.604    hit@10 : 0.7804    precision@10 : 0.078\n",
      "valid result: \n",
      "recall@10 : 0.7804    mrr@10 : 0.5485    ndcg@10 : 0.604    hit@10 : 0.7804    precision@10 : 0.078\n",
      "valid result: \n",
      "recall@10 : 0.7804    mrr@10 : 0.5485    ndcg@10 : 0.604    hit@10 : 0.7804    precision@10 : 0.078\n",
      "14 May 04:51    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:51    INFO  epoch 21 training [time: 18.64s, train loss: 153.9766]\n",
      "epoch 21 training [time: 18.64s, train loss: 153.9766]\n",
      "epoch 21 training [time: 18.64s, train loss: 153.9766]\n",
      "14 May 04:51    INFO  epoch 21 evaluating [time: 2.55s, valid_score: 0.547800]\n",
      "epoch 21 evaluating [time: 2.55s, valid_score: 0.547800]\n",
      "epoch 21 evaluating [time: 2.55s, valid_score: 0.547800]\n",
      "14 May 04:51    INFO  valid result: \n",
      "recall@10 : 0.7824    mrr@10 : 0.5478    ndcg@10 : 0.604    hit@10 : 0.7824    precision@10 : 0.0782\n",
      "valid result: \n",
      "recall@10 : 0.7824    mrr@10 : 0.5478    ndcg@10 : 0.604    hit@10 : 0.7824    precision@10 : 0.0782\n",
      "valid result: \n",
      "recall@10 : 0.7824    mrr@10 : 0.5478    ndcg@10 : 0.604    hit@10 : 0.7824    precision@10 : 0.0782\n",
      "14 May 04:51    INFO  epoch 22 training [time: 18.96s, train loss: 152.4953]\n",
      "epoch 22 training [time: 18.96s, train loss: 152.4953]\n",
      "epoch 22 training [time: 18.96s, train loss: 152.4953]\n",
      "14 May 04:51    INFO  epoch 22 evaluating [time: 2.63s, valid_score: 0.548200]\n",
      "epoch 22 evaluating [time: 2.63s, valid_score: 0.548200]\n",
      "epoch 22 evaluating [time: 2.63s, valid_score: 0.548200]\n",
      "14 May 04:51    INFO  valid result: \n",
      "recall@10 : 0.7829    mrr@10 : 0.5482    ndcg@10 : 0.6044    hit@10 : 0.7829    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7829    mrr@10 : 0.5482    ndcg@10 : 0.6044    hit@10 : 0.7829    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7829    mrr@10 : 0.5482    ndcg@10 : 0.6044    hit@10 : 0.7829    precision@10 : 0.0783\n",
      "14 May 04:52    INFO  epoch 23 training [time: 18.69s, train loss: 154.3942]\n",
      "epoch 23 training [time: 18.69s, train loss: 154.3942]\n",
      "epoch 23 training [time: 18.69s, train loss: 154.3942]\n",
      "14 May 04:52    INFO  epoch 23 evaluating [time: 2.56s, valid_score: 0.548600]\n",
      "epoch 23 evaluating [time: 2.56s, valid_score: 0.548600]\n",
      "epoch 23 evaluating [time: 2.56s, valid_score: 0.548600]\n",
      "14 May 04:52    INFO  valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.5486    ndcg@10 : 0.6043    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.5486    ndcg@10 : 0.6043    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "valid result: \n",
      "recall@10 : 0.7814    mrr@10 : 0.5486    ndcg@10 : 0.6043    hit@10 : 0.7814    precision@10 : 0.0781\n",
      "14 May 04:52    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:52    INFO  epoch 24 training [time: 18.69s, train loss: 158.2563]\n",
      "epoch 24 training [time: 18.69s, train loss: 158.2563]\n",
      "epoch 24 training [time: 18.69s, train loss: 158.2563]\n",
      "14 May 04:52    INFO  epoch 24 evaluating [time: 2.67s, valid_score: 0.547800]\n",
      "epoch 24 evaluating [time: 2.67s, valid_score: 0.547800]\n",
      "epoch 24 evaluating [time: 2.67s, valid_score: 0.547800]\n",
      "14 May 04:52    INFO  valid result: \n",
      "recall@10 : 0.782    mrr@10 : 0.5478    ndcg@10 : 0.6038    hit@10 : 0.782    precision@10 : 0.0782\n",
      "valid result: \n",
      "recall@10 : 0.782    mrr@10 : 0.5478    ndcg@10 : 0.6038    hit@10 : 0.782    precision@10 : 0.0782\n",
      "valid result: \n",
      "recall@10 : 0.782    mrr@10 : 0.5478    ndcg@10 : 0.6038    hit@10 : 0.782    precision@10 : 0.0782\n",
      "14 May 04:52    INFO  epoch 25 training [time: 18.67s, train loss: 152.2389]\n",
      "epoch 25 training [time: 18.67s, train loss: 152.2389]\n",
      "epoch 25 training [time: 18.67s, train loss: 152.2389]\n",
      "14 May 04:52    INFO  epoch 25 evaluating [time: 2.60s, valid_score: 0.549000]\n",
      "epoch 25 evaluating [time: 2.60s, valid_score: 0.549000]\n",
      "epoch 25 evaluating [time: 2.60s, valid_score: 0.549000]\n",
      "14 May 04:52    INFO  valid result: \n",
      "recall@10 : 0.7838    mrr@10 : 0.549    ndcg@10 : 0.6052    hit@10 : 0.7838    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7838    mrr@10 : 0.549    ndcg@10 : 0.6052    hit@10 : 0.7838    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7838    mrr@10 : 0.549    ndcg@10 : 0.6052    hit@10 : 0.7838    precision@10 : 0.0784\n",
      "14 May 04:52    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:53    INFO  epoch 26 training [time: 18.67s, train loss: 152.2959]\n",
      "epoch 26 training [time: 18.67s, train loss: 152.2959]\n",
      "epoch 26 training [time: 18.67s, train loss: 152.2959]\n",
      "14 May 04:53    INFO  epoch 26 evaluating [time: 2.54s, valid_score: 0.548800]\n",
      "epoch 26 evaluating [time: 2.54s, valid_score: 0.548800]\n",
      "epoch 26 evaluating [time: 2.54s, valid_score: 0.548800]\n",
      "14 May 04:53    INFO  valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.5488    ndcg@10 : 0.6049    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.5488    ndcg@10 : 0.6049    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.5488    ndcg@10 : 0.6049    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "14 May 04:53    INFO  epoch 27 training [time: 18.70s, train loss: 150.7293]\n",
      "epoch 27 training [time: 18.70s, train loss: 150.7293]\n",
      "epoch 27 training [time: 18.70s, train loss: 150.7293]\n",
      "14 May 04:53    INFO  epoch 27 evaluating [time: 2.54s, valid_score: 0.548100]\n",
      "epoch 27 evaluating [time: 2.54s, valid_score: 0.548100]\n",
      "epoch 27 evaluating [time: 2.54s, valid_score: 0.548100]\n",
      "14 May 04:53    INFO  valid result: \n",
      "recall@10 : 0.7818    mrr@10 : 0.5481    ndcg@10 : 0.604    hit@10 : 0.7818    precision@10 : 0.0782\n",
      "valid result: \n",
      "recall@10 : 0.7818    mrr@10 : 0.5481    ndcg@10 : 0.604    hit@10 : 0.7818    precision@10 : 0.0782\n",
      "valid result: \n",
      "recall@10 : 0.7818    mrr@10 : 0.5481    ndcg@10 : 0.604    hit@10 : 0.7818    precision@10 : 0.0782\n",
      "14 May 04:54    INFO  epoch 28 training [time: 18.64s, train loss: 153.7742]\n",
      "epoch 28 training [time: 18.64s, train loss: 153.7742]\n",
      "epoch 28 training [time: 18.64s, train loss: 153.7742]\n",
      "14 May 04:54    INFO  epoch 28 evaluating [time: 2.71s, valid_score: 0.548900]\n",
      "epoch 28 evaluating [time: 2.71s, valid_score: 0.548900]\n",
      "epoch 28 evaluating [time: 2.71s, valid_score: 0.548900]\n",
      "14 May 04:54    INFO  valid result: \n",
      "recall@10 : 0.7843    mrr@10 : 0.5489    ndcg@10 : 0.6053    hit@10 : 0.7843    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7843    mrr@10 : 0.5489    ndcg@10 : 0.6053    hit@10 : 0.7843    precision@10 : 0.0784\n",
      "valid result: \n",
      "recall@10 : 0.7843    mrr@10 : 0.5489    ndcg@10 : 0.6053    hit@10 : 0.7843    precision@10 : 0.0784\n",
      "14 May 04:54    INFO  epoch 29 training [time: 18.67s, train loss: 146.9267]\n",
      "epoch 29 training [time: 18.67s, train loss: 146.9267]\n",
      "epoch 29 training [time: 18.67s, train loss: 146.9267]\n",
      "14 May 04:54    INFO  epoch 29 evaluating [time: 2.50s, valid_score: 0.549600]\n",
      "epoch 29 evaluating [time: 2.50s, valid_score: 0.549600]\n",
      "epoch 29 evaluating [time: 2.50s, valid_score: 0.549600]\n",
      "14 May 04:54    INFO  valid result: \n",
      "recall@10 : 0.7847    mrr@10 : 0.5496    ndcg@10 : 0.6058    hit@10 : 0.7847    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7847    mrr@10 : 0.5496    ndcg@10 : 0.6058    hit@10 : 0.7847    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7847    mrr@10 : 0.5496    ndcg@10 : 0.6058    hit@10 : 0.7847    precision@10 : 0.0785\n",
      "14 May 04:54    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:54    INFO  epoch 30 training [time: 18.54s, train loss: 152.8454]\n",
      "epoch 30 training [time: 18.54s, train loss: 152.8454]\n",
      "epoch 30 training [time: 18.54s, train loss: 152.8454]\n",
      "14 May 04:54    INFO  epoch 30 evaluating [time: 2.73s, valid_score: 0.549000]\n",
      "epoch 30 evaluating [time: 2.73s, valid_score: 0.549000]\n",
      "epoch 30 evaluating [time: 2.73s, valid_score: 0.549000]\n",
      "14 May 04:54    INFO  valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.549    ndcg@10 : 0.605    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.549    ndcg@10 : 0.605    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "valid result: \n",
      "recall@10 : 0.7832    mrr@10 : 0.549    ndcg@10 : 0.605    hit@10 : 0.7832    precision@10 : 0.0783\n",
      "14 May 04:55    INFO  epoch 31 training [time: 18.66s, train loss: 153.7173]\n",
      "epoch 31 training [time: 18.66s, train loss: 153.7173]\n",
      "epoch 31 training [time: 18.66s, train loss: 153.7173]\n",
      "14 May 04:55    INFO  epoch 31 evaluating [time: 2.59s, valid_score: 0.549100]\n",
      "epoch 31 evaluating [time: 2.59s, valid_score: 0.549100]\n",
      "epoch 31 evaluating [time: 2.59s, valid_score: 0.549100]\n",
      "14 May 04:55    INFO  valid result: \n",
      "recall@10 : 0.7852    mrr@10 : 0.5491    ndcg@10 : 0.6056    hit@10 : 0.7852    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7852    mrr@10 : 0.5491    ndcg@10 : 0.6056    hit@10 : 0.7852    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7852    mrr@10 : 0.5491    ndcg@10 : 0.6056    hit@10 : 0.7852    precision@10 : 0.0785\n",
      "14 May 04:55    INFO  epoch 32 training [time: 18.72s, train loss: 152.4689]\n",
      "epoch 32 training [time: 18.72s, train loss: 152.4689]\n",
      "epoch 32 training [time: 18.72s, train loss: 152.4689]\n",
      "14 May 04:55    INFO  epoch 32 evaluating [time: 2.56s, valid_score: 0.549600]\n",
      "epoch 32 evaluating [time: 2.56s, valid_score: 0.549600]\n",
      "epoch 32 evaluating [time: 2.56s, valid_score: 0.549600]\n",
      "14 May 04:55    INFO  valid result: \n",
      "recall@10 : 0.7859    mrr@10 : 0.5496    ndcg@10 : 0.6062    hit@10 : 0.7859    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7859    mrr@10 : 0.5496    ndcg@10 : 0.6062    hit@10 : 0.7859    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7859    mrr@10 : 0.5496    ndcg@10 : 0.6062    hit@10 : 0.7859    precision@10 : 0.0786\n",
      "14 May 04:55    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:55    INFO  epoch 33 training [time: 18.68s, train loss: 152.8524]\n",
      "epoch 33 training [time: 18.68s, train loss: 152.8524]\n",
      "epoch 33 training [time: 18.68s, train loss: 152.8524]\n",
      "14 May 04:55    INFO  epoch 33 evaluating [time: 2.55s, valid_score: 0.550600]\n",
      "epoch 33 evaluating [time: 2.55s, valid_score: 0.550600]\n",
      "epoch 33 evaluating [time: 2.55s, valid_score: 0.550600]\n",
      "14 May 04:55    INFO  valid result: \n",
      "recall@10 : 0.7852    mrr@10 : 0.5506    ndcg@10 : 0.6068    hit@10 : 0.7852    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7852    mrr@10 : 0.5506    ndcg@10 : 0.6068    hit@10 : 0.7852    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7852    mrr@10 : 0.5506    ndcg@10 : 0.6068    hit@10 : 0.7852    precision@10 : 0.0785\n",
      "14 May 04:55    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:56    INFO  epoch 34 training [time: 18.71s, train loss: 149.6717]\n",
      "epoch 34 training [time: 18.71s, train loss: 149.6717]\n",
      "epoch 34 training [time: 18.71s, train loss: 149.6717]\n",
      "14 May 04:56    INFO  epoch 34 evaluating [time: 2.66s, valid_score: 0.550700]\n",
      "epoch 34 evaluating [time: 2.66s, valid_score: 0.550700]\n",
      "epoch 34 evaluating [time: 2.66s, valid_score: 0.550700]\n",
      "14 May 04:56    INFO  valid result: \n",
      "recall@10 : 0.7881    mrr@10 : 0.5507    ndcg@10 : 0.6075    hit@10 : 0.7881    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7881    mrr@10 : 0.5507    ndcg@10 : 0.6075    hit@10 : 0.7881    precision@10 : 0.0788\n",
      "valid result: \n",
      "recall@10 : 0.7881    mrr@10 : 0.5507    ndcg@10 : 0.6075    hit@10 : 0.7881    precision@10 : 0.0788\n",
      "14 May 04:56    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 May 04:56    INFO  epoch 35 training [time: 18.82s, train loss: 149.7253]\n",
      "epoch 35 training [time: 18.82s, train loss: 149.7253]\n",
      "epoch 35 training [time: 18.82s, train loss: 149.7253]\n",
      "14 May 04:56    INFO  epoch 35 evaluating [time: 2.53s, valid_score: 0.550200]\n",
      "epoch 35 evaluating [time: 2.53s, valid_score: 0.550200]\n",
      "epoch 35 evaluating [time: 2.53s, valid_score: 0.550200]\n",
      "14 May 04:56    INFO  valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5502    ndcg@10 : 0.6068    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5502    ndcg@10 : 0.6068    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5502    ndcg@10 : 0.6068    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "14 May 04:56    INFO  epoch 36 training [time: 18.99s, train loss: 146.1932]\n",
      "epoch 36 training [time: 18.99s, train loss: 146.1932]\n",
      "epoch 36 training [time: 18.99s, train loss: 146.1932]\n",
      "14 May 04:56    INFO  epoch 36 evaluating [time: 2.71s, valid_score: 0.550100]\n",
      "epoch 36 evaluating [time: 2.71s, valid_score: 0.550100]\n",
      "epoch 36 evaluating [time: 2.71s, valid_score: 0.550100]\n",
      "14 May 04:56    INFO  valid result: \n",
      "recall@10 : 0.7874    mrr@10 : 0.5501    ndcg@10 : 0.6068    hit@10 : 0.7874    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7874    mrr@10 : 0.5501    ndcg@10 : 0.6068    hit@10 : 0.7874    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7874    mrr@10 : 0.5501    ndcg@10 : 0.6068    hit@10 : 0.7874    precision@10 : 0.0787\n",
      "14 May 04:57    INFO  epoch 37 training [time: 18.79s, train loss: 148.2714]\n",
      "epoch 37 training [time: 18.79s, train loss: 148.2714]\n",
      "epoch 37 training [time: 18.79s, train loss: 148.2714]\n",
      "14 May 04:57    INFO  epoch 37 evaluating [time: 2.46s, valid_score: 0.550100]\n",
      "epoch 37 evaluating [time: 2.46s, valid_score: 0.550100]\n",
      "epoch 37 evaluating [time: 2.46s, valid_score: 0.550100]\n",
      "14 May 04:57    INFO  valid result: \n",
      "recall@10 : 0.7858    mrr@10 : 0.5501    ndcg@10 : 0.6065    hit@10 : 0.7858    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7858    mrr@10 : 0.5501    ndcg@10 : 0.6065    hit@10 : 0.7858    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7858    mrr@10 : 0.5501    ndcg@10 : 0.6065    hit@10 : 0.7858    precision@10 : 0.0786\n",
      "14 May 04:57    INFO  epoch 38 training [time: 18.78s, train loss: 151.4109]\n",
      "epoch 38 training [time: 18.78s, train loss: 151.4109]\n",
      "epoch 38 training [time: 18.78s, train loss: 151.4109]\n",
      "14 May 04:57    INFO  epoch 38 evaluating [time: 2.45s, valid_score: 0.550300]\n",
      "epoch 38 evaluating [time: 2.45s, valid_score: 0.550300]\n",
      "epoch 38 evaluating [time: 2.45s, valid_score: 0.550300]\n",
      "14 May 04:57    INFO  valid result: \n",
      "recall@10 : 0.7856    mrr@10 : 0.5503    ndcg@10 : 0.6066    hit@10 : 0.7856    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7856    mrr@10 : 0.5503    ndcg@10 : 0.6066    hit@10 : 0.7856    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7856    mrr@10 : 0.5503    ndcg@10 : 0.6066    hit@10 : 0.7856    precision@10 : 0.0786\n",
      "14 May 04:57    INFO  epoch 39 training [time: 18.76s, train loss: 148.9168]\n",
      "epoch 39 training [time: 18.76s, train loss: 148.9168]\n",
      "epoch 39 training [time: 18.76s, train loss: 148.9168]\n",
      "14 May 04:57    INFO  epoch 39 evaluating [time: 2.43s, valid_score: 0.550100]\n",
      "epoch 39 evaluating [time: 2.43s, valid_score: 0.550100]\n",
      "epoch 39 evaluating [time: 2.43s, valid_score: 0.550100]\n",
      "14 May 04:57    INFO  valid result: \n",
      "recall@10 : 0.7862    mrr@10 : 0.5501    ndcg@10 : 0.6066    hit@10 : 0.7862    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7862    mrr@10 : 0.5501    ndcg@10 : 0.6066    hit@10 : 0.7862    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7862    mrr@10 : 0.5501    ndcg@10 : 0.6066    hit@10 : 0.7862    precision@10 : 0.0786\n",
      "14 May 04:58    INFO  epoch 40 training [time: 18.64s, train loss: 148.4299]\n",
      "epoch 40 training [time: 18.64s, train loss: 148.4299]\n",
      "epoch 40 training [time: 18.64s, train loss: 148.4299]\n",
      "14 May 04:58    INFO  epoch 40 evaluating [time: 2.63s, valid_score: 0.550300]\n",
      "epoch 40 evaluating [time: 2.63s, valid_score: 0.550300]\n",
      "epoch 40 evaluating [time: 2.63s, valid_score: 0.550300]\n",
      "14 May 04:58    INFO  valid result: \n",
      "recall@10 : 0.7849    mrr@10 : 0.5503    ndcg@10 : 0.6064    hit@10 : 0.7849    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7849    mrr@10 : 0.5503    ndcg@10 : 0.6064    hit@10 : 0.7849    precision@10 : 0.0785\n",
      "valid result: \n",
      "recall@10 : 0.7849    mrr@10 : 0.5503    ndcg@10 : 0.6064    hit@10 : 0.7849    precision@10 : 0.0785\n",
      "14 May 04:58    INFO  epoch 41 training [time: 18.66s, train loss: 148.9353]\n",
      "epoch 41 training [time: 18.66s, train loss: 148.9353]\n",
      "epoch 41 training [time: 18.66s, train loss: 148.9353]\n",
      "14 May 04:58    INFO  epoch 41 evaluating [time: 2.64s, valid_score: 0.550700]\n",
      "epoch 41 evaluating [time: 2.64s, valid_score: 0.550700]\n",
      "epoch 41 evaluating [time: 2.64s, valid_score: 0.550700]\n",
      "14 May 04:58    INFO  valid result: \n",
      "recall@10 : 0.7859    mrr@10 : 0.5507    ndcg@10 : 0.607    hit@10 : 0.7859    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7859    mrr@10 : 0.5507    ndcg@10 : 0.607    hit@10 : 0.7859    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7859    mrr@10 : 0.5507    ndcg@10 : 0.607    hit@10 : 0.7859    precision@10 : 0.0786\n",
      "14 May 04:58    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:58    INFO  epoch 42 training [time: 18.68s, train loss: 151.0926]\n",
      "epoch 42 training [time: 18.68s, train loss: 151.0926]\n",
      "epoch 42 training [time: 18.68s, train loss: 151.0926]\n",
      "14 May 04:59    INFO  epoch 42 evaluating [time: 2.54s, valid_score: 0.550600]\n",
      "epoch 42 evaluating [time: 2.54s, valid_score: 0.550600]\n",
      "epoch 42 evaluating [time: 2.54s, valid_score: 0.550600]\n",
      "14 May 04:59    INFO  valid result: \n",
      "recall@10 : 0.7862    mrr@10 : 0.5506    ndcg@10 : 0.6069    hit@10 : 0.7862    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7862    mrr@10 : 0.5506    ndcg@10 : 0.6069    hit@10 : 0.7862    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7862    mrr@10 : 0.5506    ndcg@10 : 0.6069    hit@10 : 0.7862    precision@10 : 0.0786\n",
      "14 May 04:59    INFO  epoch 43 training [time: 18.83s, train loss: 153.1933]\n",
      "epoch 43 training [time: 18.83s, train loss: 153.1933]\n",
      "epoch 43 training [time: 18.83s, train loss: 153.1933]\n",
      "14 May 04:59    INFO  epoch 43 evaluating [time: 2.51s, valid_score: 0.551200]\n",
      "epoch 43 evaluating [time: 2.51s, valid_score: 0.551200]\n",
      "epoch 43 evaluating [time: 2.51s, valid_score: 0.551200]\n",
      "14 May 04:59    INFO  valid result: \n",
      "recall@10 : 0.7874    mrr@10 : 0.5512    ndcg@10 : 0.6078    hit@10 : 0.7874    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7874    mrr@10 : 0.5512    ndcg@10 : 0.6078    hit@10 : 0.7874    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7874    mrr@10 : 0.5512    ndcg@10 : 0.6078    hit@10 : 0.7874    precision@10 : 0.0787\n",
      "14 May 04:59    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "14 May 04:59    INFO  epoch 44 training [time: 18.87s, train loss: 151.4004]\n",
      "epoch 44 training [time: 18.87s, train loss: 151.4004]\n",
      "epoch 44 training [time: 18.87s, train loss: 151.4004]\n",
      "14 May 04:59    INFO  epoch 44 evaluating [time: 2.57s, valid_score: 0.551900]\n",
      "epoch 44 evaluating [time: 2.57s, valid_score: 0.551900]\n",
      "epoch 44 evaluating [time: 2.57s, valid_score: 0.551900]\n",
      "14 May 04:59    INFO  valid result: \n",
      "recall@10 : 0.7902    mrr@10 : 0.5519    ndcg@10 : 0.6088    hit@10 : 0.7902    precision@10 : 0.079\n",
      "valid result: \n",
      "recall@10 : 0.7902    mrr@10 : 0.5519    ndcg@10 : 0.6088    hit@10 : 0.7902    precision@10 : 0.079\n",
      "valid result: \n",
      "recall@10 : 0.7902    mrr@10 : 0.5519    ndcg@10 : 0.6088    hit@10 : 0.7902    precision@10 : 0.079\n",
      "14 May 04:59    INFO  Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n",
      "Saving current: ./model_checkpoints\\BERT4Rec-May-14-2024_04-43-43.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 May 05:00    INFO  epoch 45 training [time: 18.92s, train loss: 147.1604]\n",
      "epoch 45 training [time: 18.92s, train loss: 147.1604]\n",
      "epoch 45 training [time: 18.92s, train loss: 147.1604]\n",
      "14 May 05:00    INFO  epoch 45 evaluating [time: 2.48s, valid_score: 0.551800]\n",
      "epoch 45 evaluating [time: 2.48s, valid_score: 0.551800]\n",
      "epoch 45 evaluating [time: 2.48s, valid_score: 0.551800]\n",
      "14 May 05:00    INFO  valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5518    ndcg@10 : 0.608    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5518    ndcg@10 : 0.608    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5518    ndcg@10 : 0.608    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "14 May 05:00    INFO  epoch 46 training [time: 18.73s, train loss: 149.3211]\n",
      "epoch 46 training [time: 18.73s, train loss: 149.3211]\n",
      "epoch 46 training [time: 18.73s, train loss: 149.3211]\n",
      "14 May 05:00    INFO  epoch 46 evaluating [time: 2.53s, valid_score: 0.551200]\n",
      "epoch 46 evaluating [time: 2.53s, valid_score: 0.551200]\n",
      "epoch 46 evaluating [time: 2.53s, valid_score: 0.551200]\n",
      "14 May 05:00    INFO  valid result: \n",
      "recall@10 : 0.7866    mrr@10 : 0.5512    ndcg@10 : 0.6075    hit@10 : 0.7866    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7866    mrr@10 : 0.5512    ndcg@10 : 0.6075    hit@10 : 0.7866    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7866    mrr@10 : 0.5512    ndcg@10 : 0.6075    hit@10 : 0.7866    precision@10 : 0.0787\n",
      "14 May 05:00    INFO  epoch 47 training [time: 18.61s, train loss: 152.2484]\n",
      "epoch 47 training [time: 18.61s, train loss: 152.2484]\n",
      "epoch 47 training [time: 18.61s, train loss: 152.2484]\n",
      "14 May 05:00    INFO  epoch 47 evaluating [time: 2.65s, valid_score: 0.550600]\n",
      "epoch 47 evaluating [time: 2.65s, valid_score: 0.550600]\n",
      "epoch 47 evaluating [time: 2.65s, valid_score: 0.550600]\n",
      "14 May 05:00    INFO  valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5506    ndcg@10 : 0.6071    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5506    ndcg@10 : 0.6071    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7872    mrr@10 : 0.5506    ndcg@10 : 0.6071    hit@10 : 0.7872    precision@10 : 0.0787\n",
      "14 May 05:01    INFO  epoch 48 training [time: 18.68s, train loss: 143.8610]\n",
      "epoch 48 training [time: 18.68s, train loss: 143.8610]\n",
      "epoch 48 training [time: 18.68s, train loss: 143.8610]\n",
      "14 May 05:01    INFO  epoch 48 evaluating [time: 2.59s, valid_score: 0.550600]\n",
      "epoch 48 evaluating [time: 2.59s, valid_score: 0.550600]\n",
      "epoch 48 evaluating [time: 2.59s, valid_score: 0.550600]\n",
      "14 May 05:01    INFO  valid result: \n",
      "recall@10 : 0.7859    mrr@10 : 0.5506    ndcg@10 : 0.607    hit@10 : 0.7859    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7859    mrr@10 : 0.5506    ndcg@10 : 0.607    hit@10 : 0.7859    precision@10 : 0.0786\n",
      "valid result: \n",
      "recall@10 : 0.7859    mrr@10 : 0.5506    ndcg@10 : 0.607    hit@10 : 0.7859    precision@10 : 0.0786\n",
      "14 May 05:01    INFO  epoch 49 training [time: 18.72s, train loss: 150.1461]\n",
      "epoch 49 training [time: 18.72s, train loss: 150.1461]\n",
      "epoch 49 training [time: 18.72s, train loss: 150.1461]\n",
      "14 May 05:01    INFO  epoch 49 evaluating [time: 2.63s, valid_score: 0.550600]\n",
      "epoch 49 evaluating [time: 2.63s, valid_score: 0.550600]\n",
      "epoch 49 evaluating [time: 2.63s, valid_score: 0.550600]\n",
      "14 May 05:01    INFO  valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5506    ndcg@10 : 0.6072    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5506    ndcg@10 : 0.6072    hit@10 : 0.7868    precision@10 : 0.0787\n",
      "valid result: \n",
      "recall@10 : 0.7868    mrr@10 : 0.5506    ndcg@10 : 0.6072    hit@10 : 0.7868    precision@10 : 0.0787\n"
     ]
    }
   ],
   "source": [
    "config2 = Config(model='BERT4Rec', dataset='recbox_data', config_dict=parameter_dict_SASRec)\n",
    "\n",
    "#run_recbole(model='SASRec', dataset='recbox_data', config_dict=parameter_dict_SASRec)\n",
    "init_seed(config2['seed'], config2['reproducibility'])\n",
    "logger = init_logger(config2)\n",
    "dataset = create_dataset(config2)\n",
    "train_data, valid_data, test_data = data_preparation(config2, dataset)\n",
    "\n",
    "# Step 5: Training\n",
    "model_BERT = BERT4Rec(config2, train_data.dataset).to(config2['device'])\n",
    "trainer = Trainer(config2, model_BERT)\n",
    "\n",
    "# Train and evaluate the model\n",
    "best_valid_score_BERT, best_valid_result_BERT = trainer.fit(train_data, valid_data, saved=True)\n",
    "\n",
    "model_save_path = config2['checkpoint_dir'] + '/model_BERT4Rec.pth'\n",
    "\n",
    "torch.save(model_BERT.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 May 05:01    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "14 May 05:01    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}, 'topk': 30}]\n",
      "14 May 05:01    INFO  epoch 0 training [time: 3.28s, train loss: 402.9037]\n",
      "epoch 0 training [time: 3.28s, train loss: 402.9037]\n",
      "epoch 0 training [time: 3.28s, train loss: 402.9037]\n",
      "14 May 05:01    INFO  epoch 0 evaluating [time: 0.11s, valid_score: 0.452100]\n",
      "epoch 0 evaluating [time: 0.11s, valid_score: 0.452100]\n",
      "epoch 0 evaluating [time: 0.11s, valid_score: 0.452100]\n",
      "14 May 05:01    INFO  valid result: \n",
      "recall@10 : 0.6043    mrr@10 : 0.4521    ndcg@10 : 0.4888    hit@10 : 0.6043    precision@10 : 0.0604\n",
      "valid result: \n",
      "recall@10 : 0.6043    mrr@10 : 0.4521    ndcg@10 : 0.4888    hit@10 : 0.6043    precision@10 : 0.0604\n",
      "valid result: \n",
      "recall@10 : 0.6043    mrr@10 : 0.4521    ndcg@10 : 0.4888    hit@10 : 0.6043    precision@10 : 0.0604\n",
      "14 May 05:01    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:01    INFO  epoch 1 training [time: 3.21s, train loss: 266.8557]\n",
      "epoch 1 training [time: 3.21s, train loss: 266.8557]\n",
      "epoch 1 training [time: 3.21s, train loss: 266.8557]\n",
      "14 May 05:01    INFO  epoch 1 evaluating [time: 0.11s, valid_score: 0.482300]\n",
      "epoch 1 evaluating [time: 0.11s, valid_score: 0.482300]\n",
      "epoch 1 evaluating [time: 0.11s, valid_score: 0.482300]\n",
      "14 May 05:01    INFO  valid result: \n",
      "recall@10 : 0.6636    mrr@10 : 0.4823    ndcg@10 : 0.526    hit@10 : 0.6636    precision@10 : 0.0664\n",
      "valid result: \n",
      "recall@10 : 0.6636    mrr@10 : 0.4823    ndcg@10 : 0.526    hit@10 : 0.6636    precision@10 : 0.0664\n",
      "valid result: \n",
      "recall@10 : 0.6636    mrr@10 : 0.4823    ndcg@10 : 0.526    hit@10 : 0.6636    precision@10 : 0.0664\n",
      "14 May 05:01    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:01    INFO  epoch 2 training [time: 3.17s, train loss: 221.1089]\n",
      "epoch 2 training [time: 3.17s, train loss: 221.1089]\n",
      "epoch 2 training [time: 3.17s, train loss: 221.1089]\n",
      "14 May 05:01    INFO  epoch 2 evaluating [time: 0.12s, valid_score: 0.497200]\n",
      "epoch 2 evaluating [time: 0.12s, valid_score: 0.497200]\n",
      "epoch 2 evaluating [time: 0.12s, valid_score: 0.497200]\n",
      "14 May 05:01    INFO  valid result: \n",
      "recall@10 : 0.6985    mrr@10 : 0.4972    ndcg@10 : 0.5455    hit@10 : 0.6985    precision@10 : 0.0698\n",
      "valid result: \n",
      "recall@10 : 0.6985    mrr@10 : 0.4972    ndcg@10 : 0.5455    hit@10 : 0.6985    precision@10 : 0.0698\n",
      "valid result: \n",
      "recall@10 : 0.6985    mrr@10 : 0.4972    ndcg@10 : 0.5455    hit@10 : 0.6985    precision@10 : 0.0698\n",
      "14 May 05:01    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:01    INFO  epoch 3 training [time: 3.17s, train loss: 204.5010]\n",
      "epoch 3 training [time: 3.17s, train loss: 204.5010]\n",
      "epoch 3 training [time: 3.17s, train loss: 204.5010]\n",
      "14 May 05:01    INFO  epoch 3 evaluating [time: 0.13s, valid_score: 0.504100]\n",
      "epoch 3 evaluating [time: 0.13s, valid_score: 0.504100]\n",
      "epoch 3 evaluating [time: 0.13s, valid_score: 0.504100]\n",
      "14 May 05:01    INFO  valid result: \n",
      "recall@10 : 0.7151    mrr@10 : 0.5041    ndcg@10 : 0.5546    hit@10 : 0.7151    precision@10 : 0.0715\n",
      "valid result: \n",
      "recall@10 : 0.7151    mrr@10 : 0.5041    ndcg@10 : 0.5546    hit@10 : 0.7151    precision@10 : 0.0715\n",
      "valid result: \n",
      "recall@10 : 0.7151    mrr@10 : 0.5041    ndcg@10 : 0.5546    hit@10 : 0.7151    precision@10 : 0.0715\n",
      "14 May 05:01    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:01    INFO  epoch 4 training [time: 3.21s, train loss: 196.1777]\n",
      "epoch 4 training [time: 3.21s, train loss: 196.1777]\n",
      "epoch 4 training [time: 3.21s, train loss: 196.1777]\n",
      "14 May 05:01    INFO  epoch 4 evaluating [time: 0.13s, valid_score: 0.508800]\n",
      "epoch 4 evaluating [time: 0.13s, valid_score: 0.508800]\n",
      "epoch 4 evaluating [time: 0.13s, valid_score: 0.508800]\n",
      "14 May 05:01    INFO  valid result: \n",
      "recall@10 : 0.724    mrr@10 : 0.5088    ndcg@10 : 0.5603    hit@10 : 0.724    precision@10 : 0.0724\n",
      "valid result: \n",
      "recall@10 : 0.724    mrr@10 : 0.5088    ndcg@10 : 0.5603    hit@10 : 0.724    precision@10 : 0.0724\n",
      "valid result: \n",
      "recall@10 : 0.724    mrr@10 : 0.5088    ndcg@10 : 0.5603    hit@10 : 0.724    precision@10 : 0.0724\n",
      "14 May 05:01    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:01    INFO  epoch 5 training [time: 3.19s, train loss: 191.2056]\n",
      "epoch 5 training [time: 3.19s, train loss: 191.2056]\n",
      "epoch 5 training [time: 3.19s, train loss: 191.2056]\n",
      "14 May 05:01    INFO  epoch 5 evaluating [time: 0.12s, valid_score: 0.512700]\n",
      "epoch 5 evaluating [time: 0.12s, valid_score: 0.512700]\n",
      "epoch 5 evaluating [time: 0.12s, valid_score: 0.512700]\n",
      "14 May 05:01    INFO  valid result: \n",
      "recall@10 : 0.7319    mrr@10 : 0.5127    ndcg@10 : 0.5651    hit@10 : 0.7319    precision@10 : 0.0732\n",
      "valid result: \n",
      "recall@10 : 0.7319    mrr@10 : 0.5127    ndcg@10 : 0.5651    hit@10 : 0.7319    precision@10 : 0.0732\n",
      "valid result: \n",
      "recall@10 : 0.7319    mrr@10 : 0.5127    ndcg@10 : 0.5651    hit@10 : 0.7319    precision@10 : 0.0732\n",
      "14 May 05:01    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 6 training [time: 3.22s, train loss: 187.8965]\n",
      "epoch 6 training [time: 3.22s, train loss: 187.8965]\n",
      "epoch 6 training [time: 3.22s, train loss: 187.8965]\n",
      "14 May 05:02    INFO  epoch 6 evaluating [time: 0.12s, valid_score: 0.516400]\n",
      "epoch 6 evaluating [time: 0.12s, valid_score: 0.516400]\n",
      "epoch 6 evaluating [time: 0.12s, valid_score: 0.516400]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7367    mrr@10 : 0.5164    ndcg@10 : 0.5691    hit@10 : 0.7367    precision@10 : 0.0737\n",
      "valid result: \n",
      "recall@10 : 0.7367    mrr@10 : 0.5164    ndcg@10 : 0.5691    hit@10 : 0.7367    precision@10 : 0.0737\n",
      "valid result: \n",
      "recall@10 : 0.7367    mrr@10 : 0.5164    ndcg@10 : 0.5691    hit@10 : 0.7367    precision@10 : 0.0737\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 7 training [time: 3.17s, train loss: 185.4825]\n",
      "epoch 7 training [time: 3.17s, train loss: 185.4825]\n",
      "epoch 7 training [time: 3.17s, train loss: 185.4825]\n",
      "14 May 05:02    INFO  epoch 7 evaluating [time: 0.11s, valid_score: 0.518700]\n",
      "epoch 7 evaluating [time: 0.11s, valid_score: 0.518700]\n",
      "epoch 7 evaluating [time: 0.11s, valid_score: 0.518700]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7405    mrr@10 : 0.5187    ndcg@10 : 0.5717    hit@10 : 0.7405    precision@10 : 0.074\n",
      "valid result: \n",
      "recall@10 : 0.7405    mrr@10 : 0.5187    ndcg@10 : 0.5717    hit@10 : 0.7405    precision@10 : 0.074\n",
      "valid result: \n",
      "recall@10 : 0.7405    mrr@10 : 0.5187    ndcg@10 : 0.5717    hit@10 : 0.7405    precision@10 : 0.074\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 8 training [time: 3.18s, train loss: 183.6258]\n",
      "epoch 8 training [time: 3.18s, train loss: 183.6258]\n",
      "epoch 8 training [time: 3.18s, train loss: 183.6258]\n",
      "14 May 05:02    INFO  epoch 8 evaluating [time: 0.11s, valid_score: 0.520400]\n",
      "epoch 8 evaluating [time: 0.11s, valid_score: 0.520400]\n",
      "epoch 8 evaluating [time: 0.11s, valid_score: 0.520400]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7439    mrr@10 : 0.5204    ndcg@10 : 0.5738    hit@10 : 0.7439    precision@10 : 0.0744\n",
      "valid result: \n",
      "recall@10 : 0.7439    mrr@10 : 0.5204    ndcg@10 : 0.5738    hit@10 : 0.7439    precision@10 : 0.0744\n",
      "valid result: \n",
      "recall@10 : 0.7439    mrr@10 : 0.5204    ndcg@10 : 0.5738    hit@10 : 0.7439    precision@10 : 0.0744\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 9 training [time: 3.15s, train loss: 182.1192]\n",
      "epoch 9 training [time: 3.15s, train loss: 182.1192]\n",
      "epoch 9 training [time: 3.15s, train loss: 182.1192]\n",
      "14 May 05:02    INFO  epoch 9 evaluating [time: 0.13s, valid_score: 0.523500]\n",
      "epoch 9 evaluating [time: 0.13s, valid_score: 0.523500]\n",
      "epoch 9 evaluating [time: 0.13s, valid_score: 0.523500]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7468    mrr@10 : 0.5235    ndcg@10 : 0.5769    hit@10 : 0.7468    precision@10 : 0.0747\n",
      "valid result: \n",
      "recall@10 : 0.7468    mrr@10 : 0.5235    ndcg@10 : 0.5769    hit@10 : 0.7468    precision@10 : 0.0747\n",
      "valid result: \n",
      "recall@10 : 0.7468    mrr@10 : 0.5235    ndcg@10 : 0.5769    hit@10 : 0.7468    precision@10 : 0.0747\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 10 training [time: 3.17s, train loss: 180.8581]\n",
      "epoch 10 training [time: 3.17s, train loss: 180.8581]\n",
      "epoch 10 training [time: 3.17s, train loss: 180.8581]\n",
      "14 May 05:02    INFO  epoch 10 evaluating [time: 0.14s, valid_score: 0.525000]\n",
      "epoch 10 evaluating [time: 0.14s, valid_score: 0.525000]\n",
      "epoch 10 evaluating [time: 0.14s, valid_score: 0.525000]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7488    mrr@10 : 0.525    ndcg@10 : 0.5785    hit@10 : 0.7488    precision@10 : 0.0749\n",
      "valid result: \n",
      "recall@10 : 0.7488    mrr@10 : 0.525    ndcg@10 : 0.5785    hit@10 : 0.7488    precision@10 : 0.0749\n",
      "valid result: \n",
      "recall@10 : 0.7488    mrr@10 : 0.525    ndcg@10 : 0.5785    hit@10 : 0.7488    precision@10 : 0.0749\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 11 training [time: 3.21s, train loss: 179.7458]\n",
      "epoch 11 training [time: 3.21s, train loss: 179.7458]\n",
      "epoch 11 training [time: 3.21s, train loss: 179.7458]\n",
      "14 May 05:02    INFO  epoch 11 evaluating [time: 0.11s, valid_score: 0.526900]\n",
      "epoch 11 evaluating [time: 0.11s, valid_score: 0.526900]\n",
      "epoch 11 evaluating [time: 0.11s, valid_score: 0.526900]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7513    mrr@10 : 0.5269    ndcg@10 : 0.5806    hit@10 : 0.7513    precision@10 : 0.0751\n",
      "valid result: \n",
      "recall@10 : 0.7513    mrr@10 : 0.5269    ndcg@10 : 0.5806    hit@10 : 0.7513    precision@10 : 0.0751\n",
      "valid result: \n",
      "recall@10 : 0.7513    mrr@10 : 0.5269    ndcg@10 : 0.5806    hit@10 : 0.7513    precision@10 : 0.0751\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 12 training [time: 3.15s, train loss: 178.7914]\n",
      "epoch 12 training [time: 3.15s, train loss: 178.7914]\n",
      "epoch 12 training [time: 3.15s, train loss: 178.7914]\n",
      "14 May 05:02    INFO  epoch 12 evaluating [time: 0.12s, valid_score: 0.528100]\n",
      "epoch 12 evaluating [time: 0.12s, valid_score: 0.528100]\n",
      "epoch 12 evaluating [time: 0.12s, valid_score: 0.528100]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7527    mrr@10 : 0.5281    ndcg@10 : 0.5818    hit@10 : 0.7527    precision@10 : 0.0753\n",
      "valid result: \n",
      "recall@10 : 0.7527    mrr@10 : 0.5281    ndcg@10 : 0.5818    hit@10 : 0.7527    precision@10 : 0.0753\n",
      "valid result: \n",
      "recall@10 : 0.7527    mrr@10 : 0.5281    ndcg@10 : 0.5818    hit@10 : 0.7527    precision@10 : 0.0753\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 13 training [time: 3.19s, train loss: 177.9799]\n",
      "epoch 13 training [time: 3.19s, train loss: 177.9799]\n",
      "epoch 13 training [time: 3.19s, train loss: 177.9799]\n",
      "14 May 05:02    INFO  epoch 13 evaluating [time: 0.12s, valid_score: 0.530000]\n",
      "epoch 13 evaluating [time: 0.12s, valid_score: 0.530000]\n",
      "epoch 13 evaluating [time: 0.12s, valid_score: 0.530000]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7559    mrr@10 : 0.53    ndcg@10 : 0.584    hit@10 : 0.7559    precision@10 : 0.0756\n",
      "valid result: \n",
      "recall@10 : 0.7559    mrr@10 : 0.53    ndcg@10 : 0.584    hit@10 : 0.7559    precision@10 : 0.0756\n",
      "valid result: \n",
      "recall@10 : 0.7559    mrr@10 : 0.53    ndcg@10 : 0.584    hit@10 : 0.7559    precision@10 : 0.0756\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 14 training [time: 3.17s, train loss: 177.2236]\n",
      "epoch 14 training [time: 3.17s, train loss: 177.2236]\n",
      "epoch 14 training [time: 3.17s, train loss: 177.2236]\n",
      "14 May 05:02    INFO  epoch 14 evaluating [time: 0.11s, valid_score: 0.530400]\n",
      "epoch 14 evaluating [time: 0.11s, valid_score: 0.530400]\n",
      "epoch 14 evaluating [time: 0.11s, valid_score: 0.530400]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7565    mrr@10 : 0.5304    ndcg@10 : 0.5845    hit@10 : 0.7565    precision@10 : 0.0757\n",
      "valid result: \n",
      "recall@10 : 0.7565    mrr@10 : 0.5304    ndcg@10 : 0.5845    hit@10 : 0.7565    precision@10 : 0.0757\n",
      "valid result: \n",
      "recall@10 : 0.7565    mrr@10 : 0.5304    ndcg@10 : 0.5845    hit@10 : 0.7565    precision@10 : 0.0757\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 15 training [time: 3.17s, train loss: 176.5426]\n",
      "epoch 15 training [time: 3.17s, train loss: 176.5426]\n",
      "epoch 15 training [time: 3.17s, train loss: 176.5426]\n",
      "14 May 05:02    INFO  epoch 15 evaluating [time: 0.11s, valid_score: 0.532000]\n",
      "epoch 15 evaluating [time: 0.11s, valid_score: 0.532000]\n",
      "epoch 15 evaluating [time: 0.11s, valid_score: 0.532000]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.759    mrr@10 : 0.532    ndcg@10 : 0.5863    hit@10 : 0.759    precision@10 : 0.0759\n",
      "valid result: \n",
      "recall@10 : 0.759    mrr@10 : 0.532    ndcg@10 : 0.5863    hit@10 : 0.759    precision@10 : 0.0759\n",
      "valid result: \n",
      "recall@10 : 0.759    mrr@10 : 0.532    ndcg@10 : 0.5863    hit@10 : 0.759    precision@10 : 0.0759\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 16 training [time: 3.19s, train loss: 175.9486]\n",
      "epoch 16 training [time: 3.19s, train loss: 175.9486]\n",
      "epoch 16 training [time: 3.19s, train loss: 175.9486]\n",
      "14 May 05:02    INFO  epoch 16 evaluating [time: 0.13s, valid_score: 0.532400]\n",
      "epoch 16 evaluating [time: 0.13s, valid_score: 0.532400]\n",
      "epoch 16 evaluating [time: 0.13s, valid_score: 0.532400]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7599    mrr@10 : 0.5324    ndcg@10 : 0.5868    hit@10 : 0.7599    precision@10 : 0.076\n",
      "valid result: \n",
      "recall@10 : 0.7599    mrr@10 : 0.5324    ndcg@10 : 0.5868    hit@10 : 0.7599    precision@10 : 0.076\n",
      "valid result: \n",
      "recall@10 : 0.7599    mrr@10 : 0.5324    ndcg@10 : 0.5868    hit@10 : 0.7599    precision@10 : 0.076\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 17 training [time: 3.15s, train loss: 175.3742]\n",
      "epoch 17 training [time: 3.15s, train loss: 175.3742]\n",
      "epoch 17 training [time: 3.15s, train loss: 175.3742]\n",
      "14 May 05:02    INFO  epoch 17 evaluating [time: 0.14s, valid_score: 0.533500]\n",
      "epoch 17 evaluating [time: 0.14s, valid_score: 0.533500]\n",
      "epoch 17 evaluating [time: 0.14s, valid_score: 0.533500]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7614    mrr@10 : 0.5335    ndcg@10 : 0.588    hit@10 : 0.7614    precision@10 : 0.0761\n",
      "valid result: \n",
      "recall@10 : 0.7614    mrr@10 : 0.5335    ndcg@10 : 0.588    hit@10 : 0.7614    precision@10 : 0.0761\n",
      "valid result: \n",
      "recall@10 : 0.7614    mrr@10 : 0.5335    ndcg@10 : 0.588    hit@10 : 0.7614    precision@10 : 0.0761\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 18 training [time: 3.18s, train loss: 174.8858]\n",
      "epoch 18 training [time: 3.18s, train loss: 174.8858]\n",
      "epoch 18 training [time: 3.18s, train loss: 174.8858]\n",
      "14 May 05:02    INFO  epoch 18 evaluating [time: 0.11s, valid_score: 0.534200]\n",
      "epoch 18 evaluating [time: 0.11s, valid_score: 0.534200]\n",
      "epoch 18 evaluating [time: 0.11s, valid_score: 0.534200]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7624    mrr@10 : 0.5342    ndcg@10 : 0.5887    hit@10 : 0.7624    precision@10 : 0.0762\n",
      "valid result: \n",
      "recall@10 : 0.7624    mrr@10 : 0.5342    ndcg@10 : 0.5887    hit@10 : 0.7624    precision@10 : 0.0762\n",
      "valid result: \n",
      "recall@10 : 0.7624    mrr@10 : 0.5342    ndcg@10 : 0.5887    hit@10 : 0.7624    precision@10 : 0.0762\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 19 training [time: 3.17s, train loss: 174.4198]\n",
      "epoch 19 training [time: 3.17s, train loss: 174.4198]\n",
      "epoch 19 training [time: 3.17s, train loss: 174.4198]\n",
      "14 May 05:02    INFO  epoch 19 evaluating [time: 0.11s, valid_score: 0.535100]\n",
      "epoch 19 evaluating [time: 0.11s, valid_score: 0.535100]\n",
      "epoch 19 evaluating [time: 0.11s, valid_score: 0.535100]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7634    mrr@10 : 0.5351    ndcg@10 : 0.5897    hit@10 : 0.7634    precision@10 : 0.0763\n",
      "valid result: \n",
      "recall@10 : 0.7634    mrr@10 : 0.5351    ndcg@10 : 0.5897    hit@10 : 0.7634    precision@10 : 0.0763\n",
      "valid result: \n",
      "recall@10 : 0.7634    mrr@10 : 0.5351    ndcg@10 : 0.5897    hit@10 : 0.7634    precision@10 : 0.0763\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 20 training [time: 3.21s, train loss: 174.0077]\n",
      "epoch 20 training [time: 3.21s, train loss: 174.0077]\n",
      "epoch 20 training [time: 3.21s, train loss: 174.0077]\n",
      "14 May 05:02    INFO  epoch 20 evaluating [time: 0.11s, valid_score: 0.535800]\n",
      "epoch 20 evaluating [time: 0.11s, valid_score: 0.535800]\n",
      "epoch 20 evaluating [time: 0.11s, valid_score: 0.535800]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7644    mrr@10 : 0.5358    ndcg@10 : 0.5904    hit@10 : 0.7644    precision@10 : 0.0764\n",
      "valid result: \n",
      "recall@10 : 0.7644    mrr@10 : 0.5358    ndcg@10 : 0.5904    hit@10 : 0.7644    precision@10 : 0.0764\n",
      "valid result: \n",
      "recall@10 : 0.7644    mrr@10 : 0.5358    ndcg@10 : 0.5904    hit@10 : 0.7644    precision@10 : 0.0764\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 21 training [time: 3.17s, train loss: 173.6078]\n",
      "epoch 21 training [time: 3.17s, train loss: 173.6078]\n",
      "epoch 21 training [time: 3.17s, train loss: 173.6078]\n",
      "14 May 05:02    INFO  epoch 21 evaluating [time: 0.12s, valid_score: 0.536400]\n",
      "epoch 21 evaluating [time: 0.12s, valid_score: 0.536400]\n",
      "epoch 21 evaluating [time: 0.12s, valid_score: 0.536400]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.765    mrr@10 : 0.5364    ndcg@10 : 0.5911    hit@10 : 0.765    precision@10 : 0.0765\n",
      "valid result: \n",
      "recall@10 : 0.765    mrr@10 : 0.5364    ndcg@10 : 0.5911    hit@10 : 0.765    precision@10 : 0.0765\n",
      "valid result: \n",
      "recall@10 : 0.765    mrr@10 : 0.5364    ndcg@10 : 0.5911    hit@10 : 0.765    precision@10 : 0.0765\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 22 training [time: 3.19s, train loss: 173.2555]\n",
      "epoch 22 training [time: 3.19s, train loss: 173.2555]\n",
      "epoch 22 training [time: 3.19s, train loss: 173.2555]\n",
      "14 May 05:02    INFO  epoch 22 evaluating [time: 0.13s, valid_score: 0.537400]\n",
      "epoch 22 evaluating [time: 0.13s, valid_score: 0.537400]\n",
      "epoch 22 evaluating [time: 0.13s, valid_score: 0.537400]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7653    mrr@10 : 0.5374    ndcg@10 : 0.5919    hit@10 : 0.7653    precision@10 : 0.0765\n",
      "valid result: \n",
      "recall@10 : 0.7653    mrr@10 : 0.5374    ndcg@10 : 0.5919    hit@10 : 0.7653    precision@10 : 0.0765\n",
      "valid result: \n",
      "recall@10 : 0.7653    mrr@10 : 0.5374    ndcg@10 : 0.5919    hit@10 : 0.7653    precision@10 : 0.0765\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:02    INFO  epoch 23 training [time: 3.18s, train loss: 172.9065]\n",
      "epoch 23 training [time: 3.18s, train loss: 172.9065]\n",
      "epoch 23 training [time: 3.18s, train loss: 172.9065]\n",
      "14 May 05:02    INFO  epoch 23 evaluating [time: 0.13s, valid_score: 0.537900]\n",
      "epoch 23 evaluating [time: 0.13s, valid_score: 0.537900]\n",
      "epoch 23 evaluating [time: 0.13s, valid_score: 0.537900]\n",
      "14 May 05:02    INFO  valid result: \n",
      "recall@10 : 0.7668    mrr@10 : 0.5379    ndcg@10 : 0.5926    hit@10 : 0.7668    precision@10 : 0.0767\n",
      "valid result: \n",
      "recall@10 : 0.7668    mrr@10 : 0.5379    ndcg@10 : 0.5926    hit@10 : 0.7668    precision@10 : 0.0767\n",
      "valid result: \n",
      "recall@10 : 0.7668    mrr@10 : 0.5379    ndcg@10 : 0.5926    hit@10 : 0.7668    precision@10 : 0.0767\n",
      "14 May 05:02    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 24 training [time: 3.20s, train loss: 172.6078]\n",
      "epoch 24 training [time: 3.20s, train loss: 172.6078]\n",
      "epoch 24 training [time: 3.20s, train loss: 172.6078]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 May 05:03    INFO  epoch 24 evaluating [time: 0.12s, valid_score: 0.538000]\n",
      "epoch 24 evaluating [time: 0.12s, valid_score: 0.538000]\n",
      "epoch 24 evaluating [time: 0.12s, valid_score: 0.538000]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7676    mrr@10 : 0.538    ndcg@10 : 0.5929    hit@10 : 0.7676    precision@10 : 0.0768\n",
      "valid result: \n",
      "recall@10 : 0.7676    mrr@10 : 0.538    ndcg@10 : 0.5929    hit@10 : 0.7676    precision@10 : 0.0768\n",
      "valid result: \n",
      "recall@10 : 0.7676    mrr@10 : 0.538    ndcg@10 : 0.5929    hit@10 : 0.7676    precision@10 : 0.0768\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 25 training [time: 3.18s, train loss: 172.3060]\n",
      "epoch 25 training [time: 3.18s, train loss: 172.3060]\n",
      "epoch 25 training [time: 3.18s, train loss: 172.3060]\n",
      "14 May 05:03    INFO  epoch 25 evaluating [time: 0.12s, valid_score: 0.538400]\n",
      "epoch 25 evaluating [time: 0.12s, valid_score: 0.538400]\n",
      "epoch 25 evaluating [time: 0.12s, valid_score: 0.538400]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7682    mrr@10 : 0.5384    ndcg@10 : 0.5933    hit@10 : 0.7682    precision@10 : 0.0768\n",
      "valid result: \n",
      "recall@10 : 0.7682    mrr@10 : 0.5384    ndcg@10 : 0.5933    hit@10 : 0.7682    precision@10 : 0.0768\n",
      "valid result: \n",
      "recall@10 : 0.7682    mrr@10 : 0.5384    ndcg@10 : 0.5933    hit@10 : 0.7682    precision@10 : 0.0768\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 26 training [time: 3.20s, train loss: 172.0437]\n",
      "epoch 26 training [time: 3.20s, train loss: 172.0437]\n",
      "epoch 26 training [time: 3.20s, train loss: 172.0437]\n",
      "14 May 05:03    INFO  epoch 26 evaluating [time: 0.11s, valid_score: 0.538900]\n",
      "epoch 26 evaluating [time: 0.11s, valid_score: 0.538900]\n",
      "epoch 26 evaluating [time: 0.11s, valid_score: 0.538900]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.769    mrr@10 : 0.5389    ndcg@10 : 0.5939    hit@10 : 0.769    precision@10 : 0.0769\n",
      "valid result: \n",
      "recall@10 : 0.769    mrr@10 : 0.5389    ndcg@10 : 0.5939    hit@10 : 0.769    precision@10 : 0.0769\n",
      "valid result: \n",
      "recall@10 : 0.769    mrr@10 : 0.5389    ndcg@10 : 0.5939    hit@10 : 0.769    precision@10 : 0.0769\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 27 training [time: 3.13s, train loss: 171.7700]\n",
      "epoch 27 training [time: 3.13s, train loss: 171.7700]\n",
      "epoch 27 training [time: 3.13s, train loss: 171.7700]\n",
      "14 May 05:03    INFO  epoch 27 evaluating [time: 0.12s, valid_score: 0.539200]\n",
      "epoch 27 evaluating [time: 0.12s, valid_score: 0.539200]\n",
      "epoch 27 evaluating [time: 0.12s, valid_score: 0.539200]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7695    mrr@10 : 0.5392    ndcg@10 : 0.5942    hit@10 : 0.7695    precision@10 : 0.077\n",
      "valid result: \n",
      "recall@10 : 0.7695    mrr@10 : 0.5392    ndcg@10 : 0.5942    hit@10 : 0.7695    precision@10 : 0.077\n",
      "valid result: \n",
      "recall@10 : 0.7695    mrr@10 : 0.5392    ndcg@10 : 0.5942    hit@10 : 0.7695    precision@10 : 0.077\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 28 training [time: 3.22s, train loss: 171.5494]\n",
      "epoch 28 training [time: 3.22s, train loss: 171.5494]\n",
      "epoch 28 training [time: 3.22s, train loss: 171.5494]\n",
      "14 May 05:03    INFO  epoch 28 evaluating [time: 0.12s, valid_score: 0.539800]\n",
      "epoch 28 evaluating [time: 0.12s, valid_score: 0.539800]\n",
      "epoch 28 evaluating [time: 0.12s, valid_score: 0.539800]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7701    mrr@10 : 0.5398    ndcg@10 : 0.5949    hit@10 : 0.7701    precision@10 : 0.077\n",
      "valid result: \n",
      "recall@10 : 0.7701    mrr@10 : 0.5398    ndcg@10 : 0.5949    hit@10 : 0.7701    precision@10 : 0.077\n",
      "valid result: \n",
      "recall@10 : 0.7701    mrr@10 : 0.5398    ndcg@10 : 0.5949    hit@10 : 0.7701    precision@10 : 0.077\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 29 training [time: 3.20s, train loss: 171.3144]\n",
      "epoch 29 training [time: 3.20s, train loss: 171.3144]\n",
      "epoch 29 training [time: 3.20s, train loss: 171.3144]\n",
      "14 May 05:03    INFO  epoch 29 evaluating [time: 0.13s, valid_score: 0.540200]\n",
      "epoch 29 evaluating [time: 0.13s, valid_score: 0.540200]\n",
      "epoch 29 evaluating [time: 0.13s, valid_score: 0.540200]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7715    mrr@10 : 0.5402    ndcg@10 : 0.5955    hit@10 : 0.7715    precision@10 : 0.0771\n",
      "valid result: \n",
      "recall@10 : 0.7715    mrr@10 : 0.5402    ndcg@10 : 0.5955    hit@10 : 0.7715    precision@10 : 0.0771\n",
      "valid result: \n",
      "recall@10 : 0.7715    mrr@10 : 0.5402    ndcg@10 : 0.5955    hit@10 : 0.7715    precision@10 : 0.0771\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 30 training [time: 3.22s, train loss: 171.1036]\n",
      "epoch 30 training [time: 3.22s, train loss: 171.1036]\n",
      "epoch 30 training [time: 3.22s, train loss: 171.1036]\n",
      "14 May 05:03    INFO  epoch 30 evaluating [time: 0.12s, valid_score: 0.540400]\n",
      "epoch 30 evaluating [time: 0.12s, valid_score: 0.540400]\n",
      "epoch 30 evaluating [time: 0.12s, valid_score: 0.540400]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7715    mrr@10 : 0.5404    ndcg@10 : 0.5956    hit@10 : 0.7715    precision@10 : 0.0772\n",
      "valid result: \n",
      "recall@10 : 0.7715    mrr@10 : 0.5404    ndcg@10 : 0.5956    hit@10 : 0.7715    precision@10 : 0.0772\n",
      "valid result: \n",
      "recall@10 : 0.7715    mrr@10 : 0.5404    ndcg@10 : 0.5956    hit@10 : 0.7715    precision@10 : 0.0772\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 31 training [time: 3.16s, train loss: 170.8776]\n",
      "epoch 31 training [time: 3.16s, train loss: 170.8776]\n",
      "epoch 31 training [time: 3.16s, train loss: 170.8776]\n",
      "14 May 05:03    INFO  epoch 31 evaluating [time: 0.13s, valid_score: 0.541100]\n",
      "epoch 31 evaluating [time: 0.13s, valid_score: 0.541100]\n",
      "epoch 31 evaluating [time: 0.13s, valid_score: 0.541100]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7723    mrr@10 : 0.5411    ndcg@10 : 0.5964    hit@10 : 0.7723    precision@10 : 0.0772\n",
      "valid result: \n",
      "recall@10 : 0.7723    mrr@10 : 0.5411    ndcg@10 : 0.5964    hit@10 : 0.7723    precision@10 : 0.0772\n",
      "valid result: \n",
      "recall@10 : 0.7723    mrr@10 : 0.5411    ndcg@10 : 0.5964    hit@10 : 0.7723    precision@10 : 0.0772\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 32 training [time: 3.16s, train loss: 170.6862]\n",
      "epoch 32 training [time: 3.16s, train loss: 170.6862]\n",
      "epoch 32 training [time: 3.16s, train loss: 170.6862]\n",
      "14 May 05:03    INFO  epoch 32 evaluating [time: 0.13s, valid_score: 0.541100]\n",
      "epoch 32 evaluating [time: 0.13s, valid_score: 0.541100]\n",
      "epoch 32 evaluating [time: 0.13s, valid_score: 0.541100]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7729    mrr@10 : 0.5411    ndcg@10 : 0.5965    hit@10 : 0.7729    precision@10 : 0.0773\n",
      "valid result: \n",
      "recall@10 : 0.7729    mrr@10 : 0.5411    ndcg@10 : 0.5965    hit@10 : 0.7729    precision@10 : 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid result: \n",
      "recall@10 : 0.7729    mrr@10 : 0.5411    ndcg@10 : 0.5965    hit@10 : 0.7729    precision@10 : 0.0773\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 33 training [time: 3.20s, train loss: 170.5127]\n",
      "epoch 33 training [time: 3.20s, train loss: 170.5127]\n",
      "epoch 33 training [time: 3.20s, train loss: 170.5127]\n",
      "14 May 05:03    INFO  epoch 33 evaluating [time: 0.11s, valid_score: 0.542200]\n",
      "epoch 33 evaluating [time: 0.11s, valid_score: 0.542200]\n",
      "epoch 33 evaluating [time: 0.11s, valid_score: 0.542200]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7732    mrr@10 : 0.5422    ndcg@10 : 0.5974    hit@10 : 0.7732    precision@10 : 0.0773\n",
      "valid result: \n",
      "recall@10 : 0.7732    mrr@10 : 0.5422    ndcg@10 : 0.5974    hit@10 : 0.7732    precision@10 : 0.0773\n",
      "valid result: \n",
      "recall@10 : 0.7732    mrr@10 : 0.5422    ndcg@10 : 0.5974    hit@10 : 0.7732    precision@10 : 0.0773\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 34 training [time: 3.17s, train loss: 170.3387]\n",
      "epoch 34 training [time: 3.17s, train loss: 170.3387]\n",
      "epoch 34 training [time: 3.17s, train loss: 170.3387]\n",
      "14 May 05:03    INFO  epoch 34 evaluating [time: 0.13s, valid_score: 0.541800]\n",
      "epoch 34 evaluating [time: 0.13s, valid_score: 0.541800]\n",
      "epoch 34 evaluating [time: 0.13s, valid_score: 0.541800]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7729    mrr@10 : 0.5418    ndcg@10 : 0.5971    hit@10 : 0.7729    precision@10 : 0.0773\n",
      "valid result: \n",
      "recall@10 : 0.7729    mrr@10 : 0.5418    ndcg@10 : 0.5971    hit@10 : 0.7729    precision@10 : 0.0773\n",
      "valid result: \n",
      "recall@10 : 0.7729    mrr@10 : 0.5418    ndcg@10 : 0.5971    hit@10 : 0.7729    precision@10 : 0.0773\n",
      "14 May 05:03    INFO  epoch 35 training [time: 3.18s, train loss: 170.1736]\n",
      "epoch 35 training [time: 3.18s, train loss: 170.1736]\n",
      "epoch 35 training [time: 3.18s, train loss: 170.1736]\n",
      "14 May 05:03    INFO  epoch 35 evaluating [time: 0.11s, valid_score: 0.541900]\n",
      "epoch 35 evaluating [time: 0.11s, valid_score: 0.541900]\n",
      "epoch 35 evaluating [time: 0.11s, valid_score: 0.541900]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7746    mrr@10 : 0.5419    ndcg@10 : 0.5975    hit@10 : 0.7746    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7746    mrr@10 : 0.5419    ndcg@10 : 0.5975    hit@10 : 0.7746    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7746    mrr@10 : 0.5419    ndcg@10 : 0.5975    hit@10 : 0.7746    precision@10 : 0.0775\n",
      "14 May 05:03    INFO  epoch 36 training [time: 3.20s, train loss: 170.0231]\n",
      "epoch 36 training [time: 3.20s, train loss: 170.0231]\n",
      "epoch 36 training [time: 3.20s, train loss: 170.0231]\n",
      "14 May 05:03    INFO  epoch 36 evaluating [time: 0.13s, valid_score: 0.542100]\n",
      "epoch 36 evaluating [time: 0.13s, valid_score: 0.542100]\n",
      "epoch 36 evaluating [time: 0.13s, valid_score: 0.542100]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7747    mrr@10 : 0.5421    ndcg@10 : 0.5977    hit@10 : 0.7747    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7747    mrr@10 : 0.5421    ndcg@10 : 0.5977    hit@10 : 0.7747    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7747    mrr@10 : 0.5421    ndcg@10 : 0.5977    hit@10 : 0.7747    precision@10 : 0.0775\n",
      "14 May 05:03    INFO  epoch 37 training [time: 3.17s, train loss: 169.8631]\n",
      "epoch 37 training [time: 3.17s, train loss: 169.8631]\n",
      "epoch 37 training [time: 3.17s, train loss: 169.8631]\n",
      "14 May 05:03    INFO  epoch 37 evaluating [time: 0.12s, valid_score: 0.542500]\n",
      "epoch 37 evaluating [time: 0.12s, valid_score: 0.542500]\n",
      "epoch 37 evaluating [time: 0.12s, valid_score: 0.542500]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7751    mrr@10 : 0.5425    ndcg@10 : 0.5981    hit@10 : 0.7751    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7751    mrr@10 : 0.5425    ndcg@10 : 0.5981    hit@10 : 0.7751    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7751    mrr@10 : 0.5425    ndcg@10 : 0.5981    hit@10 : 0.7751    precision@10 : 0.0775\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 38 training [time: 3.17s, train loss: 169.7211]\n",
      "epoch 38 training [time: 3.17s, train loss: 169.7211]\n",
      "epoch 38 training [time: 3.17s, train loss: 169.7211]\n",
      "14 May 05:03    INFO  epoch 38 evaluating [time: 0.11s, valid_score: 0.543100]\n",
      "epoch 38 evaluating [time: 0.11s, valid_score: 0.543100]\n",
      "epoch 38 evaluating [time: 0.11s, valid_score: 0.543100]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7755    mrr@10 : 0.5431    ndcg@10 : 0.5986    hit@10 : 0.7755    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7755    mrr@10 : 0.5431    ndcg@10 : 0.5986    hit@10 : 0.7755    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7755    mrr@10 : 0.5431    ndcg@10 : 0.5986    hit@10 : 0.7755    precision@10 : 0.0775\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:03    INFO  epoch 39 training [time: 3.21s, train loss: 169.5826]\n",
      "epoch 39 training [time: 3.21s, train loss: 169.5826]\n",
      "epoch 39 training [time: 3.21s, train loss: 169.5826]\n",
      "14 May 05:03    INFO  epoch 39 evaluating [time: 0.13s, valid_score: 0.542900]\n",
      "epoch 39 evaluating [time: 0.13s, valid_score: 0.542900]\n",
      "epoch 39 evaluating [time: 0.13s, valid_score: 0.542900]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7756    mrr@10 : 0.5429    ndcg@10 : 0.5985    hit@10 : 0.7756    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7756    mrr@10 : 0.5429    ndcg@10 : 0.5985    hit@10 : 0.7756    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7756    mrr@10 : 0.5429    ndcg@10 : 0.5985    hit@10 : 0.7756    precision@10 : 0.0776\n",
      "14 May 05:03    INFO  epoch 40 training [time: 3.21s, train loss: 169.4271]\n",
      "epoch 40 training [time: 3.21s, train loss: 169.4271]\n",
      "epoch 40 training [time: 3.21s, train loss: 169.4271]\n",
      "14 May 05:03    INFO  epoch 40 evaluating [time: 0.12s, valid_score: 0.542800]\n",
      "epoch 40 evaluating [time: 0.12s, valid_score: 0.542800]\n",
      "epoch 40 evaluating [time: 0.12s, valid_score: 0.542800]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7758    mrr@10 : 0.5428    ndcg@10 : 0.5985    hit@10 : 0.7758    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7758    mrr@10 : 0.5428    ndcg@10 : 0.5985    hit@10 : 0.7758    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7758    mrr@10 : 0.5428    ndcg@10 : 0.5985    hit@10 : 0.7758    precision@10 : 0.0776\n",
      "14 May 05:03    INFO  epoch 41 training [time: 3.20s, train loss: 169.3090]\n",
      "epoch 41 training [time: 3.20s, train loss: 169.3090]\n",
      "epoch 41 training [time: 3.20s, train loss: 169.3090]\n",
      "14 May 05:03    INFO  epoch 41 evaluating [time: 0.12s, valid_score: 0.543200]\n",
      "epoch 41 evaluating [time: 0.12s, valid_score: 0.543200]\n",
      "epoch 41 evaluating [time: 0.12s, valid_score: 0.543200]\n",
      "14 May 05:03    INFO  valid result: \n",
      "recall@10 : 0.7754    mrr@10 : 0.5432    ndcg@10 : 0.5987    hit@10 : 0.7754    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7754    mrr@10 : 0.5432    ndcg@10 : 0.5987    hit@10 : 0.7754    precision@10 : 0.0775\n",
      "valid result: \n",
      "recall@10 : 0.7754    mrr@10 : 0.5432    ndcg@10 : 0.5987    hit@10 : 0.7754    precision@10 : 0.0775\n",
      "14 May 05:03    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:04    INFO  epoch 42 training [time: 3.21s, train loss: 169.1842]\n",
      "epoch 42 training [time: 3.21s, train loss: 169.1842]\n",
      "epoch 42 training [time: 3.21s, train loss: 169.1842]\n",
      "14 May 05:04    INFO  epoch 42 evaluating [time: 0.12s, valid_score: 0.543400]\n",
      "epoch 42 evaluating [time: 0.12s, valid_score: 0.543400]\n",
      "epoch 42 evaluating [time: 0.12s, valid_score: 0.543400]\n",
      "14 May 05:04    INFO  valid result: \n",
      "recall@10 : 0.7763    mrr@10 : 0.5434    ndcg@10 : 0.5991    hit@10 : 0.7763    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7763    mrr@10 : 0.5434    ndcg@10 : 0.5991    hit@10 : 0.7763    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7763    mrr@10 : 0.5434    ndcg@10 : 0.5991    hit@10 : 0.7763    precision@10 : 0.0776\n",
      "14 May 05:04    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:04    INFO  epoch 43 training [time: 3.19s, train loss: 169.0583]\n",
      "epoch 43 training [time: 3.19s, train loss: 169.0583]\n",
      "epoch 43 training [time: 3.19s, train loss: 169.0583]\n",
      "14 May 05:04    INFO  epoch 43 evaluating [time: 0.11s, valid_score: 0.543500]\n",
      "epoch 43 evaluating [time: 0.11s, valid_score: 0.543500]\n",
      "epoch 43 evaluating [time: 0.11s, valid_score: 0.543500]\n",
      "14 May 05:04    INFO  valid result: \n",
      "recall@10 : 0.7762    mrr@10 : 0.5435    ndcg@10 : 0.5992    hit@10 : 0.7762    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7762    mrr@10 : 0.5435    ndcg@10 : 0.5992    hit@10 : 0.7762    precision@10 : 0.0776\n",
      "valid result: \n",
      "recall@10 : 0.7762    mrr@10 : 0.5435    ndcg@10 : 0.5992    hit@10 : 0.7762    precision@10 : 0.0776\n",
      "14 May 05:04    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:04    INFO  epoch 44 training [time: 3.19s, train loss: 168.9485]\n",
      "epoch 44 training [time: 3.19s, train loss: 168.9485]\n",
      "epoch 44 training [time: 3.19s, train loss: 168.9485]\n",
      "14 May 05:04    INFO  epoch 44 evaluating [time: 0.13s, valid_score: 0.544200]\n",
      "epoch 44 evaluating [time: 0.13s, valid_score: 0.544200]\n",
      "epoch 44 evaluating [time: 0.13s, valid_score: 0.544200]\n",
      "14 May 05:04    INFO  valid result: \n",
      "recall@10 : 0.7768    mrr@10 : 0.5442    ndcg@10 : 0.5998    hit@10 : 0.7768    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7768    mrr@10 : 0.5442    ndcg@10 : 0.5998    hit@10 : 0.7768    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7768    mrr@10 : 0.5442    ndcg@10 : 0.5998    hit@10 : 0.7768    precision@10 : 0.0777\n",
      "14 May 05:04    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:04    INFO  epoch 45 training [time: 3.17s, train loss: 168.8383]\n",
      "epoch 45 training [time: 3.17s, train loss: 168.8383]\n",
      "epoch 45 training [time: 3.17s, train loss: 168.8383]\n",
      "14 May 05:04    INFO  epoch 45 evaluating [time: 0.12s, valid_score: 0.543900]\n",
      "epoch 45 evaluating [time: 0.12s, valid_score: 0.543900]\n",
      "epoch 45 evaluating [time: 0.12s, valid_score: 0.543900]\n",
      "14 May 05:04    INFO  valid result: \n",
      "recall@10 : 0.7767    mrr@10 : 0.5439    ndcg@10 : 0.5996    hit@10 : 0.7767    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7767    mrr@10 : 0.5439    ndcg@10 : 0.5996    hit@10 : 0.7767    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7767    mrr@10 : 0.5439    ndcg@10 : 0.5996    hit@10 : 0.7767    precision@10 : 0.0777\n",
      "14 May 05:04    INFO  epoch 46 training [time: 3.21s, train loss: 168.7176]\n",
      "epoch 46 training [time: 3.21s, train loss: 168.7176]\n",
      "epoch 46 training [time: 3.21s, train loss: 168.7176]\n",
      "14 May 05:04    INFO  epoch 46 evaluating [time: 0.14s, valid_score: 0.544300]\n",
      "epoch 46 evaluating [time: 0.14s, valid_score: 0.544300]\n",
      "epoch 46 evaluating [time: 0.14s, valid_score: 0.544300]\n",
      "14 May 05:04    INFO  valid result: \n",
      "recall@10 : 0.7767    mrr@10 : 0.5443    ndcg@10 : 0.5998    hit@10 : 0.7767    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7767    mrr@10 : 0.5443    ndcg@10 : 0.5998    hit@10 : 0.7767    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7767    mrr@10 : 0.5443    ndcg@10 : 0.5998    hit@10 : 0.7767    precision@10 : 0.0777\n",
      "14 May 05:04    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:04    INFO  epoch 47 training [time: 3.18s, train loss: 168.6219]\n",
      "epoch 47 training [time: 3.18s, train loss: 168.6219]\n",
      "epoch 47 training [time: 3.18s, train loss: 168.6219]\n",
      "14 May 05:04    INFO  epoch 47 evaluating [time: 0.13s, valid_score: 0.544300]\n",
      "epoch 47 evaluating [time: 0.13s, valid_score: 0.544300]\n",
      "epoch 47 evaluating [time: 0.13s, valid_score: 0.544300]\n",
      "14 May 05:04    INFO  valid result: \n",
      "recall@10 : 0.7778    mrr@10 : 0.5443    ndcg@10 : 0.6001    hit@10 : 0.7778    precision@10 : 0.0778\n",
      "valid result: \n",
      "recall@10 : 0.7778    mrr@10 : 0.5443    ndcg@10 : 0.6001    hit@10 : 0.7778    precision@10 : 0.0778\n",
      "valid result: \n",
      "recall@10 : 0.7778    mrr@10 : 0.5443    ndcg@10 : 0.6001    hit@10 : 0.7778    precision@10 : 0.0778\n",
      "14 May 05:04    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:04    INFO  epoch 48 training [time: 3.19s, train loss: 168.5193]\n",
      "epoch 48 training [time: 3.19s, train loss: 168.5193]\n",
      "epoch 48 training [time: 3.19s, train loss: 168.5193]\n",
      "14 May 05:04    INFO  epoch 48 evaluating [time: 0.12s, valid_score: 0.544800]\n",
      "epoch 48 evaluating [time: 0.12s, valid_score: 0.544800]\n",
      "epoch 48 evaluating [time: 0.12s, valid_score: 0.544800]\n",
      "14 May 05:04    INFO  valid result: \n",
      "recall@10 : 0.7773    mrr@10 : 0.5448    ndcg@10 : 0.6004    hit@10 : 0.7773    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7773    mrr@10 : 0.5448    ndcg@10 : 0.6004    hit@10 : 0.7773    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7773    mrr@10 : 0.5448    ndcg@10 : 0.6004    hit@10 : 0.7773    precision@10 : 0.0777\n",
      "14 May 05:04    INFO  Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "Saving current: ./model_checkpoints\\FOSSIL-May-14-2024_05-01-36.pth\n",
      "14 May 05:04    INFO  epoch 49 training [time: 3.16s, train loss: 168.4169]\n",
      "epoch 49 training [time: 3.16s, train loss: 168.4169]\n",
      "epoch 49 training [time: 3.16s, train loss: 168.4169]\n",
      "14 May 05:04    INFO  epoch 49 evaluating [time: 0.11s, valid_score: 0.544600]\n",
      "epoch 49 evaluating [time: 0.11s, valid_score: 0.544600]\n",
      "epoch 49 evaluating [time: 0.11s, valid_score: 0.544600]\n",
      "14 May 05:04    INFO  valid result: \n",
      "recall@10 : 0.7773    mrr@10 : 0.5446    ndcg@10 : 0.6003    hit@10 : 0.7773    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7773    mrr@10 : 0.5446    ndcg@10 : 0.6003    hit@10 : 0.7773    precision@10 : 0.0777\n",
      "valid result: \n",
      "recall@10 : 0.7773    mrr@10 : 0.5446    ndcg@10 : 0.6003    hit@10 : 0.7773    precision@10 : 0.0777\n"
     ]
    }
   ],
   "source": [
    "config2 = Config(model='FOSSIL', dataset='recbox_data', config_dict=parameter_dict_SASRec)\n",
    "\n",
    "#run_recbole(model='SASRec', dataset='recbox_data', config_dict=parameter_dict_SASRec)\n",
    "init_seed(config2['seed'], config2['reproducibility'])\n",
    "logger = init_logger(config2)\n",
    "dataset = create_dataset(config2)\n",
    "train_data, valid_data, test_data = data_preparation(config2, dataset)\n",
    "\n",
    "# Step 5: Training\n",
    "model_fossil = FOSSIL(config2, train_data.dataset).to(config2['device'])\n",
    "trainer = Trainer(config2, model_fossil)\n",
    "\n",
    "# Train and evaluate the model\n",
    "best_valid_score_fossil, best_valid_result_fossil = trainer.fit(train_data, valid_data, saved=True)\n",
    "\n",
    "model_save_path = config2['checkpoint_dir'] + '/model_FOSSIL.pth'\n",
    "\n",
    "torch.save(model_fossil.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = torch.tensor([test_dt.newid[0]])  # User ID in tensor\n",
    "item = torch.tensor([test_dt.taz[0]])\n",
    "\n",
    "model_FPMC.predict(user, item)\n",
    "# Item ID in tensor\n",
    "#model_FPMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed(config['seed'], config['reproducibility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Apr 11:45    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../SUMO_simulation/recbox_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "loss_type = BPR\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "neg_sampling = None\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../SUMO_simulation/recbox_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "loss_type = BPR\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "neg_sampling = None\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Apr 21:32    INFO  recbox_data\n",
      "The number of users: 13710\n",
      "Average actions of users: 16.57276241884893\n",
      "The number of items: 168\n",
      "Average actions of items: 1360.4550898203593\n",
      "The number of inters: 227196\n",
      "The sparsity of the dataset: 90.13597999374805%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "recbox_data\n",
      "The number of users: 13710\n",
      "Average actions of users: 16.57276241884893\n",
      "The number of items: 168\n",
      "Average actions of items: 1360.4550898203593\n",
      "The number of inters: 227196\n",
      "The sparsity of the dataset: 90.13597999374805%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "23 Apr 21:32    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "23 Apr 21:32    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.model.sequential_recommender import SASRec, GRU4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Apr 21:33    INFO  SASRec(\n",
      "  (item_embedding): Embedding(168, 64, padding_idx=0)\n",
      "  (position_embedding): Embedding(50, 64)\n",
      "  (trm_encoder): TransformerEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-1): 2 x TransformerLayer(\n",
      "        (multi_head_attention): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 114048\n",
      "SASRec(\n",
      "  (item_embedding): Embedding(168, 64, padding_idx=0)\n",
      "  (position_embedding): Embedding(50, 64)\n",
      "  (trm_encoder): TransformerEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-1): 2 x TransformerLayer(\n",
      "        (multi_head_attention): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 114048\n",
      "23 Apr 21:38    INFO  epoch 0 training [time: 306.68s, train loss: 316.4384]\n",
      "epoch 0 training [time: 306.68s, train loss: 316.4384]\n",
      "23 Apr 21:38    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 21:43    INFO  epoch 1 training [time: 301.36s, train loss: 216.1826]\n",
      "epoch 1 training [time: 301.36s, train loss: 216.1826]\n",
      "23 Apr 21:43    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 21:48    INFO  epoch 2 training [time: 291.69s, train loss: 200.5920]\n",
      "epoch 2 training [time: 291.69s, train loss: 200.5920]\n",
      "23 Apr 21:48    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 21:53    INFO  epoch 3 training [time: 284.98s, train loss: 196.5567]\n",
      "epoch 3 training [time: 284.98s, train loss: 196.5567]\n",
      "23 Apr 21:53    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 21:58    INFO  epoch 4 training [time: 292.66s, train loss: 194.2764]\n",
      "epoch 4 training [time: 292.66s, train loss: 194.2764]\n",
      "23 Apr 21:58    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:03    INFO  epoch 5 training [time: 294.22s, train loss: 193.0543]\n",
      "epoch 5 training [time: 294.22s, train loss: 193.0543]\n",
      "23 Apr 22:03    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:07    INFO  epoch 6 training [time: 293.11s, train loss: 192.1920]\n",
      "epoch 6 training [time: 293.11s, train loss: 192.1920]\n",
      "23 Apr 22:07    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:12    INFO  epoch 7 training [time: 281.46s, train loss: 191.1869]\n",
      "epoch 7 training [time: 281.46s, train loss: 191.1869]\n",
      "23 Apr 22:12    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:17    INFO  epoch 8 training [time: 279.28s, train loss: 190.5068]\n",
      "epoch 8 training [time: 279.28s, train loss: 190.5068]\n",
      "23 Apr 22:17    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:22    INFO  epoch 9 training [time: 281.04s, train loss: 190.1035]\n",
      "epoch 9 training [time: 281.04s, train loss: 190.1035]\n",
      "23 Apr 22:22    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:26    INFO  epoch 10 training [time: 284.84s, train loss: 189.2352]\n",
      "epoch 10 training [time: 284.84s, train loss: 189.2352]\n",
      "23 Apr 22:26    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:31    INFO  epoch 11 training [time: 288.25s, train loss: 189.1297]\n",
      "epoch 11 training [time: 288.25s, train loss: 189.1297]\n",
      "23 Apr 22:31    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:36    INFO  epoch 12 training [time: 285.36s, train loss: 188.5479]\n",
      "epoch 12 training [time: 285.36s, train loss: 188.5479]\n",
      "23 Apr 22:36    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:41    INFO  epoch 13 training [time: 284.73s, train loss: 188.1180]\n",
      "epoch 13 training [time: 284.73s, train loss: 188.1180]\n",
      "23 Apr 22:41    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:45    INFO  epoch 14 training [time: 281.07s, train loss: 187.7523]\n",
      "epoch 14 training [time: 281.07s, train loss: 187.7523]\n",
      "23 Apr 22:45    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:50    INFO  epoch 15 training [time: 280.44s, train loss: 187.6642]\n",
      "epoch 15 training [time: 280.44s, train loss: 187.6642]\n",
      "23 Apr 22:50    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:55    INFO  epoch 16 training [time: 281.23s, train loss: 187.2610]\n",
      "epoch 16 training [time: 281.23s, train loss: 187.2610]\n",
      "23 Apr 22:55    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 22:59    INFO  epoch 17 training [time: 281.69s, train loss: 186.7835]\n",
      "epoch 17 training [time: 281.69s, train loss: 186.7835]\n",
      "23 Apr 22:59    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:04    INFO  epoch 18 training [time: 295.10s, train loss: 186.4231]\n",
      "epoch 18 training [time: 295.10s, train loss: 186.4231]\n",
      "23 Apr 23:04    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:09    INFO  epoch 19 training [time: 283.71s, train loss: 186.2949]\n",
      "epoch 19 training [time: 283.71s, train loss: 186.2949]\n",
      "23 Apr 23:09    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:14    INFO  epoch 20 training [time: 281.88s, train loss: 185.8540]\n",
      "epoch 20 training [time: 281.88s, train loss: 185.8540]\n",
      "23 Apr 23:14    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:18    INFO  epoch 21 training [time: 283.63s, train loss: 185.8494]\n",
      "epoch 21 training [time: 283.63s, train loss: 185.8494]\n",
      "23 Apr 23:18    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:23    INFO  epoch 22 training [time: 285.57s, train loss: 185.4882]\n",
      "epoch 22 training [time: 285.57s, train loss: 185.4882]\n",
      "23 Apr 23:23    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:28    INFO  epoch 23 training [time: 290.59s, train loss: 185.4835]\n",
      "epoch 23 training [time: 290.59s, train loss: 185.4835]\n",
      "23 Apr 23:28    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:33    INFO  epoch 24 training [time: 293.99s, train loss: 185.1923]\n",
      "epoch 24 training [time: 293.99s, train loss: 185.1923]\n",
      "23 Apr 23:33    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:38    INFO  epoch 25 training [time: 292.61s, train loss: 185.1006]\n",
      "epoch 25 training [time: 292.61s, train loss: 185.1006]\n",
      "23 Apr 23:38    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:42    INFO  epoch 26 training [time: 281.25s, train loss: 184.9841]\n",
      "epoch 26 training [time: 281.25s, train loss: 184.9841]\n",
      "23 Apr 23:42    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:47    INFO  epoch 27 training [time: 281.45s, train loss: 184.8198]\n",
      "epoch 27 training [time: 281.45s, train loss: 184.8198]\n",
      "23 Apr 23:47    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:52    INFO  epoch 28 training [time: 280.81s, train loss: 184.4385]\n",
      "epoch 28 training [time: 280.81s, train loss: 184.4385]\n",
      "23 Apr 23:52    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "23 Apr 23:57    INFO  epoch 29 training [time: 281.98s, train loss: 184.4824]\n",
      "epoch 29 training [time: 281.98s, train loss: 184.4824]\n",
      "23 Apr 23:57    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:01    INFO  epoch 30 training [time: 280.57s, train loss: 184.4452]\n",
      "epoch 30 training [time: 280.57s, train loss: 184.4452]\n",
      "24 Apr 00:01    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:06    INFO  epoch 31 training [time: 285.79s, train loss: 184.0290]\n",
      "epoch 31 training [time: 285.79s, train loss: 184.0290]\n",
      "24 Apr 00:06    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:11    INFO  epoch 32 training [time: 281.52s, train loss: 183.8270]\n",
      "epoch 32 training [time: 281.52s, train loss: 183.8270]\n",
      "24 Apr 00:11    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:15    INFO  epoch 33 training [time: 279.61s, train loss: 183.7511]\n",
      "epoch 33 training [time: 279.61s, train loss: 183.7511]\n",
      "24 Apr 00:15    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:20    INFO  epoch 34 training [time: 280.90s, train loss: 183.6777]\n",
      "epoch 34 training [time: 280.90s, train loss: 183.6777]\n",
      "24 Apr 00:20    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:25    INFO  epoch 35 training [time: 281.97s, train loss: 183.4477]\n",
      "epoch 35 training [time: 281.97s, train loss: 183.4477]\n",
      "24 Apr 00:25    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:29    INFO  epoch 36 training [time: 280.93s, train loss: 183.4111]\n",
      "epoch 36 training [time: 280.93s, train loss: 183.4111]\n",
      "24 Apr 00:29    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:34    INFO  epoch 37 training [time: 287.77s, train loss: 183.4347]\n",
      "epoch 37 training [time: 287.77s, train loss: 183.4347]\n",
      "24 Apr 00:34    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:39    INFO  epoch 38 training [time: 284.35s, train loss: 183.4738]\n",
      "epoch 38 training [time: 284.35s, train loss: 183.4738]\n",
      "24 Apr 00:39    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:44    INFO  epoch 39 training [time: 280.31s, train loss: 183.1202]\n",
      "epoch 39 training [time: 280.31s, train loss: 183.1202]\n",
      "24 Apr 00:44    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:48    INFO  epoch 40 training [time: 279.01s, train loss: 183.0615]\n",
      "epoch 40 training [time: 279.01s, train loss: 183.0615]\n",
      "24 Apr 00:48    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:53    INFO  epoch 41 training [time: 278.70s, train loss: 182.9603]\n",
      "epoch 41 training [time: 278.70s, train loss: 182.9603]\n",
      "24 Apr 00:53    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 00:58    INFO  epoch 42 training [time: 281.77s, train loss: 182.7014]\n",
      "epoch 42 training [time: 281.77s, train loss: 182.7014]\n",
      "24 Apr 00:58    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:02    INFO  epoch 43 training [time: 279.43s, train loss: 182.8701]\n",
      "epoch 43 training [time: 279.43s, train loss: 182.8701]\n",
      "24 Apr 01:02    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:07    INFO  epoch 44 training [time: 287.20s, train loss: 182.4981]\n",
      "epoch 44 training [time: 287.20s, train loss: 182.4981]\n",
      "24 Apr 01:07    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:12    INFO  epoch 45 training [time: 282.54s, train loss: 182.6886]\n",
      "epoch 45 training [time: 282.54s, train loss: 182.6886]\n",
      "24 Apr 01:12    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:16    INFO  epoch 46 training [time: 281.43s, train loss: 182.3078]\n",
      "epoch 46 training [time: 281.43s, train loss: 182.3078]\n",
      "24 Apr 01:16    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:21    INFO  epoch 47 training [time: 280.36s, train loss: 182.4457]\n",
      "epoch 47 training [time: 280.36s, train loss: 182.4457]\n",
      "24 Apr 01:21    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:26    INFO  epoch 48 training [time: 291.54s, train loss: 182.4604]\n",
      "epoch 48 training [time: 291.54s, train loss: 182.4604]\n",
      "24 Apr 01:26    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:31    INFO  epoch 49 training [time: 282.79s, train loss: 182.1743]\n",
      "epoch 49 training [time: 282.79s, train loss: 182.1743]\n",
      "24 Apr 01:31    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:36    INFO  epoch 50 training [time: 287.55s, train loss: 182.2342]\n",
      "epoch 50 training [time: 287.55s, train loss: 182.2342]\n",
      "24 Apr 01:36    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:40    INFO  epoch 51 training [time: 287.75s, train loss: 182.2682]\n",
      "epoch 51 training [time: 287.75s, train loss: 182.2682]\n",
      "24 Apr 01:40    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:45    INFO  epoch 52 training [time: 282.76s, train loss: 182.2483]\n",
      "epoch 52 training [time: 282.76s, train loss: 182.2483]\n",
      "24 Apr 01:45    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24 Apr 01:50    INFO  epoch 53 training [time: 280.64s, train loss: 182.0153]\n",
      "epoch 53 training [time: 280.64s, train loss: 182.0153]\n",
      "24 Apr 01:50    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:54    INFO  epoch 54 training [time: 282.00s, train loss: 181.8769]\n",
      "epoch 54 training [time: 282.00s, train loss: 181.8769]\n",
      "24 Apr 01:54    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 01:59    INFO  epoch 55 training [time: 281.05s, train loss: 181.8251]\n",
      "epoch 55 training [time: 281.05s, train loss: 181.8251]\n",
      "24 Apr 01:59    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:04    INFO  epoch 56 training [time: 280.89s, train loss: 181.6839]\n",
      "epoch 56 training [time: 280.89s, train loss: 181.6839]\n",
      "24 Apr 02:04    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:09    INFO  epoch 57 training [time: 287.65s, train loss: 181.7608]\n",
      "epoch 57 training [time: 287.65s, train loss: 181.7608]\n",
      "24 Apr 02:09    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:13    INFO  epoch 58 training [time: 282.00s, train loss: 181.6519]\n",
      "epoch 58 training [time: 282.00s, train loss: 181.6519]\n",
      "24 Apr 02:13    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:18    INFO  epoch 59 training [time: 281.60s, train loss: 181.5663]\n",
      "epoch 59 training [time: 281.60s, train loss: 181.5663]\n",
      "24 Apr 02:18    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:23    INFO  epoch 60 training [time: 280.78s, train loss: 181.4322]\n",
      "epoch 60 training [time: 280.78s, train loss: 181.4322]\n",
      "24 Apr 02:23    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:27    INFO  epoch 61 training [time: 282.43s, train loss: 181.4336]\n",
      "epoch 61 training [time: 282.43s, train loss: 181.4336]\n",
      "24 Apr 02:27    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:32    INFO  epoch 62 training [time: 281.92s, train loss: 181.5831]\n",
      "epoch 62 training [time: 281.92s, train loss: 181.5831]\n",
      "24 Apr 02:32    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:37    INFO  epoch 63 training [time: 285.76s, train loss: 181.3882]\n",
      "epoch 63 training [time: 285.76s, train loss: 181.3882]\n",
      "24 Apr 02:37    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:42    INFO  epoch 64 training [time: 288.06s, train loss: 181.2957]\n",
      "epoch 64 training [time: 288.06s, train loss: 181.2957]\n",
      "24 Apr 02:42    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:46    INFO  epoch 65 training [time: 281.27s, train loss: 181.2656]\n",
      "epoch 65 training [time: 281.27s, train loss: 181.2656]\n",
      "24 Apr 02:46    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:51    INFO  epoch 66 training [time: 285.14s, train loss: 181.2505]\n",
      "epoch 66 training [time: 285.14s, train loss: 181.2505]\n",
      "24 Apr 02:51    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 02:56    INFO  epoch 67 training [time: 290.18s, train loss: 181.2210]\n",
      "epoch 67 training [time: 290.18s, train loss: 181.2210]\n",
      "24 Apr 02:56    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:01    INFO  epoch 68 training [time: 282.39s, train loss: 181.2288]\n",
      "epoch 68 training [time: 282.39s, train loss: 181.2288]\n",
      "24 Apr 03:01    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:05    INFO  epoch 69 training [time: 283.08s, train loss: 181.1480]\n",
      "epoch 69 training [time: 283.08s, train loss: 181.1480]\n",
      "24 Apr 03:05    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:10    INFO  epoch 70 training [time: 287.73s, train loss: 181.0415]\n",
      "epoch 70 training [time: 287.73s, train loss: 181.0415]\n",
      "24 Apr 03:10    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:15    INFO  epoch 71 training [time: 281.96s, train loss: 181.1390]\n",
      "epoch 71 training [time: 281.96s, train loss: 181.1390]\n",
      "24 Apr 03:15    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:19    INFO  epoch 72 training [time: 280.64s, train loss: 180.9933]\n",
      "epoch 72 training [time: 280.64s, train loss: 180.9933]\n",
      "24 Apr 03:19    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:24    INFO  epoch 73 training [time: 282.95s, train loss: 181.0048]\n",
      "epoch 73 training [time: 282.95s, train loss: 181.0048]\n",
      "24 Apr 03:24    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:29    INFO  epoch 74 training [time: 282.81s, train loss: 180.9307]\n",
      "epoch 74 training [time: 282.81s, train loss: 180.9307]\n",
      "24 Apr 03:29    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:34    INFO  epoch 75 training [time: 280.38s, train loss: 180.5107]\n",
      "epoch 75 training [time: 280.38s, train loss: 180.5107]\n",
      "24 Apr 03:34    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:38    INFO  epoch 76 training [time: 282.40s, train loss: 180.7863]\n",
      "epoch 76 training [time: 282.40s, train loss: 180.7863]\n",
      "24 Apr 03:38    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:43    INFO  epoch 77 training [time: 289.89s, train loss: 180.8448]\n",
      "epoch 77 training [time: 289.89s, train loss: 180.8448]\n",
      "24 Apr 03:43    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:48    INFO  epoch 78 training [time: 295.15s, train loss: 180.6042]\n",
      "epoch 78 training [time: 295.15s, train loss: 180.6042]\n",
      "24 Apr 03:48    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:53    INFO  epoch 79 training [time: 283.42s, train loss: 180.6617]\n",
      "epoch 79 training [time: 283.42s, train loss: 180.6617]\n",
      "24 Apr 03:53    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 03:57    INFO  epoch 80 training [time: 277.19s, train loss: 180.6522]\n",
      "epoch 80 training [time: 277.19s, train loss: 180.6522]\n",
      "24 Apr 03:57    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:02    INFO  epoch 81 training [time: 278.27s, train loss: 180.6428]\n",
      "epoch 81 training [time: 278.27s, train loss: 180.6428]\n",
      "24 Apr 04:02    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:07    INFO  epoch 82 training [time: 279.27s, train loss: 180.5768]\n",
      "epoch 82 training [time: 279.27s, train loss: 180.5768]\n",
      "24 Apr 04:07    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:12    INFO  epoch 83 training [time: 289.34s, train loss: 180.3919]\n",
      "epoch 83 training [time: 289.34s, train loss: 180.3919]\n",
      "24 Apr 04:12    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:16    INFO  epoch 84 training [time: 283.83s, train loss: 180.4725]\n",
      "epoch 84 training [time: 283.83s, train loss: 180.4725]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24 Apr 04:16    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:21    INFO  epoch 85 training [time: 285.41s, train loss: 180.3197]\n",
      "epoch 85 training [time: 285.41s, train loss: 180.3197]\n",
      "24 Apr 04:21    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:26    INFO  epoch 86 training [time: 292.41s, train loss: 180.4908]\n",
      "epoch 86 training [time: 292.41s, train loss: 180.4908]\n",
      "24 Apr 04:26    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:31    INFO  epoch 87 training [time: 294.10s, train loss: 180.3565]\n",
      "epoch 87 training [time: 294.10s, train loss: 180.3565]\n",
      "24 Apr 04:31    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:35    INFO  epoch 88 training [time: 279.15s, train loss: 180.3680]\n",
      "epoch 88 training [time: 279.15s, train loss: 180.3680]\n",
      "24 Apr 04:35    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:40    INFO  epoch 89 training [time: 282.78s, train loss: 180.3138]\n",
      "epoch 89 training [time: 282.78s, train loss: 180.3138]\n",
      "24 Apr 04:40    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:45    INFO  epoch 90 training [time: 288.13s, train loss: 180.2156]\n",
      "epoch 90 training [time: 288.13s, train loss: 180.2156]\n",
      "24 Apr 04:45    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:50    INFO  epoch 91 training [time: 279.81s, train loss: 180.1190]\n",
      "epoch 91 training [time: 279.81s, train loss: 180.1190]\n",
      "24 Apr 04:50    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:54    INFO  epoch 92 training [time: 282.07s, train loss: 180.2086]\n",
      "epoch 92 training [time: 282.07s, train loss: 180.2086]\n",
      "24 Apr 04:54    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 04:59    INFO  epoch 93 training [time: 283.67s, train loss: 180.2820]\n",
      "epoch 93 training [time: 283.67s, train loss: 180.2820]\n",
      "24 Apr 04:59    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:04    INFO  epoch 94 training [time: 281.73s, train loss: 180.0595]\n",
      "epoch 94 training [time: 281.73s, train loss: 180.0595]\n",
      "24 Apr 05:04    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:08    INFO  epoch 95 training [time: 282.80s, train loss: 180.2291]\n",
      "epoch 95 training [time: 282.80s, train loss: 180.2291]\n",
      "24 Apr 05:08    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:13    INFO  epoch 96 training [time: 285.83s, train loss: 180.1449]\n",
      "epoch 96 training [time: 285.83s, train loss: 180.1449]\n",
      "24 Apr 05:13    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:18    INFO  epoch 97 training [time: 282.99s, train loss: 180.0176]\n",
      "epoch 97 training [time: 282.99s, train loss: 180.0176]\n",
      "24 Apr 05:18    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:23    INFO  epoch 98 training [time: 282.40s, train loss: 180.1691]\n",
      "epoch 98 training [time: 282.40s, train loss: 180.1691]\n",
      "24 Apr 05:23    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:27    INFO  epoch 99 training [time: 281.83s, train loss: 180.0047]\n",
      "epoch 99 training [time: 281.83s, train loss: 180.0047]\n",
      "24 Apr 05:27    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:32    INFO  epoch 100 training [time: 282.06s, train loss: 179.9849]\n",
      "epoch 100 training [time: 282.06s, train loss: 179.9849]\n",
      "24 Apr 05:32    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:37    INFO  epoch 101 training [time: 282.50s, train loss: 179.9413]\n",
      "epoch 101 training [time: 282.50s, train loss: 179.9413]\n",
      "24 Apr 05:37    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:41    INFO  epoch 102 training [time: 280.76s, train loss: 179.7530]\n",
      "epoch 102 training [time: 280.76s, train loss: 179.7530]\n",
      "24 Apr 05:41    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:46    INFO  epoch 103 training [time: 285.39s, train loss: 179.9201]\n",
      "epoch 103 training [time: 285.39s, train loss: 179.9201]\n",
      "24 Apr 05:46    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:51    INFO  epoch 104 training [time: 281.02s, train loss: 179.8756]\n",
      "epoch 104 training [time: 281.02s, train loss: 179.8756]\n",
      "24 Apr 05:51    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 05:56    INFO  epoch 105 training [time: 280.32s, train loss: 179.8588]\n",
      "epoch 105 training [time: 280.32s, train loss: 179.8588]\n",
      "24 Apr 05:56    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:00    INFO  epoch 106 training [time: 281.30s, train loss: 179.9923]\n",
      "epoch 106 training [time: 281.30s, train loss: 179.9923]\n",
      "24 Apr 06:00    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:05    INFO  epoch 107 training [time: 282.32s, train loss: 179.8478]\n",
      "epoch 107 training [time: 282.32s, train loss: 179.8478]\n",
      "24 Apr 06:05    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:10    INFO  epoch 108 training [time: 282.83s, train loss: 179.6751]\n",
      "epoch 108 training [time: 282.83s, train loss: 179.6751]\n",
      "24 Apr 06:10    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:14    INFO  epoch 109 training [time: 284.09s, train loss: 179.8822]\n",
      "epoch 109 training [time: 284.09s, train loss: 179.8822]\n",
      "24 Apr 06:14    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:19    INFO  epoch 110 training [time: 285.38s, train loss: 179.6015]\n",
      "epoch 110 training [time: 285.38s, train loss: 179.6015]\n",
      "24 Apr 06:19    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:24    INFO  epoch 111 training [time: 281.02s, train loss: 179.5933]\n",
      "epoch 111 training [time: 281.02s, train loss: 179.5933]\n",
      "24 Apr 06:24    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:29    INFO  epoch 112 training [time: 281.85s, train loss: 179.7343]\n",
      "epoch 112 training [time: 281.85s, train loss: 179.7343]\n",
      "24 Apr 06:29    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:33    INFO  epoch 113 training [time: 281.63s, train loss: 179.6002]\n",
      "epoch 113 training [time: 281.63s, train loss: 179.6002]\n",
      "24 Apr 06:33    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:38    INFO  epoch 114 training [time: 284.24s, train loss: 179.5258]\n",
      "epoch 114 training [time: 284.24s, train loss: 179.5258]\n",
      "24 Apr 06:38    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:43    INFO  epoch 115 training [time: 281.62s, train loss: 179.6012]\n",
      "epoch 115 training [time: 281.62s, train loss: 179.6012]\n",
      "24 Apr 06:43    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24 Apr 06:47    INFO  epoch 116 training [time: 287.62s, train loss: 179.6055]\n",
      "epoch 116 training [time: 287.62s, train loss: 179.6055]\n",
      "24 Apr 06:47    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:52    INFO  epoch 117 training [time: 282.38s, train loss: 179.5195]\n",
      "epoch 117 training [time: 282.38s, train loss: 179.5195]\n",
      "24 Apr 06:52    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 06:57    INFO  epoch 118 training [time: 280.44s, train loss: 179.5949]\n",
      "epoch 118 training [time: 280.44s, train loss: 179.5949]\n",
      "24 Apr 06:57    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:02    INFO  epoch 119 training [time: 280.50s, train loss: 179.5956]\n",
      "epoch 119 training [time: 280.50s, train loss: 179.5956]\n",
      "24 Apr 07:02    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:06    INFO  epoch 120 training [time: 281.01s, train loss: 179.4484]\n",
      "epoch 120 training [time: 281.01s, train loss: 179.4484]\n",
      "24 Apr 07:06    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:11    INFO  epoch 121 training [time: 281.33s, train loss: 179.3981]\n",
      "epoch 121 training [time: 281.33s, train loss: 179.3981]\n",
      "24 Apr 07:11    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:16    INFO  epoch 122 training [time: 280.94s, train loss: 179.3107]\n",
      "epoch 122 training [time: 280.94s, train loss: 179.3107]\n",
      "24 Apr 07:16    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:20    INFO  epoch 123 training [time: 286.22s, train loss: 179.5864]\n",
      "epoch 123 training [time: 286.22s, train loss: 179.5864]\n",
      "24 Apr 07:20    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:25    INFO  epoch 124 training [time: 282.47s, train loss: 179.5318]\n",
      "epoch 124 training [time: 282.47s, train loss: 179.5318]\n",
      "24 Apr 07:25    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:30    INFO  epoch 125 training [time: 282.33s, train loss: 179.3085]\n",
      "epoch 125 training [time: 282.33s, train loss: 179.3085]\n",
      "24 Apr 07:30    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:34    INFO  epoch 126 training [time: 282.07s, train loss: 179.3496]\n",
      "epoch 126 training [time: 282.07s, train loss: 179.3496]\n",
      "24 Apr 07:34    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:39    INFO  epoch 127 training [time: 283.83s, train loss: 179.2049]\n",
      "epoch 127 training [time: 283.83s, train loss: 179.2049]\n",
      "24 Apr 07:39    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:44    INFO  epoch 128 training [time: 280.91s, train loss: 179.1298]\n",
      "epoch 128 training [time: 280.91s, train loss: 179.1298]\n",
      "24 Apr 07:44    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:49    INFO  epoch 129 training [time: 284.65s, train loss: 179.2363]\n",
      "epoch 129 training [time: 284.65s, train loss: 179.2363]\n",
      "24 Apr 07:49    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:53    INFO  epoch 130 training [time: 281.22s, train loss: 179.2041]\n",
      "epoch 130 training [time: 281.22s, train loss: 179.2041]\n",
      "24 Apr 07:53    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 07:58    INFO  epoch 131 training [time: 282.71s, train loss: 179.0656]\n",
      "epoch 131 training [time: 282.71s, train loss: 179.0656]\n",
      "24 Apr 07:58    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:03    INFO  epoch 132 training [time: 283.20s, train loss: 179.2546]\n",
      "epoch 132 training [time: 283.20s, train loss: 179.2546]\n",
      "24 Apr 08:03    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:07    INFO  epoch 133 training [time: 283.15s, train loss: 179.0262]\n",
      "epoch 133 training [time: 283.15s, train loss: 179.0262]\n",
      "24 Apr 08:07    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:12    INFO  epoch 134 training [time: 281.36s, train loss: 179.1733]\n",
      "epoch 134 training [time: 281.36s, train loss: 179.1733]\n",
      "24 Apr 08:12    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:17    INFO  epoch 135 training [time: 279.86s, train loss: 179.0786]\n",
      "epoch 135 training [time: 279.86s, train loss: 179.0786]\n",
      "24 Apr 08:17    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:22    INFO  epoch 136 training [time: 285.44s, train loss: 179.2456]\n",
      "epoch 136 training [time: 285.44s, train loss: 179.2456]\n",
      "24 Apr 08:22    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:26    INFO  epoch 137 training [time: 281.51s, train loss: 178.9695]\n",
      "epoch 137 training [time: 281.51s, train loss: 178.9695]\n",
      "24 Apr 08:26    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:31    INFO  epoch 138 training [time: 281.44s, train loss: 179.0198]\n",
      "epoch 138 training [time: 281.44s, train loss: 179.0198]\n",
      "24 Apr 08:31    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:36    INFO  epoch 139 training [time: 280.93s, train loss: 179.0944]\n",
      "epoch 139 training [time: 280.93s, train loss: 179.0944]\n",
      "24 Apr 08:36    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:40    INFO  epoch 140 training [time: 282.21s, train loss: 179.0892]\n",
      "epoch 140 training [time: 282.21s, train loss: 179.0892]\n",
      "24 Apr 08:40    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:45    INFO  epoch 141 training [time: 282.81s, train loss: 179.0919]\n",
      "epoch 141 training [time: 282.81s, train loss: 179.0919]\n",
      "24 Apr 08:45    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:50    INFO  epoch 142 training [time: 283.12s, train loss: 179.0326]\n",
      "epoch 142 training [time: 283.12s, train loss: 179.0326]\n",
      "24 Apr 08:50    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:55    INFO  epoch 143 training [time: 285.20s, train loss: 179.1361]\n",
      "epoch 143 training [time: 285.20s, train loss: 179.1361]\n",
      "24 Apr 08:55    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 08:59    INFO  epoch 144 training [time: 282.47s, train loss: 179.1199]\n",
      "epoch 144 training [time: 282.47s, train loss: 179.1199]\n",
      "24 Apr 08:59    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:04    INFO  epoch 145 training [time: 283.23s, train loss: 178.9344]\n",
      "epoch 145 training [time: 283.23s, train loss: 178.9344]\n",
      "24 Apr 09:04    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:09    INFO  epoch 146 training [time: 282.21s, train loss: 178.8648]\n",
      "epoch 146 training [time: 282.21s, train loss: 178.8648]\n",
      "24 Apr 09:09    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:13    INFO  epoch 147 training [time: 282.69s, train loss: 179.0127]\n",
      "epoch 147 training [time: 282.69s, train loss: 179.0127]\n",
      "24 Apr 09:13    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:18    INFO  epoch 148 training [time: 283.00s, train loss: 179.0219]\n",
      "epoch 148 training [time: 283.00s, train loss: 179.0219]\n",
      "24 Apr 09:18    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:23    INFO  epoch 149 training [time: 288.29s, train loss: 178.9108]\n",
      "epoch 149 training [time: 288.29s, train loss: 178.9108]\n",
      "24 Apr 09:23    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:28    INFO  epoch 150 training [time: 281.06s, train loss: 178.7922]\n",
      "epoch 150 training [time: 281.06s, train loss: 178.7922]\n",
      "24 Apr 09:28    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:32    INFO  epoch 151 training [time: 280.59s, train loss: 178.7072]\n",
      "epoch 151 training [time: 280.59s, train loss: 178.7072]\n",
      "24 Apr 09:32    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:37    INFO  epoch 152 training [time: 284.54s, train loss: 178.7182]\n",
      "epoch 152 training [time: 284.54s, train loss: 178.7182]\n",
      "24 Apr 09:37    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:42    INFO  epoch 153 training [time: 281.97s, train loss: 178.8016]\n",
      "epoch 153 training [time: 281.97s, train loss: 178.8016]\n",
      "24 Apr 09:42    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:46    INFO  epoch 154 training [time: 281.09s, train loss: 178.8215]\n",
      "epoch 154 training [time: 281.09s, train loss: 178.8215]\n",
      "24 Apr 09:46    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:51    INFO  epoch 155 training [time: 283.03s, train loss: 178.8163]\n",
      "epoch 155 training [time: 283.03s, train loss: 178.8163]\n",
      "24 Apr 09:51    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 09:56    INFO  epoch 156 training [time: 286.80s, train loss: 178.8221]\n",
      "epoch 156 training [time: 286.80s, train loss: 178.8221]\n",
      "24 Apr 09:56    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:01    INFO  epoch 157 training [time: 282.01s, train loss: 178.6228]\n",
      "epoch 157 training [time: 282.01s, train loss: 178.6228]\n",
      "24 Apr 10:01    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:05    INFO  epoch 158 training [time: 282.89s, train loss: 178.7309]\n",
      "epoch 158 training [time: 282.89s, train loss: 178.7309]\n",
      "24 Apr 10:05    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:10    INFO  epoch 159 training [time: 282.66s, train loss: 178.7192]\n",
      "epoch 159 training [time: 282.66s, train loss: 178.7192]\n",
      "24 Apr 10:10    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:15    INFO  epoch 160 training [time: 281.43s, train loss: 178.7042]\n",
      "epoch 160 training [time: 281.43s, train loss: 178.7042]\n",
      "24 Apr 10:15    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:19    INFO  epoch 161 training [time: 281.26s, train loss: 178.6779]\n",
      "epoch 161 training [time: 281.26s, train loss: 178.6779]\n",
      "24 Apr 10:19    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:24    INFO  epoch 162 training [time: 287.97s, train loss: 178.7266]\n",
      "epoch 162 training [time: 287.97s, train loss: 178.7266]\n",
      "24 Apr 10:24    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:29    INFO  epoch 163 training [time: 283.97s, train loss: 178.8609]\n",
      "epoch 163 training [time: 283.97s, train loss: 178.8609]\n",
      "24 Apr 10:29    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:34    INFO  epoch 164 training [time: 281.84s, train loss: 178.6420]\n",
      "epoch 164 training [time: 281.84s, train loss: 178.6420]\n",
      "24 Apr 10:34    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:38    INFO  epoch 165 training [time: 283.57s, train loss: 178.7298]\n",
      "epoch 165 training [time: 283.57s, train loss: 178.7298]\n",
      "24 Apr 10:38    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:43    INFO  epoch 166 training [time: 280.44s, train loss: 178.6271]\n",
      "epoch 166 training [time: 280.44s, train loss: 178.6271]\n",
      "24 Apr 10:43    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:48    INFO  epoch 167 training [time: 279.13s, train loss: 178.5084]\n",
      "epoch 167 training [time: 279.13s, train loss: 178.5084]\n",
      "24 Apr 10:48    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:52    INFO  epoch 168 training [time: 280.12s, train loss: 178.6233]\n",
      "epoch 168 training [time: 280.12s, train loss: 178.6233]\n",
      "24 Apr 10:52    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 10:57    INFO  epoch 169 training [time: 288.44s, train loss: 178.5234]\n",
      "epoch 169 training [time: 288.44s, train loss: 178.5234]\n",
      "24 Apr 10:57    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:02    INFO  epoch 170 training [time: 280.76s, train loss: 178.5998]\n",
      "epoch 170 training [time: 280.76s, train loss: 178.5998]\n",
      "24 Apr 11:02    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:07    INFO  epoch 171 training [time: 281.85s, train loss: 178.6153]\n",
      "epoch 171 training [time: 281.85s, train loss: 178.6153]\n",
      "24 Apr 11:07    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:11    INFO  epoch 172 training [time: 282.39s, train loss: 178.6310]\n",
      "epoch 172 training [time: 282.39s, train loss: 178.6310]\n",
      "24 Apr 11:11    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:16    INFO  epoch 173 training [time: 282.24s, train loss: 178.3439]\n",
      "epoch 173 training [time: 282.24s, train loss: 178.3439]\n",
      "24 Apr 11:16    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:21    INFO  epoch 174 training [time: 280.10s, train loss: 178.5699]\n",
      "epoch 174 training [time: 280.10s, train loss: 178.5699]\n",
      "24 Apr 11:21    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:25    INFO  epoch 175 training [time: 287.21s, train loss: 178.4852]\n",
      "epoch 175 training [time: 287.21s, train loss: 178.4852]\n",
      "24 Apr 11:25    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:30    INFO  epoch 176 training [time: 286.62s, train loss: 178.5007]\n",
      "epoch 176 training [time: 286.62s, train loss: 178.5007]\n",
      "24 Apr 11:30    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:35    INFO  epoch 177 training [time: 282.42s, train loss: 178.3353]\n",
      "epoch 177 training [time: 282.42s, train loss: 178.3353]\n",
      "24 Apr 11:35    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24 Apr 11:40    INFO  epoch 178 training [time: 283.63s, train loss: 178.4063]\n",
      "epoch 178 training [time: 283.63s, train loss: 178.4063]\n",
      "24 Apr 11:40    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:44    INFO  epoch 179 training [time: 282.91s, train loss: 178.5323]\n",
      "epoch 179 training [time: 282.91s, train loss: 178.5323]\n",
      "24 Apr 11:44    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:49    INFO  epoch 180 training [time: 281.58s, train loss: 178.5496]\n",
      "epoch 180 training [time: 281.58s, train loss: 178.5496]\n",
      "24 Apr 11:49    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:54    INFO  epoch 181 training [time: 281.04s, train loss: 178.4223]\n",
      "epoch 181 training [time: 281.04s, train loss: 178.4223]\n",
      "24 Apr 11:54    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 11:58    INFO  epoch 182 training [time: 286.61s, train loss: 178.4657]\n",
      "epoch 182 training [time: 286.61s, train loss: 178.4657]\n",
      "24 Apr 11:59    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:03    INFO  epoch 183 training [time: 281.16s, train loss: 178.3953]\n",
      "epoch 183 training [time: 281.16s, train loss: 178.3953]\n",
      "24 Apr 12:03    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:08    INFO  epoch 184 training [time: 280.24s, train loss: 178.3778]\n",
      "epoch 184 training [time: 280.24s, train loss: 178.3778]\n",
      "24 Apr 12:08    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:13    INFO  epoch 185 training [time: 281.72s, train loss: 178.5525]\n",
      "epoch 185 training [time: 281.72s, train loss: 178.5525]\n",
      "24 Apr 12:13    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:17    INFO  epoch 186 training [time: 282.32s, train loss: 178.2292]\n",
      "epoch 186 training [time: 282.32s, train loss: 178.2292]\n",
      "24 Apr 12:17    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:22    INFO  epoch 187 training [time: 281.39s, train loss: 178.2042]\n",
      "epoch 187 training [time: 281.39s, train loss: 178.2042]\n",
      "24 Apr 12:22    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:27    INFO  epoch 188 training [time: 282.68s, train loss: 178.4948]\n",
      "epoch 188 training [time: 282.68s, train loss: 178.4948]\n",
      "24 Apr 12:27    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:31    INFO  epoch 189 training [time: 288.31s, train loss: 178.4093]\n",
      "epoch 189 training [time: 288.31s, train loss: 178.4093]\n",
      "24 Apr 12:31    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:36    INFO  epoch 190 training [time: 280.36s, train loss: 178.3319]\n",
      "epoch 190 training [time: 280.36s, train loss: 178.3319]\n",
      "24 Apr 12:36    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:41    INFO  epoch 191 training [time: 283.26s, train loss: 178.2902]\n",
      "epoch 191 training [time: 283.26s, train loss: 178.2902]\n",
      "24 Apr 12:41    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:46    INFO  epoch 192 training [time: 281.37s, train loss: 178.2771]\n",
      "epoch 192 training [time: 281.37s, train loss: 178.2771]\n",
      "24 Apr 12:46    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:50    INFO  epoch 193 training [time: 281.79s, train loss: 178.2207]\n",
      "epoch 193 training [time: 281.79s, train loss: 178.2207]\n",
      "24 Apr 12:50    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 12:55    INFO  epoch 194 training [time: 282.42s, train loss: 178.3085]\n",
      "epoch 194 training [time: 282.42s, train loss: 178.3085]\n",
      "24 Apr 12:55    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:00    INFO  epoch 195 training [time: 288.45s, train loss: 178.1729]\n",
      "epoch 195 training [time: 288.45s, train loss: 178.1729]\n",
      "24 Apr 13:00    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:05    INFO  epoch 196 training [time: 284.84s, train loss: 178.3438]\n",
      "epoch 196 training [time: 284.84s, train loss: 178.3438]\n",
      "24 Apr 13:05    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:09    INFO  epoch 197 training [time: 281.22s, train loss: 178.2789]\n",
      "epoch 197 training [time: 281.22s, train loss: 178.2789]\n",
      "24 Apr 13:09    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:14    INFO  epoch 198 training [time: 279.76s, train loss: 178.3287]\n",
      "epoch 198 training [time: 279.76s, train loss: 178.3287]\n",
      "24 Apr 13:14    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:19    INFO  epoch 199 training [time: 280.27s, train loss: 178.2772]\n",
      "epoch 199 training [time: 280.27s, train loss: 178.2772]\n",
      "24 Apr 13:19    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:23    INFO  epoch 200 training [time: 281.82s, train loss: 178.0813]\n",
      "epoch 200 training [time: 281.82s, train loss: 178.0813]\n",
      "24 Apr 13:23    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:28    INFO  epoch 201 training [time: 281.96s, train loss: 178.2274]\n",
      "epoch 201 training [time: 281.96s, train loss: 178.2274]\n",
      "24 Apr 13:28    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:33    INFO  epoch 202 training [time: 287.22s, train loss: 178.3734]\n",
      "epoch 202 training [time: 287.22s, train loss: 178.3734]\n",
      "24 Apr 13:33    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:37    INFO  epoch 203 training [time: 283.28s, train loss: 178.0872]\n",
      "epoch 203 training [time: 283.28s, train loss: 178.0872]\n",
      "24 Apr 13:37    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:42    INFO  epoch 204 training [time: 280.63s, train loss: 178.1307]\n",
      "epoch 204 training [time: 280.63s, train loss: 178.1307]\n",
      "24 Apr 13:42    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:47    INFO  epoch 205 training [time: 282.57s, train loss: 178.1529]\n",
      "epoch 205 training [time: 282.57s, train loss: 178.1529]\n",
      "24 Apr 13:47    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:52    INFO  epoch 206 training [time: 281.53s, train loss: 178.1504]\n",
      "epoch 206 training [time: 281.53s, train loss: 178.1504]\n",
      "24 Apr 13:52    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 13:56    INFO  epoch 207 training [time: 282.19s, train loss: 178.2012]\n",
      "epoch 207 training [time: 282.19s, train loss: 178.2012]\n",
      "24 Apr 13:56    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:01    INFO  epoch 208 training [time: 287.40s, train loss: 178.0615]\n",
      "epoch 208 training [time: 287.40s, train loss: 178.0615]\n",
      "24 Apr 14:01    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:06    INFO  epoch 209 training [time: 283.86s, train loss: 178.1711]\n",
      "epoch 209 training [time: 283.86s, train loss: 178.1711]\n",
      "24 Apr 14:06    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:10    INFO  epoch 210 training [time: 282.54s, train loss: 177.9982]\n",
      "epoch 210 training [time: 282.54s, train loss: 177.9982]\n",
      "24 Apr 14:10    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:15    INFO  epoch 211 training [time: 280.83s, train loss: 177.9810]\n",
      "epoch 211 training [time: 280.83s, train loss: 177.9810]\n",
      "24 Apr 14:15    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:20    INFO  epoch 212 training [time: 281.13s, train loss: 178.0466]\n",
      "epoch 212 training [time: 281.13s, train loss: 178.0466]\n",
      "24 Apr 14:20    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:24    INFO  epoch 213 training [time: 279.10s, train loss: 178.0046]\n",
      "epoch 213 training [time: 279.10s, train loss: 178.0046]\n",
      "24 Apr 14:24    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:29    INFO  epoch 214 training [time: 280.46s, train loss: 177.9218]\n",
      "epoch 214 training [time: 280.46s, train loss: 177.9218]\n",
      "24 Apr 14:29    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:34    INFO  epoch 215 training [time: 286.24s, train loss: 177.8946]\n",
      "epoch 215 training [time: 286.24s, train loss: 177.8946]\n",
      "24 Apr 14:34    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:39    INFO  epoch 216 training [time: 283.64s, train loss: 178.0444]\n",
      "epoch 216 training [time: 283.64s, train loss: 178.0444]\n",
      "24 Apr 14:39    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:43    INFO  epoch 217 training [time: 283.11s, train loss: 178.0275]\n",
      "epoch 217 training [time: 283.11s, train loss: 178.0275]\n",
      "24 Apr 14:43    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:48    INFO  epoch 218 training [time: 281.99s, train loss: 177.9128]\n",
      "epoch 218 training [time: 281.99s, train loss: 177.9128]\n",
      "24 Apr 14:48    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:53    INFO  epoch 219 training [time: 282.23s, train loss: 177.8990]\n",
      "epoch 219 training [time: 282.23s, train loss: 177.8990]\n",
      "24 Apr 14:53    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 14:57    INFO  epoch 220 training [time: 280.19s, train loss: 177.7559]\n",
      "epoch 220 training [time: 280.19s, train loss: 177.7559]\n",
      "24 Apr 14:57    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 15:02    INFO  epoch 221 training [time: 284.79s, train loss: 177.8374]\n",
      "epoch 221 training [time: 284.79s, train loss: 177.8374]\n",
      "24 Apr 15:02    INFO  Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "Saving current: saved\\FPMC-Apr-23-2024_21-33-34.pth\n",
      "24 Apr 15:07    INFO  epoch 222 training [time: 287.18s, train loss: 178.0951]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\logging\\__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\logging\\__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 22] Invalid argument\n",
      "Call stack:\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Yiran\\AppData\\Local\\Temp\\ipykernel_2128\\3433955244.py\", line 9, in <module>\n",
      "    best_valid_score, best_valid_result = trainer.fit(train_data)\n",
      "  File \"c:\\users\\yiran\\desktop\\yiranzhang\\recbole\\recbole\\trainer\\trainer.py\", line 450, in fit\n",
      "    self.logger.info(train_loss_output)\n",
      "Message: 'epoch 222 training [time: 287.18s, train loss: 178.0951]'\n",
      "Arguments: ()\n",
      "epoch 222 training [time: 287.18s, train loss: 178.0951]\n",
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\threading.py\", line 932, in _bootstrap_inner\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory saved does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(config, model)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# model training\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m best_valid_score, best_valid_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\yiran\\desktop\\yiranzhang\\recbole\\recbole\\trainer\\trainer.py:460\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_step \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_data:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m saved:\n\u001b[1;32m--> 460\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\yiran\\desktop\\yiranzhang\\recbole\\recbole\\trainer\\trainer.py:308\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, epoch, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m saved_model_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_file)\n\u001b[0;32m    299\u001b[0m state \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: epoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m    307\u001b[0m }\n\u001b[1;32m--> 308\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_model_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    311\u001b[0m         set_color(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving current\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msaved_model_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\torch\\serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    625\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 628\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    629\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\torch\\serialization.py:502\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\torch\\serialization.py:473\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory saved does not exist."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self.run()\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 244, in run\n",
      "    "
     ]
    }
   ],
   "source": [
    "# model loading and initialization\n",
    "model = SASRec(config2, train_data.dataset).to(config2['device'])\n",
    "logger.info(model)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer = Trainer(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._run()\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 275, in _run\n",
      "    self._record_writer.write(data)\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 773, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 167, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"C:\\Users\\Yiran\\anaconda3\\envs\\modeltest\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 171, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "OSError: [Errno 22] Invalid argument: b'log_tensorboard\\\\FPMC-recbox_data-Apr-23-2024_11-31-44-a414de\\\\events.out.tfevents.1713933214.JB-Alienware.2128.6'\n"
     ]
    }
   ],
   "source": [
    "# model loading and initialization\n",
    "model2 = GRU4Rec(config2, train_data.dataset).to(config2['device'])\n",
    "logger.info(model2)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer = Trainer(config, model2)\n",
    "\n",
    "# model training\n",
    "best_valid_score_gru4rec, best_valid_result_gru4rec = trainer.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.utils.case_study import full_sort_topk\n",
    "external_user_ids = dataset.id2token(\n",
    "    dataset.uid_field, list(range(dataset.user_num)))[1:]#fist element in array is 'PAD'(default of Recbole) ->remove it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m internal_user_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(dataset\u001b[38;5;241m.\u001b[39muser_num))[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m      3\u001b[0m     _, topk_iid_list \u001b[38;5;241m=\u001b[39m full_sort_topk([internal_user_id], model, test_data, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, device\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m     last_topk_iid_list \u001b[38;5;241m=\u001b[39m \u001b[43mtopk_iid_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m     external_item_list \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mid2token(dataset\u001b[38;5;241m.\u001b[39miid_field, last_topk_iid_list\u001b[38;5;241m.\u001b[39mcpu())\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      6\u001b[0m     topk_items\u001b[38;5;241m.\u001b[39mappend(external_item_list)\n",
      "\u001b[1;31mIndexError\u001b[0m: index -1 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "topk_items = []\n",
    "for internal_user_id in list(range(dataset.user_num))[1:]:\n",
    "    _, topk_iid_list = full_sort_topk([internal_user_id], model, test_data, k=12, device=config['device'])\n",
    "    last_topk_iid_list = topk_iid_list[-1]\n",
    "    external_item_list = dataset.id2token(dataset.iid_field, last_topk_iid_list.cpu()).tolist()\n",
    "    topk_items.append(external_item_list)\n",
    "print(len(topk_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (3) does not match length of index (13709)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m external_item_str \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m topk_items]\n\u001b[0;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(external_user_ids, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m external_item_str\n\u001b[0;32m      4\u001b[0m result\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4134\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4135\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4146\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4147\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4148\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4149\u001b[0m     ):\n\u001b[0;32m   4150\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4870\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\modeltest\\lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (3) does not match length of index (13709)"
     ]
    }
   ],
   "source": [
    "external_item_str = [' '.join(x) for x in topk_items]\n",
    "result = pd.DataFrame(external_user_ids, columns=['customer_id'])\n",
    "result['prediction'] = external_item_str\n",
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reboletensor",
   "language": "python",
   "name": "reboletensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
