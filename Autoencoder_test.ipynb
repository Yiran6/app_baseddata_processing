{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import ast\n",
    "import time\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#for AE \n",
    "#kernel = Python 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2],\n",
       "       [0, 3, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = csr_matrix([[1,0,2],[0,3,0]])\n",
    "a.todense()\n",
    "a.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlanduse_input_path = 'G:/My Drive/2021/Bias/census_block_data/'\\nland_use_obs = pd.read_csv('obs_landuse.csv', header=None).to_numpy()\\nland_use_01 =  pd.read_csv('obs01_landuse.csv', header=None).to_numpy()\\n\\nland_use_zero_index = pd.read_csv('zero_index_landuse.csv',header=None).to_numpy()\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data processing\n",
    "#get data based on census tract\n",
    "#based on downtown Seattle\n",
    "#test data\n",
    "os.chdir('G:/My Drive/2021/Bias/')\n",
    "\n",
    "test_matrice_reverse = pd.read_csv('test_matrice_reverse.csv', header=None).to_numpy()\n",
    "Zero_index = pd.read_csv('Zero_index.csv', header=None).to_numpy()\n",
    "#os.listsdir()\n",
    "\n",
    "#land use data \n",
    "#obs\n",
    "#obs_01\n",
    "#zero index\n",
    "'''\n",
    "landuse_input_path = 'G:/My Drive/2021/Bias/census_block_data/'\n",
    "land_use_obs = pd.read_csv('obs_landuse.csv', header=None).to_numpy()\n",
    "land_use_01 =  pd.read_csv('obs01_landuse.csv', header=None).to_numpy()\n",
    "\n",
    "land_use_zero_index = pd.read_csv('zero_index_landuse.csv',header=None).to_numpy()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120127"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(test_matrice_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post data processing\n",
    "#made zero matrix \n",
    "#Functions\n",
    "#for the ods at the same location\n",
    "#the other location at the same time should be 0\n",
    "#time_diff <= 10 min\n",
    "\n",
    "#for the ods at different location\n",
    "#the other location which not belongs to the route or neatby od should be 0\n",
    "#time_diff <= 20 min\n",
    "\n",
    "#get 0 value\n",
    "\n",
    "#besides,if appears in one place already, the location will not appear in the other census tract\n",
    "def extract_od(dt, sameod = True):\n",
    "    if sameod == True:\n",
    "        test_dt = dt[(dt['od_euqal']==1) & (dt['time_diff']<=10)]\n",
    "    else:\n",
    "        test_dt = dt[(dt['od_euqal']==0) & (dt['time_diff']<=20)]\n",
    "    return(test_dt)\n",
    "\n",
    "def convert2stid(hr, minut_5, census):\n",
    "    return(str(census)+'_'+str(hr)+'_'+str(minut_5))\n",
    "\n",
    "def process_dt4convert(shr, ehr, smin, emin):\n",
    "    if ehr-shr<0:\n",
    "        print('data error')\n",
    "        return(None)\n",
    "    if ehr-shr == 0:\n",
    "        if emin-smin == 0:\n",
    "            return([shr], [smin])\n",
    "        elif emin-smin <0:\n",
    "            print('data error')\n",
    "            return(None)\n",
    "        else:\n",
    "            interval = int((emin-smin)/5)\n",
    "            min_lst = [smin]\n",
    "            hr_lst = [shr]\n",
    "            if interval > 1:\n",
    "                for i in range(interval):\n",
    "                    min_lst.append(int(smin+5*(i+1)))\n",
    "                    hr_lst.append(shr)\n",
    "            else:\n",
    "                min_lst.append(emin)\n",
    "                hr_lst.append(shr)\n",
    "            return(hr_lst, min_lst)\n",
    "    else:\n",
    "        if emin+60-smin == 0:\n",
    "            return([shr], [smin]) \n",
    "        else:\n",
    "            interval = int((emin+60-smin)/5)    \n",
    "            hr_lst = [shr]\n",
    "            min_lst = [smin]\n",
    "            if interval > 1:\n",
    "                for i in range(interval):\n",
    "                    if smin+(i+1)*5 >= 60:\n",
    "                        min_lst.append(smin+(i+1)*5-60)\n",
    "                        hr_lst.append(ehr)\n",
    "                    else:\n",
    "                        min_lst.append(smin+(i+1)*5)\n",
    "                        hr_lst.append(shr)\n",
    "            else:             \n",
    "                min_lst.append(emin)\n",
    "                hr_lst.append(ehr)\n",
    "            return(hr_lst, min_lst) \n",
    "        \n",
    "def add_zero_loc(shr, ehr, s5min, e5min, nocrossedcts, zero_loclst):\n",
    "    for i in range(len(shr)):\n",
    "        hr, minut = process_dt4convert(shr[i], ehr[i], s5min[i], e5min[i])\n",
    "        for j in nocrossedcts[i]:\n",
    "            for k in range(len(hr)):\n",
    "                loc_timeids = convert2stid(hr[k], minut[k], j)\n",
    "                if loc_timeids not in zero_loclst:\n",
    "                    zero_loclst.append(loc_timeids)\n",
    "    return(zero_loclst)\n",
    "\n",
    "def get_nocrossed_stids(dt, zero_loc_time):\n",
    "    dt = dt.sort_values(by=['newid'])\n",
    "    newids = np.unique(dt['newid'])\n",
    "    \n",
    "    for ids in newids:\n",
    "        if ids not in zero_loc_time:\n",
    "            zero_loc_time[ids] = []\n",
    "        #get start and end hr\n",
    "        s_hr = list(dt['s_hr'][dt['newid']==ids].values)\n",
    "        e_hr = list(dt['e_hr'][dt['newid']==ids].values)\n",
    "        s_5min = list(dt['s_minut_5'][dt['newid']==ids].values)\n",
    "        e_5min = list(dt['e_minut_5'][dt['newid']==ids].values)\n",
    "        no_crossed_cts = list(dt['no_crossedcts'][dt['newid']==ids].values)\n",
    "        \n",
    "        zero_loc_time[ids] = add_zero_loc(s_hr, e_hr, s_5min, e_5min, no_crossed_cts, zero_loc_time[ids])\n",
    "    return(zero_loc_time)\n",
    "\n",
    "def getzero_info(dt):\n",
    "    zero_loc_time = {}\n",
    "    dt1 = extract_od(dt, sameod = True)\n",
    "    dt2 = extract_od(dt, sameod = False)\n",
    "    zero_loc_time = get_nocrossed_stids(dt1, zero_loc_time)\n",
    "    zero_loc_time = get_nocrossed_stids(dt2, zero_loc_time)\n",
    "    return(zero_loc_time)\n",
    "\n",
    "def get_revised_matrix(pred_matrix, zero_loc_time):\n",
    "    for ids in zero_loc_time:\n",
    "        for loct_time in zero_loc_time[ids]:\n",
    "            pred_matrix[newids_map[ids]][locts_map[loct_time]] = 0\n",
    "    return(pred_matrix)\n",
    "\n",
    "def convert_missingids(time_lst, ids, time_spatial_ids, Seattle_latlon, location_ids):\n",
    "    for t in time_lst:\n",
    "        hr = (Seattle_latlon['hr'][(Seattle_latlon['newid']==ids) & (Seattle_latlon['timestamp']==t)]).values[0]\n",
    "        minut = (Seattle_latlon['minut_5'][(Seattle_latlon['newid']==ids) & (Seattle_latlon['timestamp']==t)]).values[0]\n",
    "        geoid = (Seattle_latlon[location_ids][(Seattle_latlon['newid']==ids) & (Seattle_latlon['timestamp']==t)]).values[0]\n",
    "        newgeo = (Seattle_latlon['new_geos'][(Seattle_latlon['newid']==ids) & (Seattle_latlon['timestamp']==t)]).values[0]\n",
    "        geos = list(np.unique([geoid, newgeo]))\n",
    "        if 0 in geos:\n",
    "            geos.remove(0)\n",
    "        #get no observed census_t\n",
    "        diff_ct = list(set(census_t) ^ set(geos))\n",
    "        for geo_id in diff_ct:\n",
    "            time_spatial_id = convert2stid(hr, minut, geo_id)\n",
    "            if time_spatial_id not in time_spatial_ids:\n",
    "                time_spatial_ids.append(time_spatial_id)\n",
    "    return(time_spatial_ids)\n",
    "\n",
    "def read_dict(filepath):\n",
    "    with open(filepath) as f:\n",
    "        data = f.read()\n",
    "    dict_data = ast.literal_eval(data)\n",
    "    return(dict_data)\n",
    "\n",
    "def convert_dict(index_dict):\n",
    "    convertdict = {}\n",
    "    for keys in index_dict:\n",
    "        convertdict[index_dict[keys]] = keys\n",
    "    return(convertdict)\n",
    "\n",
    "def save_matrix2file(input_path, savedname, input_matrix):\n",
    "    np.savetxt(input_path+savedname, input_matrix, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Autoencoder (AE)\n",
    "\n",
    "[Source](https://colab.research.google.com/drive/16cI2CJg-dbdxp4FdP5IPYuaLkY5Sf_2l#scrollTo=l1fH9fv9yVfg)\\\n",
    "[Code Source](https://github.com/davidberger2785/RS-Workshop)\n",
    "\n",
    "In general, auto-encoders are a class of neural networks that allow unsupervised learning of the latent characteristics of the data being studied. To do this, the AE will attempt to predict, or copy, the input observations using (multiple) hidden layer. In its simplest form, the architecture of an AE can be summarized in the diagram below.\n",
    "\n",
    "![title](https://github.com/davidberger2785/RS-Workshop/blob/master/Images/AE.png?raw=1)\n",
    "\n",
    "Looking more closely, the AE consists of an encoder, the function $h(\\cdot)$ defined by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    h(\\mathbf{x}) = \\frac{1}{1+ \\exp(-\\mathbf{W} \\mathbf{x})}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This function takes as input the observations and will consist of recoding it as a hidden layer so as to reduce their size (fewer neurons). Afterwards, an encoder defined by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    f(h(\\mathbf{x})) = \\mathbf{W}^\\top h(\\mathbf{x})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "will attempt <i>to reconstruct </i> the input observations from the hidden layer. In this sense, the AE tries to estimate the observations used as input.\n",
    "\n",
    "We can advantageously use the estimates made by the auto-encoders in such a way as to present new recommendations to the users.\n",
    "\n",
    "For example, suppose that the set of evaluations made by a user is defined by the vector:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{x} = [3, \\ 0, \\ 0, \\ 1, \\ ..., \\ 2, \\ 4].\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We note that the movie in first place, <i> Toy Story </i>, was moderately appreciated, while the following two movies, <i> Golden eye </i> and <i> Four rooms </i >, have not been viewed. Suppose once again that in this same set of assessments, the EA will present the following estimates:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{\\hat{x}} = [3.2, \\ 1.3, \\ 4, \\ 0.5, \\ ..., \\ 3, \\ 1].\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "As a result, we will be able to use the estimates associated with initially unvisited movies as recommendations. Thus, the movie <i> Four rooms </i>, in third position, seems a good suggestion for the user, while <i> Golden eye </i> is definitely not a convincing recommendation.\n",
    "\n",
    "#### Loss function\n",
    "\n",
    "As we saw in the previous workshop, the loss function plays an important role in the construction of a predictive model. In fact, it is this same loss function that we try to minimize (or maximize is according to) by iteratively adjusting the weights of the AE. Thus, two different loss functions will most likely result in two different models. As usual, Pytorch offers a large amount of <a href=\"http://pytorch.org/docs/master/nn.html#id42\">loss functions</a> that you can explore at your leisure.\n",
    "\n",
    "Since ratings vary between 1 and 5, the mean square error (MSE) seems an interesting first option. Formally, as part of a recommendation system, we will define the MSE as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textit{MSE}(\\mathbf{R}, \\hat{\\mathbf{R}}) = \\frac{1}{n} \\sum_{r_{ui} \\neq 0} (r_{ui} - \\hat{r}_{ui})^2, \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{R}$ and $\\hat{\\mathbf{R}} $ are respectively the matrices of the observed and predicted ratings and $n$ is the number of estimates. In the same way, $r_{ui}$ and $\\hat{r}_{ui} $ are scalars associated respectively with the observed evaluation and the estimate of the user $u$ for the item $i$.\n",
    "\n",
    "Since we have encoded the loss function as an attribute of the autoencoder class, we define it with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible issues of this method\n",
    "#the test dataset covers train, test data\n",
    "#however, we don't have the ground true (i.e., test data)\n",
    "#one possible way to test is to check the zero index\n",
    "#Sources: https://github.com/davidberger2785/RS-Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, inputs, outputs, features, criterion=None):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "           self: class name\n",
    "           nb_inputs: number of neurons on the input layer\n",
    "           nb_outputs: number of neurons on the output layer\n",
    "           nb_features: number of neurons on the hidden layer\n",
    "           criterion: loss function used for learning  \n",
    "        \"\"\"\n",
    "        \n",
    "        super(AE, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputs, features)\n",
    "        self.fc2 = nn.Linear(features, outputs)\n",
    "        \n",
    "        self.criterion = criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, ratio, tensor=False):\n",
    "    dt = data.copy()\n",
    "    #since the data matrix covers id\n",
    "    dt = dt[:, 1:]\n",
    "    train = np.zeros(dt.shape).tolist()\n",
    "    valid = np.zeros(dt.shape).tolist()\n",
    "    \n",
    "    row, col = dt.shape\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            if dt[i][j] > 0:\n",
    "                if np.random.binomial(1, ratio, 1):\n",
    "                    train[i][j] = dt[i][j]\n",
    "                else:\n",
    "                    valid[i][j] = dt[i][j]\n",
    "\n",
    "    return [train, valid]\n",
    "\n",
    "        \n",
    "def forward(model, x):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: name of the autoencoder as initialized\n",
    "        x: input layer, here made up of 1682 neurons\n",
    "    Return:\n",
    "        predictions: output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    h1 = torch.sigmoid(model.fc1(x))\n",
    "    return ae.fc2(h1)\n",
    "\n",
    "def fit(model, x, y, valid=False):\n",
    "    \n",
    "    nb_obs, nb_items = len(x), len(x[0])\n",
    "    average_loss, s = 0, 0.\n",
    "\n",
    "    for id_user in range(nb_obs):\n",
    "\n",
    "        inputs = Variable(x[id_user]).unsqueeze(0)\n",
    "        target = Variable(y[id_user]).unsqueeze(0)\n",
    "\n",
    "        if torch.sum(target > 0) > 0:\n",
    "            \n",
    "            estimate = forward(model, inputs)\n",
    "            estimate[target <= 0] = 0\n",
    "            target.require_grad = False\n",
    "            \n",
    "            loss = model.criterion(estimate, target)\n",
    "            \n",
    "            if not valid:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            average_loss += loss.data / float(torch.sum(target.data > 0))\n",
    "            s += 1.\n",
    "\n",
    "    return model, average_loss, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = split(test_matrice_reverse, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "train = torch.FloatTensor(train_0)\n",
    "train, valid = train[0], train[1]\n",
    "\n",
    "nb_inputs = len(train[0])\n",
    "nb_outputs = len(train[0])\n",
    "\n",
    "test = test_matrice_reverse[:, 1:].copy().tolist()\n",
    "test = torch.FloatTensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_matrice_reverse[:, 1:].copy().tolist()\n",
    "test = torch.FloatTensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previous hyperparameter test include\n",
    "ae = AE(nb_inputs, nb_outputs, 10)\n",
    "learning_rate = 0.02\n",
    "weight_decay = 0.2\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ae.criterion = nn.MSELoss()\n",
    "\n",
    "ae = AE(nb_inputs, nb_outputs, 10)\n",
    "learning_rate = 0.02\n",
    "weight_decay = 0.1\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ae.criterion = nn.MSELoss()\n",
    "\n",
    "ae = AE(nb_inputs, nb_outputs, 10)\n",
    "learning_rate = 0.02\n",
    "weight_decay = 0.3\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ae.criterion = nn.MSELoss()\n",
    "\n",
    "ae = AE(nb_inputs, nb_outputs, 10)\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.1\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ae.criterion = nn.MSELoss()\n",
    "\n",
    "ae = AE(nb_inputs, nb_outputs, 20)\n",
    "learning_rate = 0.02\n",
    "weight_decay = 0.1\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ae.criterion = nn.MSELoss()\n",
    "\n",
    "ae = AE(nb_inputs, nb_outputs, 15)\n",
    "learning_rate = 0.02\n",
    "weight_decay = 0.1\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ae.criterion = nn.MSELoss()\n",
    "\n",
    "ae = AE(nb_inputs, nb_outputs, 18)\n",
    "learning_rate = 0.02\n",
    "weight_decay = 0.1\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ae.criterion = nn.MSELoss()\n",
    "\n",
    "ae = AE(nb_inputs, nb_outputs, 18)\n",
    "learning_rate = 0.02\n",
    "weight_decay = 0.2\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ae.criterion = nn.MSELoss()\n",
    "\n",
    "nb_epoch = 20\n",
    "\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    ae, train_loss, train_s = fit(model=ae, x=train, y=train)\n",
    "    ae, valid_loss, valid_s = fit(model=ae, x=valid, y=valid, valid=True)\n",
    "\n",
    "    print(\"epoch: \", \"{:3.0f}\".format(epoch), \"   |   train: \", \"{:1.8f}\".format(train_loss.numpy() / train_s), \\\n",
    "                    '   |   valid: ', \"{:1.8f}\".format(valid_loss.numpy() / valid_s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_features: 10\n",
      "epoch:    1    |   train:  0.00735939    |   valid:  0.00590435\n",
      "epoch:    2    |   train:  0.00665492    |   valid:  0.00581273\n",
      "epoch:    3    |   train:  0.00648286    |   valid:  0.00584369\n",
      "epoch:    4    |   train:  0.00632533    |   valid:  0.00585202\n",
      "epoch:    5    |   train:  0.00612857    |   valid:  0.00579517\n",
      "epoch:    6    |   train:  0.00590494    |   valid:  0.00573204\n",
      "epoch:    7    |   train:  0.00565900    |   valid:  0.00565201\n",
      "epoch:    8    |   train:  0.00538554    |   valid:  0.00558794\n",
      "epoch:    9    |   train:  0.00512796    |   valid:  0.00549163\n",
      "epoch:   10    |   train:  0.00486895    |   valid:  0.00542668\n",
      "epoch:   11    |   train:  0.00462434    |   valid:  0.00535597\n",
      "epoch:   12    |   train:  0.00440330    |   valid:  0.00529489\n",
      "epoch:   13    |   train:  0.00418290    |   valid:  0.00523914\n",
      "epoch:   14    |   train:  0.00399679    |   valid:  0.00518108\n",
      "epoch:   15    |   train:  0.00380848    |   valid:  0.00514045\n",
      "epoch:   16    |   train:  0.00363422    |   valid:  0.00509118\n",
      "epoch:   17    |   train:  0.00347750    |   valid:  0.00506228\n",
      "epoch:   18    |   train:  0.00335001    |   valid:  0.00500882\n",
      "epoch:   19    |   train:  0.00321940    |   valid:  0.00497965\n",
      "epoch:   20    |   train:  0.00313777    |   valid:  0.00495488\n",
      "epoch:   21    |   train:  0.00302230    |   valid:  0.00492248\n",
      "epoch:   22    |   train:  0.00291023    |   valid:  0.00488565\n",
      "epoch:   23    |   train:  0.00279924    |   valid:  0.00487161\n",
      "epoch:   24    |   train:  0.00269785    |   valid:  0.00484433\n",
      "epoch:   25    |   train:  0.00261411    |   valid:  0.00481337\n",
      "epoch:   26    |   train:  0.00253091    |   valid:  0.00478957\n",
      "epoch:   27    |   train:  0.00248939    |   valid:  0.00477478\n",
      "epoch:   28    |   train:  0.00246521    |   valid:  0.00475764\n",
      "epoch:   29    |   train:  0.00238554    |   valid:  0.00473325\n",
      "epoch:   30    |   train:  0.00232506    |   valid:  0.00471672\n",
      "run time: 1159.860029500036\n",
      "test:  0.00327324\n",
      "input_features: 11\n",
      "epoch:    1    |   train:  0.00733543    |   valid:  0.00589226\n",
      "epoch:    2    |   train:  0.00664323    |   valid:  0.00582510\n",
      "epoch:    3    |   train:  0.00646673    |   valid:  0.00585045\n",
      "epoch:    4    |   train:  0.00628602    |   valid:  0.00582017\n",
      "epoch:    5    |   train:  0.00604370    |   valid:  0.00575693\n",
      "epoch:    6    |   train:  0.00576478    |   valid:  0.00567257\n",
      "epoch:    7    |   train:  0.00546407    |   valid:  0.00557362\n",
      "epoch:    8    |   train:  0.00513943    |   valid:  0.00548991\n",
      "epoch:    9    |   train:  0.00484351    |   valid:  0.00539676\n",
      "epoch:   10    |   train:  0.00456977    |   valid:  0.00532649\n",
      "epoch:   11    |   train:  0.00431476    |   valid:  0.00526348\n",
      "epoch:   12    |   train:  0.00411060    |   valid:  0.00520334\n",
      "epoch:   13    |   train:  0.00394435    |   valid:  0.00515399\n",
      "epoch:   14    |   train:  0.00375575    |   valid:  0.00510866\n",
      "epoch:   15    |   train:  0.00358251    |   valid:  0.00505331\n",
      "epoch:   16    |   train:  0.00342657    |   valid:  0.00501929\n",
      "epoch:   17    |   train:  0.00328035    |   valid:  0.00497852\n",
      "epoch:   18    |   train:  0.00316092    |   valid:  0.00493660\n",
      "epoch:   19    |   train:  0.00305553    |   valid:  0.00490535\n",
      "epoch:   20    |   train:  0.00294348    |   valid:  0.00487430\n",
      "epoch:   21    |   train:  0.00286904    |   valid:  0.00486087\n",
      "epoch:   22    |   train:  0.00276454    |   valid:  0.00481952\n",
      "epoch:   23    |   train:  0.00266141    |   valid:  0.00479074\n",
      "epoch:   24    |   train:  0.00255608    |   valid:  0.00475355\n",
      "epoch:   25    |   train:  0.00246437    |   valid:  0.00472683\n",
      "epoch:   26    |   train:  0.00239007    |   valid:  0.00471541\n",
      "epoch:   27    |   train:  0.00231972    |   valid:  0.00467992\n",
      "epoch:   28    |   train:  0.00223762    |   valid:  0.00465564\n",
      "epoch:   29    |   train:  0.00217595    |   valid:  0.00463559\n",
      "epoch:   30    |   train:  0.00211056    |   valid:  0.00461686\n",
      "run time: 32852.25953420001\n",
      "test:  0.00306599\n",
      "input_features: 12\n",
      "epoch:    1    |   train:  0.00731546    |   valid:  0.00588541\n",
      "epoch:    2    |   train:  0.00663346    |   valid:  0.00583411\n",
      "epoch:    3    |   train:  0.00644830    |   valid:  0.00584236\n",
      "epoch:    4    |   train:  0.00625465    |   valid:  0.00582535\n",
      "epoch:    5    |   train:  0.00601519    |   valid:  0.00574545\n",
      "epoch:    6    |   train:  0.00568136    |   valid:  0.00563177\n",
      "epoch:    7    |   train:  0.00534861    |   valid:  0.00552707\n",
      "epoch:    8    |   train:  0.00503429    |   valid:  0.00543536\n",
      "epoch:    9    |   train:  0.00469603    |   valid:  0.00535419\n",
      "epoch:   10    |   train:  0.00440801    |   valid:  0.00527669\n",
      "epoch:   11    |   train:  0.00413855    |   valid:  0.00519270\n",
      "epoch:   12    |   train:  0.00389068    |   valid:  0.00512979\n",
      "epoch:   13    |   train:  0.00367704    |   valid:  0.00507883\n",
      "epoch:   14    |   train:  0.00348173    |   valid:  0.00503002\n",
      "epoch:   15    |   train:  0.00329843    |   valid:  0.00497626\n",
      "epoch:   16    |   train:  0.00315594    |   valid:  0.00493830\n",
      "epoch:   17    |   train:  0.00299867    |   valid:  0.00489645\n",
      "epoch:   18    |   train:  0.00286500    |   valid:  0.00485731\n",
      "epoch:   19    |   train:  0.00276113    |   valid:  0.00483708\n",
      "epoch:   20    |   train:  0.00265762    |   valid:  0.00481098\n",
      "epoch:   21    |   train:  0.00256242    |   valid:  0.00479984\n",
      "epoch:   22    |   train:  0.00248053    |   valid:  0.00476583\n",
      "epoch:   23    |   train:  0.00242038    |   valid:  0.00474385\n",
      "epoch:   24    |   train:  0.00231964    |   valid:  0.00472577\n",
      "epoch:   25    |   train:  0.00226007    |   valid:  0.00469280\n",
      "epoch:   26    |   train:  0.00219914    |   valid:  0.00469085\n",
      "epoch:   27    |   train:  0.00216487    |   valid:  0.00466767\n",
      "epoch:   28    |   train:  0.00211790    |   valid:  0.00464822\n",
      "epoch:   29    |   train:  0.00205315    |   valid:  0.00462430\n",
      "epoch:   30    |   train:  0.00198627    |   valid:  0.00462139\n",
      "run time: 1560.5299409999861\n",
      "test:  0.00300222\n",
      "input_features: 13\n",
      "epoch:    1    |   train:  0.00729698    |   valid:  0.00587846\n",
      "epoch:    2    |   train:  0.00662547    |   valid:  0.00584388\n",
      "epoch:    3    |   train:  0.00642998    |   valid:  0.00583345\n",
      "epoch:    4    |   train:  0.00619755    |   valid:  0.00578823\n",
      "epoch:    5    |   train:  0.00590469    |   valid:  0.00570844\n",
      "epoch:    6    |   train:  0.00554705    |   valid:  0.00559058\n",
      "epoch:    7    |   train:  0.00520072    |   valid:  0.00549852\n",
      "epoch:    8    |   train:  0.00487233    |   valid:  0.00540417\n",
      "epoch:    9    |   train:  0.00452665    |   valid:  0.00532010\n",
      "epoch:   10    |   train:  0.00423054    |   valid:  0.00524516\n",
      "epoch:   11    |   train:  0.00397307    |   valid:  0.00518091\n",
      "epoch:   12    |   train:  0.00374491    |   valid:  0.00511971\n",
      "epoch:   13    |   train:  0.00356513    |   valid:  0.00506824\n",
      "epoch:   14    |   train:  0.00336580    |   valid:  0.00501486\n",
      "epoch:   15    |   train:  0.00317664    |   valid:  0.00498054\n",
      "epoch:   16    |   train:  0.00300735    |   valid:  0.00492673\n",
      "epoch:   17    |   train:  0.00286526    |   valid:  0.00488248\n",
      "epoch:   18    |   train:  0.00274874    |   valid:  0.00485223\n",
      "epoch:   19    |   train:  0.00263547    |   valid:  0.00482680\n",
      "epoch:   20    |   train:  0.00253483    |   valid:  0.00479037\n",
      "epoch:   21    |   train:  0.00243105    |   valid:  0.00478471\n",
      "epoch:   22    |   train:  0.00241562    |   valid:  0.00473740\n",
      "epoch:   23    |   train:  0.00231197    |   valid:  0.00471713\n",
      "epoch:   24    |   train:  0.00222131    |   valid:  0.00469573\n",
      "epoch:   25    |   train:  0.00213974    |   valid:  0.00467398\n",
      "epoch:   26    |   train:  0.00206751    |   valid:  0.00465448\n",
      "epoch:   27    |   train:  0.00200320    |   valid:  0.00462015\n",
      "epoch:   28    |   train:  0.00193469    |   valid:  0.00460054\n",
      "epoch:   29    |   train:  0.00190463    |   valid:  0.00460928\n",
      "epoch:   30    |   train:  0.00185249    |   valid:  0.00460053\n",
      "run time: 1617.9276699000038\n",
      "test:  0.00291592\n",
      "input_features: 14\n",
      "epoch:    1    |   train:  0.00728119    |   valid:  0.00587309\n",
      "epoch:    2    |   train:  0.00661786    |   valid:  0.00585022\n",
      "epoch:    3    |   train:  0.00640167    |   valid:  0.00582506\n",
      "epoch:    4    |   train:  0.00612424    |   valid:  0.00574782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    5    |   train:  0.00577585    |   valid:  0.00564519\n",
      "epoch:    6    |   train:  0.00544002    |   valid:  0.00555422\n",
      "epoch:    7    |   train:  0.00505656    |   valid:  0.00544623\n",
      "epoch:    8    |   train:  0.00468214    |   valid:  0.00533758\n",
      "epoch:    9    |   train:  0.00435328    |   valid:  0.00525410\n",
      "epoch:   10    |   train:  0.00403880    |   valid:  0.00517228\n",
      "epoch:   11    |   train:  0.00376819    |   valid:  0.00511070\n",
      "epoch:   12    |   train:  0.00355936    |   valid:  0.00506270\n",
      "epoch:   13    |   train:  0.00336064    |   valid:  0.00501164\n",
      "epoch:   14    |   train:  0.00318159    |   valid:  0.00497547\n",
      "epoch:   15    |   train:  0.00300791    |   valid:  0.00493518\n",
      "epoch:   16    |   train:  0.00284558    |   valid:  0.00488535\n",
      "epoch:   17    |   train:  0.00272973    |   valid:  0.00486264\n",
      "epoch:   18    |   train:  0.00259116    |   valid:  0.00482193\n",
      "epoch:   19    |   train:  0.00246049    |   valid:  0.00478945\n",
      "epoch:   20    |   train:  0.00236159    |   valid:  0.00476173\n",
      "epoch:   21    |   train:  0.00228138    |   valid:  0.00472973\n",
      "epoch:   22    |   train:  0.00217966    |   valid:  0.00470345\n",
      "epoch:   23    |   train:  0.00211519    |   valid:  0.00468388\n",
      "epoch:   24    |   train:  0.00202763    |   valid:  0.00465517\n",
      "epoch:   25    |   train:  0.00194249    |   valid:  0.00463676\n",
      "epoch:   26    |   train:  0.00187083    |   valid:  0.00461506\n",
      "epoch:   27    |   train:  0.00179912    |   valid:  0.00459405\n",
      "epoch:   28    |   train:  0.00173861    |   valid:  0.00456705\n",
      "epoch:   29    |   train:  0.00168112    |   valid:  0.00454608\n",
      "epoch:   30    |   train:  0.00162902    |   valid:  0.00452375\n",
      "run time: 1203.003805699991\n",
      "test:  0.00273197\n",
      "input_features: 15\n",
      "epoch:    1    |   train:  0.00726779    |   valid:  0.00586962\n",
      "epoch:    2    |   train:  0.00661139    |   valid:  0.00585820\n",
      "epoch:    3    |   train:  0.00638247    |   valid:  0.00581680\n",
      "epoch:    4    |   train:  0.00607451    |   valid:  0.00574040\n",
      "epoch:    5    |   train:  0.00571638    |   valid:  0.00564106\n",
      "epoch:    6    |   train:  0.00534231    |   valid:  0.00553226\n",
      "epoch:    7    |   train:  0.00496120    |   valid:  0.00541590\n",
      "epoch:    8    |   train:  0.00460573    |   valid:  0.00532067\n",
      "epoch:    9    |   train:  0.00426585    |   valid:  0.00522783\n",
      "epoch:   10    |   train:  0.00396935    |   valid:  0.00514943\n",
      "epoch:   11    |   train:  0.00372056    |   valid:  0.00507743\n",
      "epoch:   12    |   train:  0.00349494    |   valid:  0.00503614\n",
      "epoch:   13    |   train:  0.00328688    |   valid:  0.00497463\n",
      "epoch:   14    |   train:  0.00310090    |   valid:  0.00492362\n",
      "epoch:   15    |   train:  0.00293883    |   valid:  0.00487895\n",
      "epoch:   16    |   train:  0.00278680    |   valid:  0.00484070\n",
      "epoch:   17    |   train:  0.00264048    |   valid:  0.00479149\n",
      "epoch:   18    |   train:  0.00250206    |   valid:  0.00474941\n",
      "epoch:   19    |   train:  0.00237872    |   valid:  0.00471602\n",
      "epoch:   20    |   train:  0.00227418    |   valid:  0.00467952\n",
      "epoch:   21    |   train:  0.00216721    |   valid:  0.00465644\n",
      "epoch:   22    |   train:  0.00208150    |   valid:  0.00463652\n",
      "epoch:   23    |   train:  0.00199563    |   valid:  0.00460507\n",
      "epoch:   24    |   train:  0.00191877    |   valid:  0.00457712\n",
      "epoch:   25    |   train:  0.00183688    |   valid:  0.00455235\n",
      "epoch:   26    |   train:  0.00177196    |   valid:  0.00454018\n",
      "epoch:   27    |   train:  0.00173621    |   valid:  0.00451906\n",
      "epoch:   28    |   train:  0.00166985    |   valid:  0.00450153\n",
      "epoch:   29    |   train:  0.00161678    |   valid:  0.00448567\n",
      "epoch:   30    |   train:  0.00156242    |   valid:  0.00445565\n",
      "run time: 2150.2093193000183\n",
      "test:  0.00263938\n",
      "input_features: 16\n",
      "epoch:    1    |   train:  0.00725564    |   valid:  0.00586771\n",
      "epoch:    2    |   train:  0.00660542    |   valid:  0.00586140\n",
      "epoch:    3    |   train:  0.00636668    |   valid:  0.00580959\n",
      "epoch:    4    |   train:  0.00604678    |   valid:  0.00573821\n",
      "epoch:    5    |   train:  0.00570127    |   valid:  0.00564667\n",
      "epoch:    6    |   train:  0.00530383    |   valid:  0.00551848\n",
      "epoch:    7    |   train:  0.00489130    |   valid:  0.00540658\n",
      "epoch:    8    |   train:  0.00451414    |   valid:  0.00529363\n",
      "epoch:    9    |   train:  0.00418035    |   valid:  0.00520168\n",
      "epoch:   10    |   train:  0.00387389    |   valid:  0.00512906\n",
      "epoch:   11    |   train:  0.00360040    |   valid:  0.00505776\n",
      "epoch:   12    |   train:  0.00336229    |   valid:  0.00499789\n",
      "epoch:   13    |   train:  0.00313740    |   valid:  0.00493662\n",
      "epoch:   14    |   train:  0.00295117    |   valid:  0.00488622\n",
      "epoch:   15    |   train:  0.00278264    |   valid:  0.00484508\n",
      "epoch:   16    |   train:  0.00263168    |   valid:  0.00479673\n",
      "epoch:   17    |   train:  0.00251215    |   valid:  0.00475823\n",
      "epoch:   18    |   train:  0.00237892    |   valid:  0.00472196\n",
      "epoch:   19    |   train:  0.00227105    |   valid:  0.00470179\n",
      "epoch:   20    |   train:  0.00219030    |   valid:  0.00466554\n",
      "epoch:   21    |   train:  0.00211044    |   valid:  0.00462597\n",
      "epoch:   22    |   train:  0.00200073    |   valid:  0.00461257\n",
      "epoch:   23    |   train:  0.00192455    |   valid:  0.00458161\n",
      "epoch:   24    |   train:  0.00186643    |   valid:  0.00456108\n",
      "epoch:   25    |   train:  0.00180710    |   valid:  0.00454642\n",
      "epoch:   26    |   train:  0.00174283    |   valid:  0.00453451\n",
      "epoch:   27    |   train:  0.00168592    |   valid:  0.00450822\n",
      "epoch:   28    |   train:  0.00159713    |   valid:  0.00449058\n",
      "epoch:   29    |   train:  0.00155379    |   valid:  0.00447843\n",
      "epoch:   30    |   train:  0.00149336    |   valid:  0.00446473\n",
      "run time: 1263.2263906000298\n",
      "test:  0.00260031\n",
      "input_features: 17\n",
      "epoch:    1    |   train:  0.00724455    |   valid:  0.00586992\n",
      "epoch:    2    |   train:  0.00660165    |   valid:  0.00586771\n",
      "epoch:    3    |   train:  0.00633795    |   valid:  0.00578556\n",
      "epoch:    4    |   train:  0.00598598    |   valid:  0.00571101\n",
      "epoch:    5    |   train:  0.00559275    |   valid:  0.00559770\n",
      "epoch:    6    |   train:  0.00516814    |   valid:  0.00547541\n",
      "epoch:    7    |   train:  0.00477263    |   valid:  0.00537147\n",
      "epoch:    8    |   train:  0.00438683    |   valid:  0.00527535\n",
      "epoch:    9    |   train:  0.00403295    |   valid:  0.00518754\n",
      "epoch:   10    |   train:  0.00372930    |   valid:  0.00509564\n",
      "epoch:   11    |   train:  0.00345311    |   valid:  0.00501580\n",
      "epoch:   12    |   train:  0.00321918    |   valid:  0.00496110\n",
      "epoch:   13    |   train:  0.00300871    |   valid:  0.00490919\n",
      "epoch:   14    |   train:  0.00282530    |   valid:  0.00486659\n",
      "epoch:   15    |   train:  0.00265688    |   valid:  0.00481350\n",
      "epoch:   16    |   train:  0.00250346    |   valid:  0.00477740\n",
      "epoch:   17    |   train:  0.00237438    |   valid:  0.00473820\n",
      "epoch:   18    |   train:  0.00223612    |   valid:  0.00470137\n",
      "epoch:   19    |   train:  0.00211277    |   valid:  0.00466743\n",
      "epoch:   20    |   train:  0.00201867    |   valid:  0.00464493\n",
      "epoch:   21    |   train:  0.00193948    |   valid:  0.00462046\n",
      "epoch:   22    |   train:  0.00188141    |   valid:  0.00458962\n",
      "epoch:   23    |   train:  0.00181613    |   valid:  0.00455464\n",
      "epoch:   24    |   train:  0.00172533    |   valid:  0.00453116\n",
      "epoch:   25    |   train:  0.00165185    |   valid:  0.00450944\n",
      "epoch:   26    |   train:  0.00158562    |   valid:  0.00448968\n",
      "epoch:   27    |   train:  0.00152930    |   valid:  0.00448143\n",
      "epoch:   28    |   train:  0.00148758    |   valid:  0.00445931\n",
      "epoch:   29    |   train:  0.00143903    |   valid:  0.00444501\n",
      "epoch:   30    |   train:  0.00139407    |   valid:  0.00442745\n",
      "run time: 1383.3065794999711\n",
      "test:  0.00250333\n",
      "input_features: 18\n",
      "epoch:    1    |   train:  0.00723528    |   valid:  0.00587026\n",
      "epoch:    2    |   train:  0.00659581    |   valid:  0.00587240\n",
      "epoch:    3    |   train:  0.00631476    |   valid:  0.00577558\n",
      "epoch:    4    |   train:  0.00596050    |   valid:  0.00570809\n",
      "epoch:    5    |   train:  0.00558436    |   valid:  0.00560162\n",
      "epoch:    6    |   train:  0.00514331    |   valid:  0.00547340\n",
      "epoch:    7    |   train:  0.00471804    |   valid:  0.00534283\n",
      "epoch:    8    |   train:  0.00431685    |   valid:  0.00523383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    9    |   train:  0.00396493    |   valid:  0.00514398\n",
      "epoch:   10    |   train:  0.00365339    |   valid:  0.00506262\n",
      "epoch:   11    |   train:  0.00339602    |   valid:  0.00499819\n",
      "epoch:   12    |   train:  0.00315910    |   valid:  0.00494159\n",
      "epoch:   13    |   train:  0.00296406    |   valid:  0.00489219\n",
      "epoch:   14    |   train:  0.00277429    |   valid:  0.00483551\n",
      "epoch:   15    |   train:  0.00260558    |   valid:  0.00479628\n",
      "epoch:   16    |   train:  0.00245917    |   valid:  0.00475121\n",
      "epoch:   17    |   train:  0.00232326    |   valid:  0.00472356\n",
      "epoch:   18    |   train:  0.00222021    |   valid:  0.00468033\n",
      "epoch:   19    |   train:  0.00212231    |   valid:  0.00464590\n",
      "epoch:   20    |   train:  0.00202801    |   valid:  0.00462136\n",
      "epoch:   21    |   train:  0.00194197    |   valid:  0.00459747\n",
      "epoch:   22    |   train:  0.00187151    |   valid:  0.00456627\n",
      "epoch:   23    |   train:  0.00179290    |   valid:  0.00453562\n",
      "epoch:   24    |   train:  0.00170981    |   valid:  0.00451140\n",
      "epoch:   25    |   train:  0.00162864    |   valid:  0.00449003\n",
      "epoch:   26    |   train:  0.00156684    |   valid:  0.00446531\n",
      "epoch:   27    |   train:  0.00149710    |   valid:  0.00444481\n",
      "epoch:   28    |   train:  0.00143242    |   valid:  0.00442524\n",
      "epoch:   29    |   train:  0.00138050    |   valid:  0.00441293\n",
      "epoch:   30    |   train:  0.00131912    |   valid:  0.00439665\n",
      "run time: 1130.894909799972\n",
      "test:  0.00241875\n",
      "input_features: 19\n",
      "epoch:    1    |   train:  0.00722591    |   valid:  0.00587019\n",
      "epoch:    2    |   train:  0.00659248    |   valid:  0.00587466\n",
      "epoch:    3    |   train:  0.00629137    |   valid:  0.00577045\n",
      "epoch:    4    |   train:  0.00590544    |   valid:  0.00570773\n",
      "epoch:    5    |   train:  0.00550797    |   valid:  0.00558046\n",
      "epoch:    6    |   train:  0.00505137    |   valid:  0.00545116\n",
      "epoch:    7    |   train:  0.00462573    |   valid:  0.00533623\n",
      "epoch:    8    |   train:  0.00423648    |   valid:  0.00522692\n",
      "epoch:    9    |   train:  0.00389794    |   valid:  0.00512624\n",
      "epoch:   10    |   train:  0.00359718    |   valid:  0.00503849\n",
      "epoch:   11    |   train:  0.00334612    |   valid:  0.00495925\n",
      "epoch:   12    |   train:  0.00310913    |   valid:  0.00489451\n",
      "epoch:   13    |   train:  0.00290449    |   valid:  0.00483586\n",
      "epoch:   14    |   train:  0.00269880    |   valid:  0.00478061\n",
      "epoch:   15    |   train:  0.00252812    |   valid:  0.00473716\n",
      "epoch:   16    |   train:  0.00237338    |   valid:  0.00469430\n",
      "epoch:   17    |   train:  0.00223108    |   valid:  0.00464995\n",
      "epoch:   18    |   train:  0.00214803    |   valid:  0.00461160\n",
      "epoch:   19    |   train:  0.00203313    |   valid:  0.00457306\n",
      "epoch:   20    |   train:  0.00192182    |   valid:  0.00454232\n",
      "epoch:   21    |   train:  0.00182646    |   valid:  0.00452263\n",
      "epoch:   22    |   train:  0.00175277    |   valid:  0.00449686\n",
      "epoch:   23    |   train:  0.00167602    |   valid:  0.00447451\n",
      "epoch:   24    |   train:  0.00162818    |   valid:  0.00445370\n",
      "epoch:   25    |   train:  0.00154783    |   valid:  0.00444091\n",
      "epoch:   26    |   train:  0.00149240    |   valid:  0.00441821\n",
      "epoch:   27    |   train:  0.00144029    |   valid:  0.00440798\n",
      "epoch:   28    |   train:  0.00136682    |   valid:  0.00438240\n",
      "epoch:   29    |   train:  0.00132002    |   valid:  0.00436806\n",
      "epoch:   30    |   train:  0.00127704    |   valid:  0.00434167\n",
      "run time: 1042.6655020999606\n",
      "test:  0.00236732\n",
      "input_features: 20\n",
      "epoch:    1    |   train:  0.00721780    |   valid:  0.00586987\n",
      "epoch:    2    |   train:  0.00658604    |   valid:  0.00587565\n",
      "epoch:    3    |   train:  0.00627527    |   valid:  0.00576628\n",
      "epoch:    4    |   train:  0.00585839    |   valid:  0.00565913\n",
      "epoch:    5    |   train:  0.00541664    |   valid:  0.00554410\n",
      "epoch:    6    |   train:  0.00496126    |   valid:  0.00542301\n",
      "epoch:    7    |   train:  0.00451423    |   valid:  0.00529117\n",
      "epoch:    8    |   train:  0.00411629    |   valid:  0.00517629\n",
      "epoch:    9    |   train:  0.00376552    |   valid:  0.00508140\n",
      "epoch:   10    |   train:  0.00346123    |   valid:  0.00500242\n",
      "epoch:   11    |   train:  0.00320284    |   valid:  0.00492824\n",
      "epoch:   12    |   train:  0.00296382    |   valid:  0.00486807\n",
      "epoch:   13    |   train:  0.00276600    |   valid:  0.00481311\n",
      "epoch:   14    |   train:  0.00257174    |   valid:  0.00474788\n",
      "epoch:   15    |   train:  0.00239511    |   valid:  0.00469639\n",
      "epoch:   16    |   train:  0.00224711    |   valid:  0.00465171\n",
      "epoch:   17    |   train:  0.00211871    |   valid:  0.00461504\n",
      "epoch:   18    |   train:  0.00198778    |   valid:  0.00457891\n",
      "epoch:   19    |   train:  0.00188329    |   valid:  0.00454762\n",
      "epoch:   20    |   train:  0.00178525    |   valid:  0.00451410\n",
      "epoch:   21    |   train:  0.00169180    |   valid:  0.00448631\n",
      "epoch:   22    |   train:  0.00159447    |   valid:  0.00445892\n",
      "epoch:   23    |   train:  0.00152010    |   valid:  0.00444457\n",
      "epoch:   24    |   train:  0.00144505    |   valid:  0.00441243\n",
      "epoch:   25    |   train:  0.00137168    |   valid:  0.00439719\n",
      "epoch:   26    |   train:  0.00132318    |   valid:  0.00437075\n",
      "epoch:   27    |   train:  0.00126904    |   valid:  0.00436066\n",
      "epoch:   28    |   train:  0.00123825    |   valid:  0.00434324\n",
      "epoch:   29    |   train:  0.00119834    |   valid:  0.00433287\n",
      "epoch:   30    |   train:  0.00115939    |   valid:  0.00431097\n",
      "run time: 1083.4894411999849\n",
      "test:  0.00227154\n",
      "input_features: 21\n",
      "epoch:    1    |   train:  0.00721151    |   valid:  0.00586985\n",
      "epoch:    2    |   train:  0.00658126    |   valid:  0.00587480\n",
      "epoch:    3    |   train:  0.00625413    |   valid:  0.00575725\n",
      "epoch:    4    |   train:  0.00579957    |   valid:  0.00565175\n",
      "epoch:    5    |   train:  0.00534129    |   valid:  0.00552327\n",
      "epoch:    6    |   train:  0.00483782    |   valid:  0.00538103\n",
      "epoch:    7    |   train:  0.00437226    |   valid:  0.00525064\n",
      "epoch:    8    |   train:  0.00394697    |   valid:  0.00512648\n",
      "epoch:    9    |   train:  0.00358481    |   valid:  0.00502945\n",
      "epoch:   10    |   train:  0.00327693    |   valid:  0.00495112\n",
      "epoch:   11    |   train:  0.00303532    |   valid:  0.00487105\n",
      "epoch:   12    |   train:  0.00280017    |   valid:  0.00479755\n",
      "epoch:   13    |   train:  0.00259576    |   valid:  0.00474291\n",
      "epoch:   14    |   train:  0.00244251    |   valid:  0.00468723\n",
      "epoch:   15    |   train:  0.00225381    |   valid:  0.00464771\n",
      "epoch:   16    |   train:  0.00212343    |   valid:  0.00460253\n",
      "epoch:   17    |   train:  0.00201463    |   valid:  0.00456160\n",
      "epoch:   18    |   train:  0.00188562    |   valid:  0.00452869\n",
      "epoch:   19    |   train:  0.00178638    |   valid:  0.00448956\n",
      "epoch:   20    |   train:  0.00169159    |   valid:  0.00446192\n",
      "epoch:   21    |   train:  0.00162054    |   valid:  0.00443238\n",
      "epoch:   22    |   train:  0.00153941    |   valid:  0.00441226\n",
      "epoch:   23    |   train:  0.00146271    |   valid:  0.00439064\n",
      "epoch:   24    |   train:  0.00141033    |   valid:  0.00437764\n",
      "epoch:   25    |   train:  0.00134072    |   valid:  0.00435482\n",
      "epoch:   26    |   train:  0.00128495    |   valid:  0.00433969\n",
      "epoch:   27    |   train:  0.00123299    |   valid:  0.00431315\n",
      "epoch:   28    |   train:  0.00120677    |   valid:  0.00431022\n",
      "epoch:   29    |   train:  0.00117730    |   valid:  0.00429006\n",
      "epoch:   30    |   train:  0.00113436    |   valid:  0.00429291\n",
      "run time: 8289.63838129997\n",
      "test:  0.00225506\n",
      "input_features: 22\n",
      "epoch:    1    |   train:  0.00720631    |   valid:  0.00587269\n",
      "epoch:    2    |   train:  0.00657962    |   valid:  0.00587763\n",
      "epoch:    3    |   train:  0.00623951    |   valid:  0.00575157\n",
      "epoch:    4    |   train:  0.00576438    |   valid:  0.00564923\n",
      "epoch:    5    |   train:  0.00529091    |   valid:  0.00549431\n",
      "epoch:    6    |   train:  0.00476009    |   valid:  0.00535270\n",
      "epoch:    7    |   train:  0.00430470    |   valid:  0.00522932\n",
      "epoch:    8    |   train:  0.00387261    |   valid:  0.00510484\n",
      "epoch:    9    |   train:  0.00351468    |   valid:  0.00500614\n",
      "epoch:   10    |   train:  0.00320742    |   valid:  0.00491655\n",
      "epoch:   11    |   train:  0.00297840    |   valid:  0.00485200\n",
      "epoch:   12    |   train:  0.00275213    |   valid:  0.00478605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   13    |   train:  0.00255454    |   valid:  0.00472567\n",
      "epoch:   14    |   train:  0.00236767    |   valid:  0.00467311\n",
      "epoch:   15    |   train:  0.00221507    |   valid:  0.00462790\n",
      "epoch:   16    |   train:  0.00208726    |   valid:  0.00458887\n",
      "epoch:   17    |   train:  0.00195714    |   valid:  0.00455146\n",
      "epoch:   18    |   train:  0.00184058    |   valid:  0.00451258\n",
      "epoch:   19    |   train:  0.00175628    |   valid:  0.00449148\n",
      "epoch:   20    |   train:  0.00165771    |   valid:  0.00446186\n",
      "epoch:   21    |   train:  0.00158251    |   valid:  0.00443560\n",
      "epoch:   22    |   train:  0.00151256    |   valid:  0.00441050\n",
      "epoch:   23    |   train:  0.00144050    |   valid:  0.00438258\n",
      "epoch:   24    |   train:  0.00139150    |   valid:  0.00436078\n",
      "epoch:   25    |   train:  0.00132439    |   valid:  0.00433949\n",
      "epoch:   26    |   train:  0.00127432    |   valid:  0.00433170\n",
      "epoch:   27    |   train:  0.00122687    |   valid:  0.00430289\n",
      "epoch:   28    |   train:  0.00119373    |   valid:  0.00429644\n",
      "epoch:   29    |   train:  0.00115681    |   valid:  0.00427256\n",
      "epoch:   30    |   train:  0.00112212    |   valid:  0.00426802\n",
      "run time: 1304.3760744999745\n",
      "test:  0.00223235\n",
      "input_features: 23\n",
      "epoch:    1    |   train:  0.00720052    |   valid:  0.00587716\n",
      "epoch:    2    |   train:  0.00657626    |   valid:  0.00587704\n",
      "epoch:    3    |   train:  0.00620676    |   valid:  0.00573773\n",
      "epoch:    4    |   train:  0.00570700    |   valid:  0.00561160\n",
      "epoch:    5    |   train:  0.00522351    |   valid:  0.00547130\n",
      "epoch:    6    |   train:  0.00468163    |   valid:  0.00531051\n",
      "epoch:    7    |   train:  0.00419738    |   valid:  0.00517022\n",
      "epoch:    8    |   train:  0.00377714    |   valid:  0.00506878\n",
      "epoch:    9    |   train:  0.00340203    |   valid:  0.00497810\n",
      "epoch:   10    |   train:  0.00311415    |   valid:  0.00490287\n",
      "epoch:   11    |   train:  0.00285899    |   valid:  0.00483946\n",
      "epoch:   12    |   train:  0.00265063    |   valid:  0.00477936\n",
      "epoch:   13    |   train:  0.00245652    |   valid:  0.00472315\n",
      "epoch:   14    |   train:  0.00226461    |   valid:  0.00467164\n",
      "epoch:   15    |   train:  0.00210978    |   valid:  0.00462578\n",
      "epoch:   16    |   train:  0.00198584    |   valid:  0.00458139\n",
      "epoch:   17    |   train:  0.00186631    |   valid:  0.00455028\n",
      "epoch:   18    |   train:  0.00175303    |   valid:  0.00451576\n",
      "epoch:   19    |   train:  0.00166352    |   valid:  0.00448391\n",
      "epoch:   20    |   train:  0.00157699    |   valid:  0.00445862\n",
      "epoch:   21    |   train:  0.00150345    |   valid:  0.00442983\n",
      "epoch:   22    |   train:  0.00143091    |   valid:  0.00441251\n",
      "epoch:   23    |   train:  0.00137596    |   valid:  0.00439502\n",
      "epoch:   24    |   train:  0.00130388    |   valid:  0.00437473\n",
      "epoch:   25    |   train:  0.00124339    |   valid:  0.00435695\n",
      "epoch:   26    |   train:  0.00120133    |   valid:  0.00433763\n",
      "epoch:   27    |   train:  0.00114724    |   valid:  0.00432084\n",
      "epoch:   28    |   train:  0.00110141    |   valid:  0.00430926\n",
      "epoch:   29    |   train:  0.00107075    |   valid:  0.00429792\n",
      "epoch:   30    |   train:  0.00102481    |   valid:  0.00428589\n",
      "run time: 1635.401154400024\n",
      "test:  0.00216468\n",
      "input_features: 24\n",
      "epoch:    1    |   train:  0.00719648    |   valid:  0.00588141\n",
      "epoch:    2    |   train:  0.00657328    |   valid:  0.00587804\n",
      "epoch:    3    |   train:  0.00617957    |   valid:  0.00572133\n",
      "epoch:    4    |   train:  0.00564191    |   valid:  0.00559384\n",
      "epoch:    5    |   train:  0.00511320    |   valid:  0.00544072\n",
      "epoch:    6    |   train:  0.00453538    |   valid:  0.00528899\n",
      "epoch:    7    |   train:  0.00405548    |   valid:  0.00516311\n",
      "epoch:    8    |   train:  0.00364169    |   valid:  0.00505456\n",
      "epoch:    9    |   train:  0.00329141    |   valid:  0.00496965\n",
      "epoch:   10    |   train:  0.00300727    |   valid:  0.00488807\n",
      "epoch:   11    |   train:  0.00276863    |   valid:  0.00482289\n",
      "epoch:   12    |   train:  0.00255626    |   valid:  0.00477410\n",
      "epoch:   13    |   train:  0.00236744    |   valid:  0.00471901\n",
      "epoch:   14    |   train:  0.00219867    |   valid:  0.00467031\n",
      "epoch:   15    |   train:  0.00205338    |   valid:  0.00461812\n",
      "epoch:   16    |   train:  0.00191805    |   valid:  0.00457496\n",
      "epoch:   17    |   train:  0.00178860    |   valid:  0.00454009\n",
      "epoch:   18    |   train:  0.00168161    |   valid:  0.00451161\n",
      "epoch:   19    |   train:  0.00159437    |   valid:  0.00448370\n",
      "epoch:   20    |   train:  0.00152512    |   valid:  0.00446019\n",
      "epoch:   21    |   train:  0.00147210    |   valid:  0.00442809\n",
      "epoch:   22    |   train:  0.00141368    |   valid:  0.00440399\n",
      "epoch:   23    |   train:  0.00135010    |   valid:  0.00438992\n",
      "epoch:   24    |   train:  0.00129455    |   valid:  0.00437540\n",
      "epoch:   25    |   train:  0.00124895    |   valid:  0.00435983\n",
      "epoch:   26    |   train:  0.00119378    |   valid:  0.00434932\n",
      "epoch:   27    |   train:  0.00114942    |   valid:  0.00432785\n",
      "epoch:   28    |   train:  0.00110179    |   valid:  0.00431520\n",
      "epoch:   29    |   train:  0.00106214    |   valid:  0.00430046\n",
      "epoch:   30    |   train:  0.00102244    |   valid:  0.00429423\n",
      "run time: 1205.2161556999781\n",
      "test:  0.00219121\n",
      "input_features: 25\n",
      "epoch:    1    |   train:  0.00719298    |   valid:  0.00588158\n",
      "epoch:    2    |   train:  0.00656822    |   valid:  0.00586839\n",
      "epoch:    3    |   train:  0.00613362    |   valid:  0.00569987\n",
      "epoch:    4    |   train:  0.00557216    |   valid:  0.00557043\n",
      "epoch:    5    |   train:  0.00505319    |   valid:  0.00542026\n",
      "epoch:    6    |   train:  0.00446566    |   valid:  0.00527105\n",
      "epoch:    7    |   train:  0.00397095    |   valid:  0.00514050\n",
      "epoch:    8    |   train:  0.00355062    |   valid:  0.00503367\n",
      "epoch:    9    |   train:  0.00320910    |   valid:  0.00494937\n",
      "epoch:   10    |   train:  0.00292404    |   valid:  0.00487305\n",
      "epoch:   11    |   train:  0.00266979    |   valid:  0.00480251\n",
      "epoch:   12    |   train:  0.00244190    |   valid:  0.00474307\n",
      "epoch:   13    |   train:  0.00225955    |   valid:  0.00468347\n",
      "epoch:   14    |   train:  0.00209695    |   valid:  0.00464245\n",
      "epoch:   15    |   train:  0.00196153    |   valid:  0.00458891\n",
      "epoch:   16    |   train:  0.00182422    |   valid:  0.00455051\n",
      "epoch:   17    |   train:  0.00172315    |   valid:  0.00451661\n",
      "epoch:   18    |   train:  0.00163062    |   valid:  0.00448983\n",
      "epoch:   19    |   train:  0.00154178    |   valid:  0.00445777\n",
      "epoch:   20    |   train:  0.00145650    |   valid:  0.00442814\n",
      "epoch:   21    |   train:  0.00137970    |   valid:  0.00441120\n",
      "epoch:   22    |   train:  0.00132147    |   valid:  0.00439132\n",
      "epoch:   23    |   train:  0.00126224    |   valid:  0.00437078\n",
      "epoch:   24    |   train:  0.00120810    |   valid:  0.00436514\n",
      "epoch:   25    |   train:  0.00117428    |   valid:  0.00434458\n",
      "epoch:   26    |   train:  0.00113693    |   valid:  0.00432491\n",
      "epoch:   27    |   train:  0.00109881    |   valid:  0.00430760\n",
      "epoch:   28    |   train:  0.00107188    |   valid:  0.00429306\n",
      "epoch:   29    |   train:  0.00103066    |   valid:  0.00429415\n",
      "epoch:   30    |   train:  0.00099748    |   valid:  0.00426334\n",
      "run time: 6713.265827600029\n",
      "test:  0.00214509\n",
      "input_features: 26\n",
      "epoch:    1    |   train:  0.00718903    |   valid:  0.00588242\n",
      "epoch:    2    |   train:  0.00656043    |   valid:  0.00586016\n",
      "epoch:    3    |   train:  0.00608362    |   valid:  0.00567414\n",
      "epoch:    4    |   train:  0.00550618    |   valid:  0.00552705\n",
      "epoch:    5    |   train:  0.00491386    |   valid:  0.00537934\n",
      "epoch:    6    |   train:  0.00434230    |   valid:  0.00524336\n",
      "epoch:    7    |   train:  0.00385396    |   valid:  0.00511184\n",
      "epoch:    8    |   train:  0.00344058    |   valid:  0.00500687\n",
      "epoch:    9    |   train:  0.00309608    |   valid:  0.00491423\n",
      "epoch:   10    |   train:  0.00281774    |   valid:  0.00483698\n",
      "epoch:   11    |   train:  0.00256309    |   valid:  0.00476624\n",
      "epoch:   12    |   train:  0.00233630    |   valid:  0.00470394\n",
      "epoch:   13    |   train:  0.00215254    |   valid:  0.00464275\n",
      "epoch:   14    |   train:  0.00199598    |   valid:  0.00459914\n",
      "epoch:   15    |   train:  0.00188830    |   valid:  0.00455249\n",
      "epoch:   16    |   train:  0.00176279    |   valid:  0.00451616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   17    |   train:  0.00165339    |   valid:  0.00448123\n",
      "epoch:   18    |   train:  0.00156218    |   valid:  0.00445702\n",
      "epoch:   19    |   train:  0.00148530    |   valid:  0.00443147\n",
      "epoch:   20    |   train:  0.00141236    |   valid:  0.00440516\n",
      "epoch:   21    |   train:  0.00133994    |   valid:  0.00438172\n",
      "epoch:   22    |   train:  0.00129360    |   valid:  0.00435170\n",
      "epoch:   23    |   train:  0.00122215    |   valid:  0.00432903\n",
      "epoch:   24    |   train:  0.00117501    |   valid:  0.00430586\n",
      "epoch:   25    |   train:  0.00112106    |   valid:  0.00428504\n",
      "epoch:   26    |   train:  0.00107587    |   valid:  0.00426979\n",
      "epoch:   27    |   train:  0.00102355    |   valid:  0.00424811\n",
      "epoch:   28    |   train:  0.00098542    |   valid:  0.00423282\n",
      "epoch:   29    |   train:  0.00094292    |   valid:  0.00421428\n",
      "epoch:   30    |   train:  0.00090612    |   valid:  0.00420223\n",
      "run time: 1067.7671113000251\n",
      "test:  0.00205738\n",
      "input_features: 27\n",
      "epoch:    1    |   train:  0.00718504    |   valid:  0.00588414\n",
      "epoch:    2    |   train:  0.00655551    |   valid:  0.00585515\n",
      "epoch:    3    |   train:  0.00605548    |   valid:  0.00566981\n",
      "epoch:    4    |   train:  0.00545418    |   valid:  0.00554898\n",
      "epoch:    5    |   train:  0.00490664    |   valid:  0.00542270\n",
      "epoch:    6    |   train:  0.00434587    |   valid:  0.00525573\n",
      "epoch:    7    |   train:  0.00381894    |   valid:  0.00512500\n",
      "epoch:    8    |   train:  0.00339356    |   valid:  0.00501895\n",
      "epoch:    9    |   train:  0.00304708    |   valid:  0.00492650\n",
      "epoch:   10    |   train:  0.00275190    |   valid:  0.00485284\n",
      "epoch:   11    |   train:  0.00250978    |   valid:  0.00477582\n",
      "epoch:   12    |   train:  0.00230075    |   valid:  0.00471686\n",
      "epoch:   13    |   train:  0.00211188    |   valid:  0.00466664\n",
      "epoch:   14    |   train:  0.00195336    |   valid:  0.00461482\n",
      "epoch:   15    |   train:  0.00183081    |   valid:  0.00457311\n",
      "epoch:   16    |   train:  0.00169674    |   valid:  0.00453513\n",
      "epoch:   17    |   train:  0.00158674    |   valid:  0.00450343\n",
      "epoch:   18    |   train:  0.00149623    |   valid:  0.00446345\n",
      "epoch:   19    |   train:  0.00140104    |   valid:  0.00443741\n",
      "epoch:   20    |   train:  0.00131970    |   valid:  0.00441488\n",
      "epoch:   21    |   train:  0.00124152    |   valid:  0.00439755\n",
      "epoch:   22    |   train:  0.00118870    |   valid:  0.00436976\n",
      "epoch:   23    |   train:  0.00114115    |   valid:  0.00436555\n",
      "epoch:   24    |   train:  0.00109814    |   valid:  0.00434110\n",
      "epoch:   25    |   train:  0.00106521    |   valid:  0.00432316\n",
      "epoch:   26    |   train:  0.00102186    |   valid:  0.00430716\n",
      "epoch:   27    |   train:  0.00097822    |   valid:  0.00429225\n",
      "epoch:   28    |   train:  0.00094402    |   valid:  0.00427761\n",
      "epoch:   29    |   train:  0.00090767    |   valid:  0.00426323\n",
      "epoch:   30    |   train:  0.00088866    |   valid:  0.00426139\n",
      "run time: 1212.9025845000288\n",
      "test:  0.00208352\n",
      "input_features: 28\n",
      "epoch:    1    |   train:  0.00718261    |   valid:  0.00588249\n",
      "epoch:    2    |   train:  0.00654766    |   valid:  0.00585605\n",
      "epoch:    3    |   train:  0.00603215    |   valid:  0.00566459\n",
      "epoch:    4    |   train:  0.00543317    |   valid:  0.00553196\n",
      "epoch:    5    |   train:  0.00484691    |   valid:  0.00538033\n",
      "epoch:    6    |   train:  0.00424196    |   valid:  0.00520996\n",
      "epoch:    7    |   train:  0.00370568    |   valid:  0.00507127\n",
      "epoch:    8    |   train:  0.00327905    |   valid:  0.00495686\n",
      "epoch:    9    |   train:  0.00294931    |   valid:  0.00486364\n",
      "epoch:   10    |   train:  0.00264734    |   valid:  0.00478968\n",
      "epoch:   11    |   train:  0.00242183    |   valid:  0.00472431\n",
      "epoch:   12    |   train:  0.00223755    |   valid:  0.00466748\n",
      "epoch:   13    |   train:  0.00204443    |   valid:  0.00461564\n",
      "epoch:   14    |   train:  0.00189351    |   valid:  0.00456941\n",
      "epoch:   15    |   train:  0.00176822    |   valid:  0.00452507\n",
      "epoch:   16    |   train:  0.00165475    |   valid:  0.00449222\n",
      "epoch:   17    |   train:  0.00154633    |   valid:  0.00445331\n",
      "epoch:   18    |   train:  0.00146212    |   valid:  0.00443034\n",
      "epoch:   19    |   train:  0.00139488    |   valid:  0.00440864\n",
      "epoch:   20    |   train:  0.00132416    |   valid:  0.00438207\n",
      "epoch:   21    |   train:  0.00125750    |   valid:  0.00436208\n",
      "epoch:   22    |   train:  0.00121888    |   valid:  0.00434407\n",
      "epoch:   23    |   train:  0.00117808    |   valid:  0.00432073\n",
      "epoch:   24    |   train:  0.00112380    |   valid:  0.00429888\n",
      "epoch:   25    |   train:  0.00107525    |   valid:  0.00427898\n",
      "epoch:   26    |   train:  0.00102677    |   valid:  0.00425697\n",
      "epoch:   27    |   train:  0.00098762    |   valid:  0.00423118\n",
      "epoch:   28    |   train:  0.00094845    |   valid:  0.00422320\n",
      "epoch:   29    |   train:  0.00091986    |   valid:  0.00420351\n",
      "epoch:   30    |   train:  0.00087977    |   valid:  0.00418879\n",
      "run time: 1200.578791500011\n",
      "test:  0.00203672\n",
      "input_features: 29\n",
      "epoch:    1    |   train:  0.00717986    |   valid:  0.00588424\n",
      "epoch:    2    |   train:  0.00654286    |   valid:  0.00584802\n",
      "epoch:    3    |   train:  0.00599983    |   valid:  0.00564315\n",
      "epoch:    4    |   train:  0.00536262    |   valid:  0.00549681\n",
      "epoch:    5    |   train:  0.00472525    |   valid:  0.00531922\n",
      "epoch:    6    |   train:  0.00411878    |   valid:  0.00516037\n",
      "epoch:    7    |   train:  0.00361271    |   valid:  0.00504028\n",
      "epoch:    8    |   train:  0.00320567    |   valid:  0.00493959\n",
      "epoch:    9    |   train:  0.00285379    |   valid:  0.00485297\n",
      "epoch:   10    |   train:  0.00256020    |   valid:  0.00478436\n",
      "epoch:   11    |   train:  0.00234157    |   valid:  0.00472273\n",
      "epoch:   12    |   train:  0.00214887    |   valid:  0.00467204\n",
      "epoch:   13    |   train:  0.00197535    |   valid:  0.00462933\n",
      "epoch:   14    |   train:  0.00184010    |   valid:  0.00459452\n",
      "epoch:   15    |   train:  0.00171657    |   valid:  0.00454909\n",
      "epoch:   16    |   train:  0.00160910    |   valid:  0.00452678\n",
      "epoch:   17    |   train:  0.00151743    |   valid:  0.00449467\n",
      "epoch:   18    |   train:  0.00142537    |   valid:  0.00446770\n",
      "epoch:   19    |   train:  0.00135091    |   valid:  0.00444380\n",
      "epoch:   20    |   train:  0.00129392    |   valid:  0.00442326\n",
      "epoch:   21    |   train:  0.00122340    |   valid:  0.00439123\n",
      "epoch:   22    |   train:  0.00116315    |   valid:  0.00437665\n",
      "epoch:   23    |   train:  0.00110733    |   valid:  0.00435790\n",
      "epoch:   24    |   train:  0.00106794    |   valid:  0.00434370\n",
      "epoch:   25    |   train:  0.00101806    |   valid:  0.00431964\n",
      "epoch:   26    |   train:  0.00097831    |   valid:  0.00431644\n",
      "epoch:   27    |   train:  0.00093354    |   valid:  0.00429402\n",
      "epoch:   28    |   train:  0.00090054    |   valid:  0.00428583\n",
      "epoch:   29    |   train:  0.00086759    |   valid:  0.00426501\n",
      "epoch:   30    |   train:  0.00083772    |   valid:  0.00426688\n",
      "run time: 1295.225619499979\n",
      "test:  0.00203152\n",
      "input_features: 30\n",
      "epoch:    1    |   train:  0.00717769    |   valid:  0.00588827\n",
      "epoch:    2    |   train:  0.00653322    |   valid:  0.00584006\n",
      "epoch:    3    |   train:  0.00596478    |   valid:  0.00563402\n",
      "epoch:    4    |   train:  0.00531343    |   valid:  0.00548545\n",
      "epoch:    5    |   train:  0.00467570    |   valid:  0.00533163\n",
      "epoch:    6    |   train:  0.00408431    |   valid:  0.00517895\n",
      "epoch:    7    |   train:  0.00358394    |   valid:  0.00504091\n",
      "epoch:    8    |   train:  0.00317709    |   valid:  0.00492749\n",
      "epoch:    9    |   train:  0.00284089    |   valid:  0.00482724\n",
      "epoch:   10    |   train:  0.00255563    |   valid:  0.00474736\n",
      "epoch:   11    |   train:  0.00232744    |   valid:  0.00467615\n",
      "epoch:   12    |   train:  0.00212694    |   valid:  0.00462814\n",
      "epoch:   13    |   train:  0.00196347    |   valid:  0.00457353\n",
      "epoch:   14    |   train:  0.00183947    |   valid:  0.00453274\n",
      "epoch:   15    |   train:  0.00170695    |   valid:  0.00448544\n",
      "epoch:   16    |   train:  0.00159829    |   valid:  0.00445640\n",
      "epoch:   17    |   train:  0.00149724    |   valid:  0.00442164\n",
      "epoch:   18    |   train:  0.00140998    |   valid:  0.00440416\n",
      "epoch:   19    |   train:  0.00134027    |   valid:  0.00437032\n",
      "epoch:   20    |   train:  0.00127383    |   valid:  0.00436208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   21    |   train:  0.00120766    |   valid:  0.00433173\n",
      "epoch:   22    |   train:  0.00115493    |   valid:  0.00432264\n",
      "epoch:   23    |   train:  0.00111544    |   valid:  0.00428866\n",
      "epoch:   24    |   train:  0.00106458    |   valid:  0.00428716\n",
      "epoch:   25    |   train:  0.00103057    |   valid:  0.00425956\n",
      "epoch:   26    |   train:  0.00099121    |   valid:  0.00425266\n",
      "epoch:   27    |   train:  0.00095676    |   valid:  0.00422756\n",
      "epoch:   28    |   train:  0.00092294    |   valid:  0.00421754\n",
      "epoch:   29    |   train:  0.00088117    |   valid:  0.00419358\n",
      "epoch:   30    |   train:  0.00084145    |   valid:  0.00418437\n",
      "run time: 6456.92212969996\n",
      "test:  0.00201486\n",
      "input_features: 31\n",
      "epoch:    1    |   train:  0.00717564    |   valid:  0.00588959\n",
      "epoch:    2    |   train:  0.00652922    |   valid:  0.00584090\n",
      "epoch:    3    |   train:  0.00595174    |   valid:  0.00563026\n",
      "epoch:    4    |   train:  0.00528544    |   valid:  0.00546073\n",
      "epoch:    5    |   train:  0.00462529    |   valid:  0.00528839\n",
      "epoch:    6    |   train:  0.00401456    |   valid:  0.00513189\n",
      "epoch:    7    |   train:  0.00352079    |   valid:  0.00501629\n",
      "epoch:    8    |   train:  0.00311692    |   valid:  0.00491803\n",
      "epoch:    9    |   train:  0.00278839    |   valid:  0.00482549\n",
      "epoch:   10    |   train:  0.00250127    |   valid:  0.00474841\n",
      "epoch:   11    |   train:  0.00226438    |   valid:  0.00467606\n",
      "epoch:   12    |   train:  0.00207892    |   valid:  0.00462913\n",
      "epoch:   13    |   train:  0.00190428    |   valid:  0.00458053\n",
      "epoch:   14    |   train:  0.00176493    |   valid:  0.00454075\n",
      "epoch:   15    |   train:  0.00164489    |   valid:  0.00450704\n",
      "epoch:   16    |   train:  0.00154456    |   valid:  0.00447814\n",
      "epoch:   17    |   train:  0.00145771    |   valid:  0.00444265\n",
      "epoch:   18    |   train:  0.00140532    |   valid:  0.00441480\n",
      "epoch:   19    |   train:  0.00132339    |   valid:  0.00438969\n",
      "epoch:   20    |   train:  0.00125965    |   valid:  0.00436632\n",
      "epoch:   21    |   train:  0.00118955    |   valid:  0.00434417\n",
      "epoch:   22    |   train:  0.00113231    |   valid:  0.00432482\n",
      "epoch:   23    |   train:  0.00108719    |   valid:  0.00430939\n",
      "epoch:   24    |   train:  0.00102919    |   valid:  0.00429030\n",
      "epoch:   25    |   train:  0.00098667    |   valid:  0.00427288\n",
      "epoch:   26    |   train:  0.00095681    |   valid:  0.00425521\n",
      "epoch:   27    |   train:  0.00092441    |   valid:  0.00423887\n",
      "epoch:   28    |   train:  0.00088275    |   valid:  0.00422513\n",
      "epoch:   29    |   train:  0.00084387    |   valid:  0.00420065\n",
      "epoch:   30    |   train:  0.00080951    |   valid:  0.00419152\n",
      "run time: 1560.9947522000293\n",
      "test:  0.00196519\n",
      "input_features: 32\n",
      "epoch:    1    |   train:  0.00717504    |   valid:  0.00589064\n",
      "epoch:    2    |   train:  0.00651994    |   valid:  0.00583173\n",
      "epoch:    3    |   train:  0.00592138    |   valid:  0.00562729\n",
      "epoch:    4    |   train:  0.00524094    |   valid:  0.00545770\n",
      "epoch:    5    |   train:  0.00457421    |   valid:  0.00528730\n",
      "epoch:    6    |   train:  0.00396957    |   valid:  0.00513542\n",
      "epoch:    7    |   train:  0.00347081    |   valid:  0.00499287\n",
      "epoch:    8    |   train:  0.00303229    |   valid:  0.00488410\n",
      "epoch:    9    |   train:  0.00271325    |   valid:  0.00478804\n",
      "epoch:   10    |   train:  0.00244044    |   valid:  0.00470849\n",
      "epoch:   11    |   train:  0.00220833    |   valid:  0.00463939\n",
      "epoch:   12    |   train:  0.00202072    |   valid:  0.00458641\n",
      "epoch:   13    |   train:  0.00186600    |   valid:  0.00452873\n",
      "epoch:   14    |   train:  0.00173297    |   valid:  0.00449353\n",
      "epoch:   15    |   train:  0.00161589    |   valid:  0.00444970\n",
      "epoch:   16    |   train:  0.00150342    |   valid:  0.00441956\n",
      "epoch:   17    |   train:  0.00141874    |   valid:  0.00438250\n",
      "epoch:   18    |   train:  0.00134494    |   valid:  0.00437032\n",
      "epoch:   19    |   train:  0.00127379    |   valid:  0.00433644\n",
      "epoch:   20    |   train:  0.00120699    |   valid:  0.00432103\n",
      "epoch:   21    |   train:  0.00114321    |   valid:  0.00428472\n",
      "epoch:   22    |   train:  0.00107497    |   valid:  0.00427418\n",
      "epoch:   23    |   train:  0.00103327    |   valid:  0.00424368\n",
      "epoch:   24    |   train:  0.00097847    |   valid:  0.00423849\n",
      "epoch:   25    |   train:  0.00093463    |   valid:  0.00420713\n",
      "epoch:   26    |   train:  0.00089680    |   valid:  0.00420822\n",
      "epoch:   27    |   train:  0.00086343    |   valid:  0.00417985\n",
      "epoch:   28    |   train:  0.00082333    |   valid:  0.00418981\n",
      "epoch:   29    |   train:  0.00078614    |   valid:  0.00415750\n",
      "epoch:   30    |   train:  0.00075441    |   valid:  0.00414973\n",
      "run time: 1769.6280744000105\n",
      "test:  0.00191676\n",
      "input_features: 33\n",
      "epoch:    1    |   train:  0.00717328    |   valid:  0.00589244\n",
      "epoch:    2    |   train:  0.00651620    |   valid:  0.00582554\n",
      "epoch:    3    |   train:  0.00589686    |   valid:  0.00562859\n",
      "epoch:    4    |   train:  0.00518773    |   valid:  0.00545368\n",
      "epoch:    5    |   train:  0.00452405    |   valid:  0.00526079\n",
      "epoch:    6    |   train:  0.00388300    |   valid:  0.00509289\n",
      "epoch:    7    |   train:  0.00336719    |   valid:  0.00495820\n",
      "epoch:    8    |   train:  0.00296845    |   valid:  0.00485309\n",
      "epoch:    9    |   train:  0.00262553    |   valid:  0.00475853\n",
      "epoch:   10    |   train:  0.00236197    |   valid:  0.00468038\n",
      "epoch:   11    |   train:  0.00214674    |   valid:  0.00461636\n",
      "epoch:   12    |   train:  0.00196242    |   valid:  0.00455775\n",
      "epoch:   13    |   train:  0.00181261    |   valid:  0.00450561\n",
      "epoch:   14    |   train:  0.00167913    |   valid:  0.00447157\n",
      "epoch:   15    |   train:  0.00156986    |   valid:  0.00442721\n",
      "epoch:   16    |   train:  0.00147796    |   valid:  0.00439056\n",
      "epoch:   17    |   train:  0.00138215    |   valid:  0.00435509\n",
      "epoch:   18    |   train:  0.00131199    |   valid:  0.00432903\n",
      "epoch:   19    |   train:  0.00123268    |   valid:  0.00430228\n",
      "epoch:   20    |   train:  0.00116080    |   valid:  0.00427809\n",
      "epoch:   21    |   train:  0.00110476    |   valid:  0.00425520\n",
      "epoch:   22    |   train:  0.00104923    |   valid:  0.00423472\n",
      "epoch:   23    |   train:  0.00099170    |   valid:  0.00421202\n",
      "epoch:   24    |   train:  0.00094988    |   valid:  0.00419534\n",
      "epoch:   25    |   train:  0.00090321    |   valid:  0.00416996\n",
      "epoch:   26    |   train:  0.00086599    |   valid:  0.00415670\n",
      "epoch:   27    |   train:  0.00082938    |   valid:  0.00413719\n",
      "epoch:   28    |   train:  0.00079755    |   valid:  0.00412745\n",
      "epoch:   29    |   train:  0.00076303    |   valid:  0.00410630\n",
      "epoch:   30    |   train:  0.00074610    |   valid:  0.00410266\n",
      "run time: 1304.7175972000114\n",
      "test:  0.00189822\n",
      "input_features: 34\n",
      "epoch:    1    |   train:  0.00717103    |   valid:  0.00589658\n",
      "epoch:    2    |   train:  0.00651294    |   valid:  0.00582307\n",
      "epoch:    3    |   train:  0.00589051    |   valid:  0.00563353\n",
      "epoch:    4    |   train:  0.00520013    |   valid:  0.00545219\n",
      "epoch:    5    |   train:  0.00451165    |   valid:  0.00528425\n",
      "epoch:    6    |   train:  0.00388493    |   valid:  0.00512521\n",
      "epoch:    7    |   train:  0.00336600    |   valid:  0.00498903\n",
      "epoch:    8    |   train:  0.00294914    |   valid:  0.00489654\n",
      "epoch:    9    |   train:  0.00262284    |   valid:  0.00480135\n",
      "epoch:   10    |   train:  0.00233683    |   valid:  0.00474261\n",
      "epoch:   11    |   train:  0.00211275    |   valid:  0.00467337\n",
      "epoch:   12    |   train:  0.00192923    |   valid:  0.00462756\n",
      "epoch:   13    |   train:  0.00177043    |   valid:  0.00458064\n",
      "epoch:   14    |   train:  0.00164409    |   valid:  0.00454506\n",
      "epoch:   15    |   train:  0.00151457    |   valid:  0.00450795\n",
      "epoch:   16    |   train:  0.00142382    |   valid:  0.00449327\n",
      "epoch:   17    |   train:  0.00135041    |   valid:  0.00446712\n",
      "epoch:   18    |   train:  0.00130993    |   valid:  0.00444119\n",
      "epoch:   19    |   train:  0.00122640    |   valid:  0.00439854\n",
      "epoch:   20    |   train:  0.00115692    |   valid:  0.00438735\n",
      "epoch:   21    |   train:  0.00111569    |   valid:  0.00436046\n",
      "epoch:   22    |   train:  0.00105449    |   valid:  0.00434539\n",
      "epoch:   23    |   train:  0.00100758    |   valid:  0.00430985\n",
      "epoch:   24    |   train:  0.00094946    |   valid:  0.00429650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   25    |   train:  0.00090908    |   valid:  0.00427256\n",
      "epoch:   26    |   train:  0.00087269    |   valid:  0.00426131\n",
      "epoch:   27    |   train:  0.00082796    |   valid:  0.00423337\n",
      "epoch:   28    |   train:  0.00081453    |   valid:  0.00424206\n",
      "epoch:   29    |   train:  0.00078833    |   valid:  0.00421831\n",
      "epoch:   30    |   train:  0.00076062    |   valid:  0.00421114\n",
      "run time: 1314.5879901000299\n",
      "test:  0.00195208\n",
      "input_features: 35\n",
      "epoch:    1    |   train:  0.00716928    |   valid:  0.00589842\n",
      "epoch:    2    |   train:  0.00650933    |   valid:  0.00581542\n",
      "epoch:    3    |   train:  0.00587779    |   valid:  0.00563081\n",
      "epoch:    4    |   train:  0.00518648    |   valid:  0.00544429\n",
      "epoch:    5    |   train:  0.00447159    |   valid:  0.00525670\n",
      "epoch:    6    |   train:  0.00384755    |   valid:  0.00510789\n",
      "epoch:    7    |   train:  0.00332668    |   valid:  0.00497107\n",
      "epoch:    8    |   train:  0.00293662    |   valid:  0.00486386\n",
      "epoch:    9    |   train:  0.00259140    |   valid:  0.00477202\n",
      "epoch:   10    |   train:  0.00233003    |   valid:  0.00469641\n",
      "epoch:   11    |   train:  0.00210808    |   valid:  0.00464588\n",
      "epoch:   12    |   train:  0.00192460    |   valid:  0.00458619\n",
      "epoch:   13    |   train:  0.00176823    |   valid:  0.00454533\n",
      "epoch:   14    |   train:  0.00163877    |   valid:  0.00450471\n",
      "epoch:   15    |   train:  0.00151418    |   valid:  0.00447273\n",
      "epoch:   16    |   train:  0.00143174    |   valid:  0.00444608\n",
      "epoch:   17    |   train:  0.00134380    |   valid:  0.00441358\n",
      "epoch:   18    |   train:  0.00126260    |   valid:  0.00439785\n",
      "epoch:   19    |   train:  0.00119155    |   valid:  0.00436853\n",
      "epoch:   20    |   train:  0.00113030    |   valid:  0.00435296\n",
      "epoch:   21    |   train:  0.00108870    |   valid:  0.00433128\n",
      "epoch:   22    |   train:  0.00102985    |   valid:  0.00431466\n",
      "epoch:   23    |   train:  0.00098395    |   valid:  0.00429018\n",
      "epoch:   24    |   train:  0.00093559    |   valid:  0.00427863\n",
      "epoch:   25    |   train:  0.00089800    |   valid:  0.00426006\n",
      "epoch:   26    |   train:  0.00086126    |   valid:  0.00424701\n",
      "epoch:   27    |   train:  0.00082321    |   valid:  0.00422351\n",
      "epoch:   28    |   train:  0.00080853    |   valid:  0.00421347\n",
      "epoch:   29    |   train:  0.00078134    |   valid:  0.00420119\n",
      "epoch:   30    |   train:  0.00076318    |   valid:  0.00419547\n",
      "run time: 1343.6683773999684\n",
      "test:  0.00195527\n"
     ]
    }
   ],
   "source": [
    "#check input features \n",
    "for i in range(10, 36):\n",
    "    print('input_features:', i)\n",
    "    start = timeit.default_timer()\n",
    "    ae = AE(nb_inputs, nb_outputs, i)\n",
    "    learning_rate = 0.01\n",
    "    weight_decay = 0.1\n",
    "    optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    ae.criterion = nn.MSELoss()\n",
    "\n",
    "    nb_epoch = 30\n",
    "\n",
    "    for epoch in range(1, nb_epoch + 1):\n",
    "        ae, train_loss, train_s = fit(model=ae, x=train, y=train)\n",
    "        ae, valid_loss, valid_s = fit(model=ae, x=valid, y=valid, valid=True)\n",
    "\n",
    "        print(\"epoch: \", \"{:3.0f}\".format(epoch), \"   |   train: \", \"{:1.8f}\".format(train_loss.numpy() / train_s), \\\n",
    "                        '   |   valid: ', \"{:1.8f}\".format(valid_loss.numpy() / valid_s))\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    print('run time:', stop-start)\n",
    "\n",
    "    ae, test_loss, test_s = fit(model=ae, x=test, y=test, valid=True)\n",
    "    print('test: ',\"{:1.8f}\".format(test_loss.numpy() / test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_features: 35\n",
      "epoch:    1    |   train:  0.00746239    |   valid:  0.00484377\n",
      "epoch:    2    |   train:  0.00677463    |   valid:  0.00480537\n",
      "epoch:    3    |   train:  0.00608932    |   valid:  0.00471043\n",
      "epoch:    4    |   train:  0.00530351    |   valid:  0.00452954\n",
      "epoch:    5    |   train:  0.00455928    |   valid:  0.00438284\n",
      "epoch:    6    |   train:  0.00390538    |   valid:  0.00427674\n",
      "epoch:    7    |   train:  0.00335897    |   valid:  0.00420739\n",
      "epoch:    8    |   train:  0.00292239    |   valid:  0.00414099\n",
      "epoch:    9    |   train:  0.00257395    |   valid:  0.00410186\n",
      "epoch:   10    |   train:  0.00229418    |   valid:  0.00405087\n",
      "epoch:   11    |   train:  0.00207107    |   valid:  0.00400526\n",
      "epoch:   12    |   train:  0.00188730    |   valid:  0.00397885\n",
      "epoch:   13    |   train:  0.00173995    |   valid:  0.00394830\n",
      "epoch:   14    |   train:  0.00161751    |   valid:  0.00393081\n",
      "epoch:   15    |   train:  0.00150198    |   valid:  0.00390152\n",
      "epoch:   16    |   train:  0.00140783    |   valid:  0.00388085\n",
      "epoch:   17    |   train:  0.00133709    |   valid:  0.00385347\n",
      "epoch:   18    |   train:  0.00126293    |   valid:  0.00384384\n",
      "epoch:   19    |   train:  0.00120246    |   valid:  0.00382048\n",
      "epoch:   20    |   train:  0.00113881    |   valid:  0.00381678\n",
      "epoch:   21    |   train:  0.00109901    |   valid:  0.00379657\n",
      "epoch:   22    |   train:  0.00103897    |   valid:  0.00376812\n",
      "epoch:   23    |   train:  0.00099096    |   valid:  0.00376278\n",
      "epoch:   24    |   train:  0.00095815    |   valid:  0.00374999\n",
      "epoch:   25    |   train:  0.00093190    |   valid:  0.00374313\n",
      "epoch:   26    |   train:  0.00089352    |   valid:  0.00373572\n",
      "epoch:   27    |   train:  0.00084796    |   valid:  0.00370232\n",
      "epoch:   28    |   train:  0.00081775    |   valid:  0.00368663\n",
      "epoch:   29    |   train:  0.00078682    |   valid:  0.00367252\n",
      "epoch:   30    |   train:  0.00075955    |   valid:  0.00367116\n",
      "run time: 799.4627865000002\n",
      "test:  0.00160911\n"
     ]
    }
   ],
   "source": [
    "i =35\n",
    "print('input_features:', i)\n",
    "start = timeit.default_timer()\n",
    "ae = AE(nb_inputs, nb_outputs, i)\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.1\n",
    "optimizer = optim.RMSprop(ae.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ae.criterion = nn.MSELoss()\n",
    "\n",
    "nb_epoch = 30\n",
    "\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    ae, train_loss, train_s = fit(model=ae, x=train, y=train)\n",
    "    ae, valid_loss, valid_s = fit(model=ae, x=valid, y=valid, valid=True)\n",
    "\n",
    "    print(\"epoch: \", \"{:3.0f}\".format(epoch), \"   |   train: \", \"{:1.8f}\".format(train_loss.numpy() / train_s), \\\n",
    "                    '   |   valid: ', \"{:1.8f}\".format(valid_loss.numpy() / valid_s))\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('run time:', stop-start)\n",
    "\n",
    "ae, test_loss, test_s = fit(model=ae, x=test, y=test, valid=True)\n",
    "print('test: ',\"{:1.8f}\".format(test_loss.numpy() / test_s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input feature =35\n",
    "#epoch = 30, weight_decay=0.1, learning_rate=0.01\n",
    "print('test: ',\"{:1.8f}\".format(test_loss.numpy() / test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.sigmoid(ae.fc1(train)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#exploring the correlations between different neurons\n",
    "df = pd.DataFrame(np.array(hidden))\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "plt.matshow(df.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.shape[1]), df.columns, fontsize=8, rotation=0)\n",
    "plt.yticks(range(df.shape[1]), df.columns, fontsize=8)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, x, y, valid=False):\n",
    "    \n",
    "    nb_obs, nb_items = len(x), len(x[0])\n",
    "    average_loss, s = 0, 0.\n",
    "\n",
    "    for id_user in range(nb_obs):\n",
    "\n",
    "        inputs = Variable(x[id_user]).unsqueeze(0)\n",
    "        target = Variable(y[id_user]).unsqueeze(0)\n",
    "\n",
    "        if torch.sum(target > 0) > 0:\n",
    "            \n",
    "            estimate = forward(model, inputs)\n",
    "            estimate[target <= 0] = 0\n",
    "            target.require_grad = False\n",
    "            \n",
    "            loss = model.criterion(estimate, target)\n",
    "            \n",
    "            if not valid:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            average_loss += loss.data / float(torch.sum(target.data > 0))\n",
    "            s += 1.\n",
    "\n",
    "    return model, average_loss, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3657990070.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [18]\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in range()\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_est(model, data, input_f, k):\n",
    "    \"\"\"\n",
    "     Args:\n",
    "         model: name of the autoencoder as initialized\n",
    "         data: assessments associated with the user\n",
    "         titles: list of titles of potentially recommended objects\n",
    "         k: number of recommendations wanted\n",
    "     Return:\n",
    "         names: names of the recommendations\n",
    "         scores: the score associated with them\n",
    "     \"\"\"\n",
    "    nb_obs, nb_items = len(), len([0])\n",
    "    for i in range()\n",
    "    inputs = Variable(data).unsqueeze(0)\n",
    "    outputs = forward(model, inputs)\n",
    "    outputs[inputs != 0] = 0\n",
    "    \n",
    "    names, scores = utl.rearrange(titles, outputs[0].detach().numpy())\n",
    "    \n",
    "    return names[-k:], scores[-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Variable(train+valid+test)[0]\n",
    "torch.unique(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Variable in module torch.autograd.variable:\n",
      "\n",
      "class Variable(torch._C._LegacyVariableBase)\n",
      " |  # mypy doesn't understand torch._six.with_metaclass\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Variable\n",
      " |      torch._C._LegacyVariableBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from torch._C._LegacyVariableBase:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1335, 1.1812, 0.9569,  ..., 1.9046, 1.1285, 1.0608],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 0\n",
    "k = 30\n",
    "names, scores = recommendations(ae, (train + valid + test)[user_id], movies['Title'], k)\n",
    "\n",
    "df = pd.DataFrame(np.matrix((names[-k:], scores[-k:])).T, (np.arange(k) + 1).tolist())\n",
    "df.columns = ['Title', 'Predicted rating']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutl\u001b[49m\u001b[38;5;241m.\u001b[39mrearrange\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utl' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3456"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data sparsity= 0.9958141400702879\n"
     ]
    }
   ],
   "source": [
    "#keras model\n",
    "#calculate sparsity\n",
    "def get_sparsity(test_matrice):\n",
    "    n_user, n_item = test_matrice.shape\n",
    "    sparsity = 1 - (np.count_nonzero(test_matrice))/(n_user*n_item)\n",
    "    print('data sparsity=', sparsity)\n",
    "    \n",
    "def get_data(user_t_data_path, test_matrice):\n",
    "    #with open('user_tsinfo.txt') as f:\n",
    "    with open(user_t_data_path) as f:\n",
    "        infos = f.readlines()\n",
    "    \n",
    "    n_user, n_item = test_matrice[:, 1:].shape\n",
    "    user_ids = infos[1].split(',')\n",
    "    item_ids = infos[0].split(',')\n",
    "    user_ids = user_ids[:-1]\n",
    "    item_ids = item_ids[:-1]\n",
    "\n",
    "    test_dt_obs = test_matrice[:,1:].flatten('F')\n",
    "    test_dt_users = np.tile(user_ids, n_item)\n",
    "    test_dt_items = np.repeat(item_ids, n_user)\n",
    "\n",
    "    test_dt = pd.DataFrame(test_dt_users, columns=['userID'])\n",
    "    test_dt['item'] = test_dt_items\n",
    "    test_dt['obs'] = test_dt_obs\n",
    "    \n",
    "    return(test_dt, user_ids, item_ids)\n",
    "\n",
    "test_sparse = get_sparsity(test_matrice_reverse[:, 1:])\n",
    "\n",
    "'''\n",
    "test_dt, user_ids, item_ids = get_data('user_tsinfo.txt', test_matrice_reverse)\n",
    "test_dt_non_zero = test_dt[test_dt['obs'] > 0]\n",
    "\n",
    "#create dict to store item index\n",
    "a = 1\n",
    "item_index = {}\n",
    "for st_ids in item_ids:\n",
    "    item_index[st_ids] = a\n",
    "    a += 1\n",
    "    \n",
    "a = 1 \n",
    "user_index = {}\n",
    "for ids in user_ids:\n",
    "    user_index[int(ids)] = a\n",
    "    a += 1\n",
    "'''\n",
    "\n",
    "latlon_shape = pd.read_csv('G:/My Drive/2020/Bias/data-processing/latlon_shape.csv')\n",
    "obs_Seattle = pd.read_csv('G:/My Drive/2020/Bias/data-processing/obs_Seattle.csv')\n",
    "\n",
    "Seattle_geos = np.unique(list(obs_Seattle['GEOID10'].values))\n",
    "\n",
    "latlon_shape = latlon_shape[['newid', 'geoid', 'obs', 'timestamp', 'accuracy']]\n",
    "latlon_shape = latlon_shape[latlon_shape['geoid'].isin(Seattle_geos)]\n",
    "\n",
    "get_hr = lambda x: datetime.fromtimestamp(x).hour\n",
    "get_min = lambda x: int(datetime.fromtimestamp(x).minute/5)*5\n",
    "\n",
    "latlon_shape['hr_str'] = list(map(str, list(latlon_shape['timestamp'].apply(get_hr).values)))\n",
    "latlon_shape['minute_str'] = list(map(str, list(latlon_shape['timestamp'].apply(get_min).values)))\n",
    "latlon_shape['geoids_str'] = list(map(str, list(latlon_shape['geoid'].values)))\n",
    "\n",
    "latlon_shape['spatial_temp_id'] = latlon_shape['geoids_str'] + '_' + latlon_shape['hr_str'] + '_' + latlon_shape['minute_str']\n",
    "\n",
    "latlon_shape = latlon_shape[['newid','spatial_temp_id','obs','timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_st2index = lambda x: item_index[x]\n",
    "latlon_shape['spatial_temp_id'] = latlon_shape['spatial_temp_id'].apply(convert_st2index)\n",
    "convert_newid2index = lambda x: user_index[x]\n",
    "latlon_shape['newid'] = latlon_shape['newid'].apply(convert_newid2index)\n",
    "\n",
    "latlon_shape['newid'] = latlon_shape['newid'] - 1\n",
    "latlon_shape['spatial_temp_id'] = latlon_shape['spatial_temp_id'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_obs = min(latlon_shape['obs'])\n",
    "max_obs = max(latlon_shape['obs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(latlon_shape, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROW_COUNT = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'timestamp', 'lat', 'lon', 'accuracy', 'idtype', 'newid',\n",
       "       'd', 'hr', 'minut', 'obs', 'time', 'geometry', 'index_right',\n",
       "       'STATEFP10', 'COUNTYFP10', 'TRACTCE10', 'GEOID10', 'NAME10',\n",
       "       'NAMELSAD10', 'MTFCC10', 'FUNCSTAT10', 'ALAND10', 'AWATER10',\n",
       "       'INTPTLAT10', 'INTPTLON10', 'geoid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latlon_shape.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 10\n",
    "NUM_USERS = latlon_shape['newid'].nunique()\n",
    "NUM_MOVIES = latlon_shape['spatial_temp_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning from keras\n",
    "#source: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "#keras model\n",
    "def EmbeddingRec(EMBEDDING_SIZE, NUM_MOVIES, NUM_USERS, ROW_COUNT):\n",
    "    movie_input = keras.Input(shape=(1,), name='movie_id')\n",
    "\n",
    "    movie_emb = layers.Embedding(output_dim=EMBEDDING_SIZE, input_dim=NUM_MOVIES, input_length=ROW_COUNT, name='movie_emb')(movie_input)\n",
    "    movie_vec = layers.Flatten(name='FlattenMovie')(movie_emb)\n",
    "\n",
    "    movie_model = keras.Model(inputs=movie_input, outputs=movie_vec)\n",
    "    \n",
    "    user_input = keras.Input(shape=(1,), name='user_id')\n",
    "\n",
    "    user_emb = layers.Embedding(output_dim=EMBEDDING_SIZE, input_dim=NUM_USERS, input_length=ROW_COUNT, name='user_emb')(user_input)\n",
    "    user_vec = layers.Flatten(name='FlattenUser')(user_emb)\n",
    "\n",
    "    user_model = keras.Model(inputs=user_input, outputs=user_vec)\n",
    "    \n",
    "    merged = layers.Dot(name = 'dot_product', normalize = True, axes = 2)([movie_emb, user_emb])\n",
    "    merged_dropout = layers.Dropout(0.2)(merged)\n",
    "    \n",
    "    \n",
    "    dense_1 = layers.Dense(70,name='FullyConnected-1')(merged)\n",
    "    dropout_1 = layers.Dropout(0.2,name='Dropout_1')(dense_1)\n",
    "\n",
    "    dense_2 = layers.Dense(50,name='FullyConnected-2')(dropout_1)\n",
    "    dropout_2 = layers.Dropout(0.2,name='Dropout_2')(dense_2)\n",
    "\n",
    "    dense_3 = keras.layers.Dense(20,name='FullyConnected-3')(dropout_2)\n",
    "    dropout_3 = keras.layers.Dropout(0.2,name='Dropout_3')(dense_3)\n",
    "\n",
    "    dense_4 = keras.layers.Dense(10,name='FullyConnected-4', activation='relu')(dropout_3)\n",
    "\n",
    "    result = layers.Dense(1, name='result', activation=\"relu\") (dense_4)\n",
    "\n",
    "    adam = keras.optimizers.Adam(lr=0.001)\n",
    "    model = keras.Model([movie_input, user_input], result)\n",
    "    model.compile(optimizer=adam,loss= 'mean_absolute_error')\n",
    "    return model, movie_model, user_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29700\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model, movie_model, user_model = EmbeddingRec(EMBEDDING_SIZE, NUM_MOVIES, NUM_USERS, ROW_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping('val_loss', patience=10),\n",
    "             keras.callbacks.ModelCheckpoint('besttest.h5', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([train.spatial_temp_id, train.newid],\n",
    "                    train.obs, batch_size=100,\n",
    "                    epochs =50, validation_data = ([test.spatial_temp_id, \n",
    "                                                    test.newid],\n",
    "                                                   test.obs),\n",
    "                              verbose = 1, \n",
    "                              callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.0031551]]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([np.array([10]), np.array([3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'] , 'g')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previous Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#land use data processing\n",
    "\n",
    "#land use data\n",
    "\n",
    "input_path = 'G:/My Drive/2021/Bias/census_block_data/'\n",
    "os.chdir(input_path)\n",
    "\n",
    "Seattle_land_use = pd.read_csv(input_path+'Seattle_land_use.csv')\n",
    "Seattle_land_use.columns\n",
    "\n",
    "Seattle_dt = pd.read_csv('Seattle_land_use_joined_points.csv')\n",
    "Seattle_dt.head(3)\n",
    "\n",
    "row_index = read_dict('row_index.txt')\n",
    "col_index = read_dict('col_index.txt')\n",
    "\n",
    "user_index = convert_dict(row_index)\n",
    "item_index = convert_dict(col_index)\n",
    "\n",
    "Seattle_01obs = pd.read_csv('obs01_landuse.csv', header=None).to_numpy()\n",
    "Seattle_obs = pd.read_csv('obs_landuse.csv', header=None).to_numpy()\n",
    "\n",
    "numobs_onuser = np.count_nonzero(Seattle_01obs, axis=1)\n",
    "numobs_onuser_obs = np.count_nonzero(Seattle_obs, axis=1)\n",
    "\n",
    "#data for zero index processing\n",
    "latlon_file = pd.read_csv('latlon_file.csv')\n",
    "col_name = latlon_file.columns\n",
    "col_name\n",
    "\n",
    "col_name = list(latlon_file.columns)\n",
    "col_name.remove('Unnamed: 0')\n",
    "latlon_file = latlon_file[col_name]\n",
    "\n",
    "#latlon_file_test = pd.read_csv('Seattle_land_use_joined_points.csv')\n",
    "#crossed_rt = pd.read_csv('crossed_rt.csv', index_col=0)\n",
    "#crossed_rt = pd.read_csv('crossed_routes.csv')\n",
    "#crossed_rt.head(3)\n",
    "\n",
    "crossed_rt = pd.read_csv('crossed_rt.csv', index_col=0)\n",
    "newids_map = row_index\n",
    "locts_map = col_index\n",
    "newids = list(newids_map.keys())\n",
    "a = 0\n",
    "index = 0\n",
    "for ids in newids:\n",
    "    if a <= index:\n",
    "        test_dt = crossed_rt[['time_diff', 's_hr','e_hr','od_euqal']][crossed_rt['newid'] == ids]\n",
    "        test_dt = test_dt.sort_values(by=['time_diff'])\n",
    "        plt.figure(a)\n",
    "        x = list(test_dt['s_hr'].values)\n",
    "        y = list(test_dt['time_diff'].values)\n",
    "        plt.plot(x,y,'o')\n",
    "        plt.title('time difference between each time segement for ids = '+str(ids))\n",
    "        a += 1\n",
    "        \n",
    "test_dt = crossed_rt[['s_hr', 'time_diff']][crossed_rt['od_euqal']==0].sort_values(by=['s_hr', 'time_diff'])\n",
    "plt.figure(0)\n",
    "plt.plot(list(test_dt['s_hr'].values), list(test_dt['time_diff'].values),'o')\n",
    "plt.title('time difference across day')\n",
    "\n",
    "#keep previous census tract\n",
    "ori_geo = crossed_rt['ori_geo'].values\n",
    "dest_geo = crossed_rt['dest_geo'].values\n",
    "no_crossed_ct = crossed_rt['no_crossed_ct'].values\n",
    "no_crossed_cts = []\n",
    "for i in range(len(ori_geo)):\n",
    "    no_crossed = no_crossed_ct[i].strip('[]').split(', ')\n",
    "    if str(ori_geo[i]) in no_crossed:\n",
    "        no_crossed.remove(str(ori_geo[i]))\n",
    "    if str(dest_geo[i]) in no_crossed:\n",
    "        no_crossed.remove(str(dest_geo[i]))\n",
    "    no_crossed_cts.append(no_crossed)\n",
    "\n",
    "del(ori_geo)\n",
    "del(dest_geo)\n",
    "del(no_crossed_ct)\n",
    "\n",
    "crossed_rt['no_crossedcts'] = no_crossed_cts\n",
    "crossed_rt = crossed_rt.sort_values(by=['newid','time_diff','s_hr'])\n",
    "\n",
    "#we found missing valeues after we processing the data\n",
    "#latlon_path = 'G:/My Drive/2021/Bias/data-processing/'\n",
    "#Seattle_latlon = pd.read_csv('Seattle_latlon.csv', index_col=0)\n",
    "\n",
    "selected_colname = list(latlon_file.columns)\n",
    "#selected_colname.remove('Unnamed: 0.1')\n",
    "to5min = lambda x: int(x/5)*5\n",
    "latlon_file['minut_5'] = (latlon_file['minut'].apply(to5min)).values\n",
    "#through the checking, it is found there are individuals missing after the shortest path algorithm\n",
    "ids_in_dt = list(np.unique(crossed_rt['newid']))\n",
    "diff = set(newids)^set(ids_in_dt)\n",
    "\n",
    "print('# of ids with shortest path: ', len(ids_in_dt))\n",
    "print('# of identified ids: ', len(newids_map.keys()))\n",
    "print('# of missing ids without shortest path: ', len(diff))\n",
    "\n",
    "#check the missed data in detail\n",
    "\n",
    "crossed_rt = crossed_rt.sort_values(by=['newid','start_time'])\n",
    "crossed_rt.reset_index(inplace=True)\n",
    "crossed_rt.head(3)\n",
    "\n",
    "newids = np.unique(crossed_rt['newid'])\n",
    "kept_data_start = {}\n",
    "kept_data_end = {}\n",
    "for ids in newids:\n",
    "    kept_data_start[ids] = list(crossed_rt['start_time'][crossed_rt['newid']==ids].values)\n",
    "    kept_data_end[ids] = list(crossed_rt['end_time'][crossed_rt['newid']==ids].values)\n",
    "    \n",
    "#get missing trips\n",
    "#missing ids with missing data\n",
    "newids = np.unique(crossed_rt['newid'])\n",
    "newids_all = list(newids_map.keys())\n",
    "missing_ids = {}\n",
    "for ids in newids_all:\n",
    "    missing_ids[ids] = []\n",
    "    time_data = list(latlon_file['timestamp'][latlon_file['newid']==ids].values)\n",
    "    if ids not in newids:\n",
    "        missing_ids[ids] = time_data\n",
    "    else:    \n",
    "        for time in time_data:\n",
    "            if time not in kept_data_end[ids] and time not in kept_data_start[ids]:\n",
    "                missing_ids[ids].append(time)\n",
    "                \n",
    "missing_pairs = {}\n",
    "for ids in newids:\n",
    "    missing_pairs[ids] = {'o':[],'d':[]}\n",
    "    cur_odpairs = crossed_rt[['start_time', 'end_time']][crossed_rt['newid']==ids].values\n",
    "    time_data = list(latlon_file['timestamp'][latlon_file['newid']==ids].values)\n",
    "    for i in range(len(time_data)):\n",
    "        if i < len(time_data)-1:\n",
    "            od_pairs = []\n",
    "            od_pairs.append(time_data[i]) \n",
    "            od_pairs.append(time_data[i+1])\n",
    "            if od_pairs not in cur_odpairs:\n",
    "                missing_pairs[ids]['o'].append(od_pairs[0])\n",
    "                missing_pairs[ids]['d'].append(od_pairs[1]) \n",
    "                \n",
    "\n",
    "                \n",
    "print('worst data accuracy: ', np.max(latlon_file['accuracy']))\n",
    "\n",
    "census_t = list(np.unique(latlon_file['ZONEID']))\n",
    "\n",
    "zero_loc_time = {}\n",
    "for ids in missing_ids:\n",
    "    if ids not in zero_loc_time:\n",
    "        #print(ids)\n",
    "        zero_loc_time[ids] = []\n",
    "    #print(missing_ids[ids])    \n",
    "    zero_loc_time[ids] = convert_missingids(missing_ids[ids], ids, zero_loc_time[ids], latlon_file, 'ZONEID')\n",
    "\n",
    "#obs data check\n",
    "#count_nonzeros\n",
    "index_num = 0\n",
    "user_w_smallobs = []\n",
    "for i in numobs_onuser:\n",
    "    if i <= 1:\n",
    "        user_w_smallobs.append(user_index[index_num])\n",
    "    index_num += 1     \n",
    "    \n",
    "for i in range(len(user_w_smallobs)):\n",
    "    print(np.max(Seattle_obs[row_index[user_w_smallobs[i]]]))\n",
    "    \n",
    "### create the zero index matrix\n",
    "Zero_index = np.zeros(Seattle_01obs.shape)\n",
    "for row in zero_loc_time:\n",
    "    for col in zero_loc_time[row]:\n",
    "        Zero_index[newids_map[row]][locts_map[col]] = 1\n",
    "        \n",
    "### create the zero index matrix\n",
    "Zero_index = np.zeros(Seattle_01obs.shape)\n",
    "for row in zero_loc_time:\n",
    "    for col in zero_loc_time[row]:\n",
    "        Zero_index[newids_map[row]][locts_map[col]] = 1\n",
    "        \n",
    "save_matrix2file('../census_block_data/','zero_land_use.csv', Zero_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
